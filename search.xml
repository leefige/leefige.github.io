<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>3月10日的山桃和忍冬</title>
    <url>/2021/03/11/3%E6%9C%8810%E6%97%A5%E7%9A%84%E5%B1%B1%E6%A1%83%E5%92%8C%E5%BF%8D%E5%86%AC/</url>
    <content><![CDATA[<p>昨天逸夫馆前的山桃已经几乎盛开了。北馆前的忍冬也开花了（不知道是开了还快谢了？），望春玉兰也在开的边缘了。</p>
<span id="more"></span>
<figure>
<img data-src="3-10-忍冬.jpg" alt="3月10日的忍冬" />
<figcaption aria-hidden="true">3月10日的忍冬</figcaption>
</figure>
<figure>
<img data-src="3-10-山桃.jpg" alt="3月10日的山桃" />
<figcaption aria-hidden="true">3月10日的山桃</figcaption>
</figure>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>2021赏花</tag>
      </tags>
  </entry>
  <entry>
    <title>[CMU OS lab] P1 (part 1): x86硬件</title>
    <url>/2020/01/26/CMU-OS-lab-P1-part-1-x86%E7%A1%AC%E4%BB%B6/</url>
    <content><![CDATA[<p>P1的主要内容是写一个以核心态 Privilege Level 0 直接运行在 x86
硬件上的游戏 Sokoban
(推箱子)。同样，出于学术规范考虑，本文不会透露项目的全部代码和 handout
，但可能会在必要时节选少量代码片段。代码片段版权所有为CMU 15-410/605 OS
课程。另外也可能节选少量清华 OS 课程代码片段，版权所有为清华大学计算机系
OS 课程。</p>
<p>作为第一部分，本文主要介绍 x86
的基础硬件（体系结构要求，如分段机制、特权级等）。正如 CMU OS
课程所述，并非所有 OS 都要满足这样的要求，这是利用 x86 平台学习 OS
必须的代价。</p>
<span id="more"></span>
<h1 id="特权级-privilege-level">特权级 Privilege Level</h1>
<p>x86 特权级共有 ring 0 - ring 3 四等，OS 课程中称为 PL0 - PL3。kernel
运行在 PL0，用户代码运行在 PL3，PL1 2 本课程不涉及。</p>
<h1 id="分段机制-segmentation">分段机制 Segmentation</h1>
<p>段机制的实现基于段寄存器 segment register，段选择子 segment
selector，段描述符（表） segment descriptor (table)。描述符表分为全局
global descriptor table (GDT) 和本地 local descriptor table
(LDT)。本课程只使用GDT，清华OS课程也只使用GDT。</p>
<p>段选择子如图所示： <img data-src="/2020/01/26/CMU-OS-lab-P1-part-1-x86%E7%A1%AC%E4%BB%B6/segsel.gif" class="" title="段选择子"></p>
<p>段选择子被存储在段寄存器中。段寄存器共有以下几种： -
%CS：代码段寄存器，当前运行的代码所在的段 - %SS:
栈（stack）段寄存器，栈所在的段 - %DS, %ES, %FS, %GS:
数据段寄存器，一般用%DS</p>
<p>段描述符如图所示： <img data-src="/2020/01/26/CMU-OS-lab-P1-part-1-x86%E7%A1%AC%E4%BB%B6/segdesc.gif" class="" title="段描述符"></p>
<p>段描述符被存储在内存中。<code>Type</code>
字段规定了段的读写权限。因为 x86
体系规定一个段不能既有“读/写”权限又有“读/执行”权限，因此至少需要两个段：代码段和数据段。为了简便（因为段本身的保护能力被移交给了分页机制），所以这两个段的基址都为0，大小都为
4G （即 <code>limit</code> 为 0xFFFFFFFF）。</p>
<p>注意， <code>limit</code> 字段为 20 bits，表示上限为 1 MB，如何表示 4
GB 呢？在于其 <code>G (granularity)</code> 字段。<code>G</code>
设置时粒度为 4 Kb，那么 <span class="math inline">\(1M \times 4KB =
4GB\)</span>. 同时应该设置
<code>D/B (default operation size/default stack pointer size and/or upper bound)</code>
为 <code>1</code> 表示 32 bits。</p>
<h2 id="关于-type">关于 <code>Type</code>：</h2>
<img data-src="/2020/01/26/CMU-OS-lab-P1-part-1-x86%E7%A1%AC%E4%BB%B6/segtype.png" class="" title="段类型">
<p>解释了为什么“一个段不能既有‘读/写’权限又有‘读/执行’权限”。CMU中将代码段
type 设为 b，数据段设为 3，这是额外把 <code>A</code> 也置为了
1。<code>A</code> 表示
accessed，即已经访问过，所以这里初始化时设不设置其实没什么影响（似乎）。但THU课程中初始化没有设置
<code>A</code>.</p>
<p>另外吐槽一点，CMU 的 GDT 表完全是 magic number 写的：</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">init_gdt:</span> /* <span class="number">0x100900</span> */</span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x00000000</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x00000000</span></span><br><span class="line">    /* Next two lines need to be kept <span class="keyword">in</span> sync with smp/smp<span class="number">.</span>c */</span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x09500067</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x00008910</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x0000ffff</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x00cf9b00</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x0000ffff</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x00cf9300</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x0000ffff</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x00cffb00</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x0000ffff</span></span><br><span class="line"><span class="meta">    .long</span> <span class="number">0x00cff200</span></span><br></pre></td></tr></table></figure>
<p>然而 THU 的 GDT 是通过定义了各种宏，生成的可读代码：</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">#define SEG_ASM(type,base,lim)                                  \</span><br><span class="line"><span class="meta">    .word</span> (((lim) &gt;&gt; <span class="number">12</span>) &amp; <span class="number">0xffff</span>), ((base) &amp; <span class="number">0xffff</span>)<span class="comment">;          \</span></span><br><span class="line"><span class="meta">    .byte</span> (((base) &gt;&gt; <span class="number">16</span>) &amp; <span class="number">0xff</span>), (<span class="number">0x90</span> | (type)),             \</span><br><span class="line">        (<span class="number">0xC0</span> | (((lim) &gt;&gt; <span class="number">28</span>) &amp; <span class="number">0xf</span>)), (((base) &gt;&gt; <span class="number">24</span>) &amp; <span class="number">0xff</span>)</span><br><span class="line"></span><br><span class="line">/* Normal <span class="meta">segment</span> */</span><br><span class="line">#define SEG_NULLASM                                             \</span><br><span class="line"><span class="meta">    .word</span> <span class="number">0</span>, <span class="number">0</span><span class="comment">;                                                 \</span></span><br><span class="line"><span class="meta">    .byte</span> <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">.data</span></span><br><span class="line"># Bootstrap GDT</span><br><span class="line"><span class="meta">.p2align</span> <span class="number">2</span>                                          # force <span class="number">4</span> <span class="built_in">byte</span> alignment</span><br><span class="line"><span class="symbol">gdt:</span></span><br><span class="line">    SEG_NULLASM                                     # null <span class="built_in">seg</span></span><br><span class="line">    SEG_ASM(STA_X|STA_R, <span class="number">0x0</span>, <span class="number">0xffffffff</span>)           # code <span class="built_in">seg</span> for bootloader <span class="keyword">and</span> kernel</span><br><span class="line">    SEG_ASM(STA_W, <span class="number">0x0</span>, <span class="number">0xffffffff</span>)                 # data <span class="built_in">seg</span> for bootloader <span class="keyword">and</span> kernel</span><br><span class="line"><span class="symbol"></span></span><br><span class="line"><span class="symbol">gdtdesc:</span></span><br><span class="line"><span class="meta">    .word</span> <span class="number">0x17</span>                                      # sizeof(gdt) - <span class="number">1</span></span><br><span class="line"><span class="meta">    .long</span> gdt                                       # address gdt</span><br></pre></td></tr></table></figure>
<p>而且 CMU 的代码把这一堆 hard code 的 GDT 写在了 <code>.text</code>
段...不过 CMU 做的好的一个方面是，封装了一个 <code>lgdt</code>
的函数，通过 asm 代码里一通操作，可以随意 load gdt。THU 倒是把初始化的
GDT 通过 hard code 给 load 了。</p>
<p>关于 <code>lgdt</code>，它要的是一个 6B 的参数，前 2B （一个 word）是
limit，后 4B 是 GDT base。因此 CMU 操作里先 <code>pushl</code> 再
<code>pushw</code> 然后 <code>lgdt (%esp)</code> 把我整懵了，没想到
<code>pushw</code> 真就 <code>%esp</code> 减2而非减4...这也对应于 THU
代码里的 <code>gdtdesc</code> 是一个 word 一个 long。</p>
<p><code>lgdt</code> 以后 GDT base address 被存在 <code>%CR3</code>
寄存器里。</p>
<h2 id="cpl-rpl-dpl">CPL RPL DPL</h2>
<ul>
<li><code>CPL</code>: <code>%CR0</code> 寄存器里的处理器 current
特权级</li>
<li><code>RPL</code>: 段寄存器里（段选择子）的 required 特权级</li>
<li><code>DPL</code>: 段描述符里段本身的 descriptor 特权级</li>
</ul>
<p>有什么联系：</p>
<h3 id="访问数据段">访问数据段</h3>
<p>把一个段选择子加载到数据段寄存器时，需要一个 privilege level
check：</p>
<blockquote>
<p>The processor loads the segment selector into the segment register if
the DPL is numerically greater than or equal to both the CPL and the
RPL. Otherwise, a general-protection fault is generated and the segment
register is not loaded. -- <em>Intel 2001 ed Volume 3 4-9</em></p>
</blockquote>
<p>也就是说，RPL 的目的是可以降低当前的特权级（制约
CPL）。利用一个低特权级的选择子访问低特权级的内存是可行并且更安全的。</p>
<h3 id="访问代码段">访问代码段</h3>
<p>通过门 (Gate) 访问代码段也要做检查，这里直接复制我在 THU 上课时在
Piazza 上回答一个问题的内容<a
href="https://piazza.com/class/i5j09fnsl7k5x0?cid=1009">关于x-86访问时特权级的问题</a>：</p>
<p>关于上面提到的最后一点，即“Example of Accessing Call Gates At Various
Privilege Levels”，对应于PPT中“x86访问门时的特权级：CPL &lt;= DPL[门]
&amp; CPL &gt;= DPL[段]”，我的理解如下：</p>
<p>首先手册中Table
5-1给出了访问门时的特权级检查规则（此处仅考虑使用call而非jmp）：</p>
<img data-src="/2020/01/26/CMU-OS-lab-P1-part-1-x86%E7%A1%AC%E4%BB%B6/pc-call.png" class="" title="访问门时的特权级检查规则">
<p>可以看到，对于DPL有两个概念需要区分：其一是门本身的gate
DPL，其二是门对应的目标代码段的code segment DPL.
此外，这里还有两个名词需要解释：</p>
<ul>
<li>conforming code
segment：一致代码段，可以被低特权级的用户直接调用访问的代码，但是特权级不会改变，用户态还是用户态</li>
<li>nonconforming code
segment：非一致代码段，只允许同级间访问，绝对禁止不同级访问</li>
</ul>
<p>这样就可以理解PPT中提到的“CPL &lt;= DPL[门] &amp; CPL &gt;=
DPL[段]”的含义如下：</p>
<ul>
<li>对于第一条“CPL &lt;= DPL[门]”，对应的是Table
5-1中第一条条件，即门本身是可以在当前特权级下被访问到的</li>
<li>对于第二条“CPL &gt;= DPL[段]”，对应的是Table
5-1中第二条条件，即门对应的目标代码段（可以理解为门指向的中断服务例程代码）所满足的条件，也就是要求目标代码的DPL不大于当前特权级；这一点很好理解，因为目标代码段一般为核心代码，其本身的DPL为核心等级，但存在处于用户态的进程需要执行这些代码的需求（如系统调用），因此允许目标代码DPL小于CPL的情况出现。但针对代码段是conforming还是nonconforming，会涉及到是否要变更CPL</li>
</ul>
<p>下面举出手册中的例子。作为例子的Figure 5-12如下：</p>
<img data-src="/2020/01/26/CMU-OS-lab-P1-part-1-x86%E7%A1%AC%E4%BB%B6/pc-call-eg.png" class="" title="不同特权级访问门的例子">
<p>仅以在ring 3访问Gate A为例：</p>
<ul>
<li>当前处于用户态的代码段A，CPL=3</li>
<li>通过Gate Selector A以RPL=3访问门A，门A的DPL=3，这满足Table
5-1的第一条检查条件，即“CPL &lt;= call gate DPL, RPL &lt;= call gate
DPL”</li>
<li>在满足上面的条件后，则可以跳转并执行门A对应的核心态代码段E（可以理解为门A对应的中断服务例程），代码段E的DPL=0，小于CPL，对于call
gate而言这是允许的，满足Table 5-1的第二条检查条件</li>
<li>由于代码段E是nonconforming code
segment，所以会要求CPL的特权级变更（需要变为代码段E的同级即ring
0），因而会导致stack switch（作为对比，访问代码段D时不需要stack
switch）</li>
</ul>
<p>（参考：Intel® 64 and IA-32 Architectures Software Developer’s Manual
第5.8.4节 Accessing a Code Segment Through a Call Gate）</p>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>System</tag>
        <tag>x86</tag>
        <tag>CMU</tag>
      </tags>
  </entry>
  <entry>
    <title>KaTex中的多行等式</title>
    <url>/2019/03/11/KaTex%E4%B8%AD%E7%9A%84%E5%A4%9A%E8%A1%8C%E7%AD%89%E5%BC%8F/</url>
    <content><![CDATA[<p>Traceback (most recent call last): File "/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/" Error: no
idea of using KaTex for math formula</p>
<p>During handling of the above exception, another exception
occurred:</p>
<p>Traceback (most recent call last): File " <a
href="https://katex.org/docs/support_table.html">KaTex Support Table</a>
" Error: no idea of how to display multi-line equations</p>
<span id="more"></span>
<p>在写博客时要输入数学公式，发现想不起来<span
class="math inline">\(\KaTeX\)</span>（也即<span
class="math inline">\(\LaTeX\)</span>）的语法了……</p>
<p>于是去查了语法，比如：</p>
<p><strong>In:</strong></p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="built_in">$</span><span class="built_in">$</span><span class="keyword">\frac</span>&#123;1&#125;&#123;n-1&#125;<span class="built_in">$</span><span class="built_in">$</span></span><br><span class="line"><span class="built_in">$</span><span class="built_in">$</span><span class="keyword">\frac</span>&#123;v<span class="built_in">_</span>1&#125;&#123;<span class="keyword">\theta</span><span class="built_in">^</span>&#123;3&#125;&#125;<span class="built_in">$</span><span class="built_in">$</span></span><br></pre></td></tr></table></figure>
<p><strong>Out:</strong></p>
<p><span class="math display">\[\frac{1}{n-1}\]</span></p>
<p><span class="math display">\[\frac{v_1}{\theta^{3}}\]</span></p>
<p>然而遇到了一个多行公式（连等式），太长了实在避免不了分行，于是只能查一下怎么打多行公式。却发现<span
class="math inline">\(\LaTeX\)</span>支持的</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;equation*&#125;<span class="comment">%加*表示不对公式编号</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;split&#125;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">\end</span>&#123;split&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;equation*&#125;</span><br></pre></td></tr></table></figure>
<p>并不被<span class="math inline">\(\KaTeX\)</span>支持，同时指向了<a
href="https://github.com/KaTeX/KaTeX/issues/445">Issue
#445</a>，打开发现其实可以用<code>aligned</code>代替：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;aligned&#125;</span><br><span class="line">a<span class="built_in">&amp;</span>=b<span class="built_in">&amp;</span>c<span class="built_in">&amp;</span>=d<span class="keyword">\\</span></span><br><span class="line">e<span class="built_in">&amp;</span>=f</span><br><span class="line"><span class="keyword">\end</span>&#123;aligned&#125;</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<p><span class="math display">\[\begin{aligned}
a&amp;=b&amp;c&amp;=d\\
e&amp;=f
\end{aligned}
\]</span></p>
<p>问题解决。EOF</p>
]]></content>
      <categories>
        <category>技巧</category>
      </categories>
      <tags>
        <tag>LaTeX</tag>
        <tag>KaTeX</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang创建定时程序</title>
    <url>/2021/03/10/Golang%E5%88%9B%E5%BB%BA%E5%AE%9A%E6%97%B6%E7%A8%8B%E5%BA%8F/</url>
    <content><![CDATA[<p>前两天用Golang手写MapReduce框架时，遇到这样一个问题：</p>
<blockquote>
<p>worker可能随时crash，那么coordinator分配给worker的任务不能无限等待worker的回复，因此需要给每个分配出去的任务设置timeout，也就是需要一个定时程序清理crash/太慢的worker的任务。</p>
</blockquote>
<span id="more"></span>
<p>Golang对并发的原生支持是比较好的，直观而言，只需要在某个goroutine里等待timeout，然后重置这个任务即可。这里我们用“更像Golang”的方法来完成这个任务。</p>
<h3 id="golang-time.timer">Golang <code>time.Timer</code></h3>
<p><code>time.Timer</code>是Golang标准库中提供的定时器。用如下代码可以创建一个新定时器(定时10秒)：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">timer := time.NewTimer(time.Second * <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p><code>Timer</code>有一个成员<code>C</code>，类型是<code>chan Time</code>的channel，根据官方文档：</p>
<blockquote>
<p>The Timer type represents a single event. When the Timer expires, the
current time will be sent on C, unless the Timer was created by
AfterFunc. A Timer must be created with NewTimer or AfterFunc.</p>
</blockquote>
<p>可见如果用上面的<code>NewTimer</code>方法指定计时，那么<code>Timer</code>到期后，会给<code>C</code>发送时间。</p>
<p>再注意到Golang中channel是会阻塞的，我们可以用这个方法判断是否到时。</p>
<h3 id="定时程序">定时程序</h3>
<p>首先在调用者函数中创建定时器<code>Timer</code>，接着启动一个goroutine来等候<code>Timer</code>的信号，这时调用者函数可以继续做其他工作。</p>
<figure class="highlight go"><figcaption><span>timer.go</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    done := <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// set up timer</span></span><br><span class="line">    fmt.Println(<span class="string">&quot;10s timeout set up&quot;</span>)</span><br><span class="line">    timer := time.NewTimer(time.Second * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// goroutine waiting for timeout</span></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="comment">// will block here before expiring</span></span><br><span class="line">        &lt;-timer.C</span><br><span class="line">        <span class="comment">// mark the flag as done</span></span><br><span class="line">        fmt.Println(<span class="string">&quot;timeout!&quot;</span>)</span><br><span class="line">        done = <span class="literal">true</span></span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// do some other work...</span></span><br><span class="line">    <span class="keyword">for</span> !done &#123;</span><br><span class="line">        fmt.Println(<span class="string">&quot;still working...&quot;</span>)</span><br><span class="line">        time.Sleep(time.Second)</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(<span class="string">&quot;finally finished!&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面这段程序输出如下，每句<code>still working...</code>输出间隔1秒：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ go run timer.go</span><br><span class="line">10s <span class="built_in">timeout</span> <span class="built_in">set</span> up</span><br><span class="line">still working...</span><br><span class="line">still working...</span><br><span class="line">still working...</span><br><span class="line">still working...</span><br><span class="line">still working...</span><br><span class="line">still working...</span><br><span class="line">still working...</span><br><span class="line">still working...</span><br><span class="line">still working...</span><br><span class="line">still working...</span><br><span class="line"><span class="built_in">timeout</span>!</span><br><span class="line">finally finished!</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技巧</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>并发</tag>
        <tag>定时</tag>
        <tag>程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title>人类心智和计算机发展简史：《人类的终极命运》读书笔记</title>
    <url>/2019/03/04/%E3%80%8A%E4%BA%BA%E7%B1%BB%E7%9A%84%E7%BB%88%E6%9E%81%E5%91%BD%E8%BF%90%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>作为对老师推荐书目《人类的终极命运——从旧石器时代到人工智能的未来》的阅读笔记……对我而言是一种备忘和阅读输出，对读者而言多多少少也是一种想法的交流和讨论，而非仅仅是对枯燥历史的教科书式搬运。</p>

</blockquote>
<span id="more"></span>
<h3 id="前言">〇、前言</h3>
<p>尽管作业题目是“计算机发展简史”，但鉴于纯粹的“计算机发展过程”我们已经在若干门课程中以若干种形式有了充分的了解，何况资料性质的内容在当今信息时代可以用无数种方法方便而全面地检索到，那么我如果在这里用整整5000字篇幅将各大“百科”上的枯燥资料复制粘贴，再将它们以一些我个人风格的叙事形式进行连接拼贴呈现出一篇宏大而乏味的“计算机史”，则实在是对我个人和将要阅读这篇文字的老师或助教时间的非有效利用。</p>
<p>因此，我希望我的这5000字在涉及计算机发展历史之余，更多作为对老师推荐书目《人类的终极命运——从旧石器时代到人工智能的未来》的阅读笔记，更重要的是，希望在这里记录下我个人在阅读中的一些体验、思考，或是在看到某个句段时脑中闪现的只言片语，这样一方面对我而言是一种备忘和阅读输出，对读者而言多多少少也是一种想法的交流和讨论，而非仅仅是对枯燥历史的教科书式搬运。</p>
<p>在开始之前还有一点其他的题外话。作为一名转系生，我在上学期才终于补修了“信息科学技术概论”课，坦白地讲，很多同学都视此课无足轻重，然而实际上老师们的讲座却给我颇多思考。讲座的目的固然是要给大多数对信息学一无所知的、刚入学的大一新生们以信息科学的总体概述，但其中也涉及到很多老师的经验、思考，以及大量建立在一定专业知识之上的对于学科本身的理解，这些内容对于我这样对计算机和信息学还算略有一点专业背景了解的学生而言，还是有着很多远超出我对课程预期的收获的。其中影响很深的两次讲座来自张小平老师和刘云浩老师。在这两次相邻的讲座中，二位老师除了介绍信息学、计算机发展的历史外，还涉及到了大量当时哲学界、数学界、物理学界的发展情况，尤其是哲学界的思想冲突，给了我对于信息科学发展契机本身的新的认识。</p>
<p>相应的，这本书和这两次讲座有着异曲同工之妙。我的读书习惯是不放过一个字，包括注释、目录，尤其是书籍的前言。从前言中我了解到了本书作者的丰富经历——专家系统领域博士毕业，而后因为对学术界的失望转向业界，但从未放弃自己的个人研究，随后对其他学科知识大量涉猎，包括哲学、脑神经科学等，在他所理解的真正的“人工智能”方面思考不休，终于赶上这样一个人工智能重放异彩的时代，将自己的学习、研究和思考凝聚为一本综合阐释人类智慧、哲学、技术是何以从旧石器时代走到今天乃至未来的综述读本，而其独特之处更在于作者本身的计算机专业背景和专注的思考点，使得每一次回顾和讨论都紧扣着“人工智能”和“人类心智”这一重点，给了我们从历史、哲学等多方面审视“人工智能”这一概念的绝佳契机。因此阅读的过程于我而言是一次密集的思考，我本人此前对人类发展和西方哲学就有着兴趣和少许了解，这次在作者的专业背景引导下，重新思考这些领域对我们身处专业本身议题的潜移默化的影响，实在是一次难得的经历。</p>
<p>本书所要着眼的关键虽然是“人工智能”，但在作者眼里，“真正的”人工智能必然不能缺乏人类心智，因此本书用大量篇幅讨论了所谓“人类心智”。这篇文字将围绕“人类心智”，记录作者的关键论点，以及我对相应观点的个人思索。</p>
<h3 id="一人工智能和人类心智">一、人工智能和人类心智</h3>
<p>人工智能自从大数据驱动的神经网络重获生机、AlphaGo在围棋这一传统困难的领域战胜人类后重新在公众间引起重大轰动，而不明就里的媒体狂热地给2016或是2017年冠以“AI元年”的称呼，一时间举国上下尽被AI相关资讯占据，当然此时此刻与之平分秋色的是年初在公众中突然火爆的区块链——这便是媒体叙事对当代人认识的引领与改变——而所谓“叙事”本身也是人类心智的一个议题，后文还将涉及。</p>
<p>但是事实上，人工智能伴随着计算机本身一同出现，在计算机之父图灵发表他对于通用计算机器的论文的同时他就提出了“人工智能”这一设想，同样著名的“图灵测验”（也即“模仿游戏”，也将在后文涉及）也在同时产生。可以说，人工智能在某种程度上也是计算机发展所一直追寻的目标，而人工智能本身的发展历史和研究人员对人工智能的界定与认识也反映出了计算机的发展历程。原书作者本身即为人工智能相关研究人员之一，他从幼年在影视作品中看到的机器人形象得到激励，因此走上了这样一条专业道路，而他的博士论文则是构建一个被称为“普罗米修斯”的能够诊断黄疸的专家系统。在转而研究专家系统之前，人工智能经历了美好的幻想年代，尽管那时计算机的发展还太不成熟，但人们对最原初的“人工智能”的理解是真正的智能，是和人类“一样”的智能，但这一目标太过宏大，当时所能做的却只是用逻辑去赋予计算机“智慧”，也就是基于逻辑推断给出结果的“智能机器”，专家系统也正是这样一种装置，它处理信息、根据已有的知识和逻辑判断过程给出意见，但正如作者所说，它在诊疗的过程中无法认识到自己面对的是“病人”，无法明白“病人”的思想、愿望、恐惧，它没有“意识”，它无法意识到自己在“思考”，它只是一具僵尸。</p>
<p>在作者眼里，这与他所认识的真正的、理想中的“人工智能”相去太远，他关注于如何赋予机器以“意识”，但在学界人们却极端忽视对“意识”的讨论，于是他在失望中离开了学术界，并在业界工作中私下继续自己的研究，同时转向了哲学领域——用作者的话说，这是“大多数工程师和科学家都认为是最浪费时间和精力的领域”。</p>
<p>然而就我个人而言，我十分认同作者对哲学的看法——它可以用历史上最聪明的思想家丰富的思想滋养年轻的心灵。在转系前到刚刚转系后的日子里，我总是被对于人生意义的思考所困扰，我不知道自己该选择怎样的道路，不知道自己该如何面对选择的必然代价，这时我转向了哲学，希望能从中得到对迷茫的指点。可惜的是转系后由巨大的课程差异带来的学业压力迫使我放弃了“在闲暇时阅读哲学书籍”的想法。所幸当时了解到的一些基本概念对我现在阅读这本书多少有所助益，而本书中对于一些哲学观点的论述也丰富了我的认识。</p>
<p>如前所述，“意识”成为了作者眼中人工智能必须拥有的东西，而意识本身则是难以研究的——它涉及到“感质”等主观内容，因而无法用传统的客观科学方法去捉摸，何况对于“意识”的本质的思考更是千年来哲学争论不休的问题，即二元论与一元论的争端。如果认为意识和物质来源于不同本原，即二元论，则人类的意识是否是一种如软件般存在的编码？是否可以通过编程上载到数字生命中？而如果认为意识来源于物质，即一元论，在已经证明了“逻辑本身是有限制的”前提下，又该用什么方法制造真正拥有人类心智的人工智能？</p>
<p>意识就是人类心智，要研究拥有人类心智的人工智能，则不可能脱开对人类心智的探讨。</p>
<h3 id="二人类心智及其发展历程">二、人类心智及其发展历程</h3>
<p>开门见山，我希望在一开头就先说明人类的心智到底是什么，或者说心智到底拥有哪些独特特征，以使人类区别于其他万物。作者将人类心智的创造方式归为“四元素”：拟人化，叙事，二元论思维方式，隐喻。而在此之上，还有真正让人类更为独特、更为理性的第五元素，也即“自我意识”。下文将对这五大特征进行描述，也包括人类如何从猿类演化出了这些特征。</p>
<h4 id="一拟人化">（一）拟人化</h4>
<p>拟人化，顾名思义是对非人物体的描述赋予了人的特质，如对着宠物说话，踢树发泄怒火，甚至于我们语言中的“足球把玻璃打碎了”等。而拟人化实际上就是所谓“共情”，我们想象着其他人、其他动物甚至其他无生命的物体拥有了和我们一样的感情和思维，我们用我们自己的思维去预测、判断他们的行为模式，这就是拟人化的背后逻辑。</p>
<p>共情和拟人化是何以在演化中进入了我们的心智的？根据“个体发育复现了种系发育”的理论，即将认知与行为相结合，通过观察行为可以得出认知过程的理论，我们可以观察到幼儿在4岁后拥有了共情的能力，他能够意识到其他人也有和自己一样的思考和感情，这被称为“心理理论”。这一能力的优势在于，作为群居动物，有能力预测他人行为的人将具有更强的社会能力，从而在自然选择中占据优势，而这一步发生的时间是在旧石器时代。更进一步，我们在拥有共情的能力后，偶然的基因变异赋予了人类产生语言的能力，这种能力是在基因变异的基础上从生物学角度建立在大脑的生物结构上的，也就是所谓“语言的硬件”，而不仅仅是人类在后天教育中学会的。最初的语言是一种“社会语言”，只能够用来表述社会活动，但这极大地增强了人类的社交能力和合作能力，终于拥有这种变异的人凭借巨大的演化优势淘汰了不会语言的人，这一时间点大概是在距今15万年前。</p>
<p>随后经过十万年快速进化，社会语言演化成了能够表达非社会信息的通用语言，这种语言能够用来描述工具制造过程，能够用来记录知识，能够用来表达人类的思考，能够用来谈论动物行为、狩猎等信息，利用通用语言，人类的智能也迅速进化，促成了通用智能的产生。所谓通用智能就是能够广泛适用于不同情境的智能，而非像直立人一样只能打造特定工具的智能，这意味着人类随后将能够创造艺术、宗教和科学。对应的，因为人类已经能讨论动物行为，就产生了对动物的拟人化，人们用自己的行为模式去预测动物行为，由此可以伏击猎物，这提升了人类的生存能力，而广泛的拟人化就此进入了人类心智。</p>
<p>这种对万事万物的拟人化渗透于全人类的基因中，对于动物植物和山河大地的拟人描述可见于各种文明的神话传说中，对于原始的人类而言，人类社会和自然世界从来不存在割裂，我们只有一个世界，一个包容了人类和其他自然万物的世界，因此一切对超自然的猜测也是拟人化的，闪电和打雷都是天神为之。而万物一体的概念让我想起中国古人所追求的“天人合一”之境，也许这种人和自然交织相融的状态因为符合人类原始的本能而给人以心灵慰藉。</p>
<h4 id="二叙事">（二）叙事</h4>
<p>叙事，这个词汇我在哲学和文学相关论述中经常看到，但未曾很好地理解其含义。这里，根据作者的长篇幅叙述，我将本书中的叙事理解为人类用连贯语言构建情境、描述行为和事件的能力和行为。</p>
<p>人类的记忆是不精准、不连续的，我们所谓的记忆仅仅是在特定瞬间的对特定主体的记忆片段，而非对完整现场和完整过程的精确记录。因此当我们要复述记忆时，不可避免需要通过某种虚构能力去弥合记忆碎片之间的沟壑，并努力给出一个符合逻辑的过程，这一点事实上是我们的心智在不知不觉中完成的。写到这里，我想起一部布拉德·皮特主演的电影《记忆碎片》，主人公由于大脑损伤无法形成新的记忆，只能靠照片当做记忆的载体，而故事就建构在他根据这些零碎的照片和心智的叙事能力虚构出的截然不同的对过去经历的“回忆”之上。</p>
<p>叙事能力的演化优势可能来源于人类在社交中的讲述需求。凭借叙事，人类得以形成自传记忆，我们所经历的记忆碎片藉由叙事形成一个完整的故事，当别人问起我们是谁时，我们可以用这个故事来解释我们的一切，这大大增强了原始人类获得同伴认可的能力。</p>
<h4 id="三二元论思维方式">（三）二元论思维方式</h4>
<p>所谓二元论，就是认为在现实的世界之外还存在另一个世界，这个世界被认为是形式上的或观念上的。举个例子，当你拿着一个苹果，苹果本身的存在是现实的存在，而我们通过视觉、触觉、味觉等认识到的苹果则是我们观念中的苹果。但是这种二元的分裂并没有导致我们在认识世界时出现困难，因为通用智能使我们本能地认为真实地表现就是真实本身。</p>
<p>二元思维长期以来影响这人类对自己的心智的认识。基于二元论，身体是实在的存在，是符合现实世界规律的，而精神或灵魂是非物质的，是独立于肉体的存在。因此在宗教和神话中常常出现对复活和死后世界的描绘，在基督教中，也认为身体的死亡是永恒的，但灵魂则会前往其他世界。当然这也带来了所谓“身心问题”，即物质的大脑如何制造了非物质的思想，或者非物质的思想如何驱使物质的身体行动。对于二元或一元的争论至今仍未解决。</p>
<h4 id="四隐喻">（四）隐喻</h4>
<p>如前所述，叙事可以将我们的记忆碎片连接成故事从而进行交流，可以说人类使用叙事来感受其他人的经历。而隐喻则是人类的另一种工具，我们通过叙事来感受，通过隐喻来思考。隐喻背后的逻辑是一种联想和类比，我们用已经认识的事务去类比未知或尚不了解的事务，由此增强我们的思考能力和对世界的认知力。在这种心智本能下，我们不用隐喻几乎无法思考。</p>
<p>这一点尤其表现在我们对自身的认识上。人类认识自身的意图从未中断，但这种认识往往基于“范式”，我们倾向于用当时的科技产物来类比我们自身。最早的隐喻是泥土，在各大文明中都有人类来自于天神用泥土捏制的人偶，如中国的女娲造人、希腊的普罗米修斯等。随后在阿基米德时代，通过风力和水力驱使的大型机器问世，对人的隐喻变成了由体液驱动的机器。之后是由笛卡尔提出的齿轮、弹簧驱动的机器，在电被发现和电报等出现后，隐喻变成了电力机器，直到计算机的发明，人脑就成了“电脑”。</p>
<p>隐喻在计算机领域其实还有一个著名的应用，但我们在教材中似乎并没有见到过对这一点的提及。图灵提出的“图灵测试”的原型其实就是所谓“模仿游戏”，内容就是一男一女和裁判三人分别处于三个房间，裁判需要问问题并根据两个房间给出的回答判断哪个是男人哪个是女人，而男人要尽量表现得像女人以混淆裁判，女人则需要尽量表现得像男人来抵消男人对裁判的影响。将游戏中的女人换成机器，就变成了“图灵测试”，这本身就是一个隐喻。更深层次的隐喻则是，图灵本身是一名同性恋，而“模仿游戏”本身的寓意就是在性别问题上的掩饰以误导社会，很难不把这层含义和图灵本人的身份相联系，不论图灵当时利用这个游戏作为隐喻是否是有意为之。而理解这一点后，我也更能明白为何那部关于图灵的电影要起名为《模仿游戏》了。</p>
<h4 id="五自我意识">（五）自我意识</h4>
<p>前面四种心智的特征都表征着人类在演化过程中本能的痕迹，而自我意识则完全相反，它给了我们超越自我本能、思考抽象与绝对的能力，它让我们能够暂时脱离主观意识，作为一种反射机制，能够察觉到我们自己正在思考。凭借这种能力，我们得以独立于自身看待自己、反思自己，从而脱离隐喻给我们带来的混淆，并且看到自身的局限进而改变自身。根据控制论，这种机制是一种反馈循环，那么自我意识就是大脑中神经通路将信息传递回自身的递归过程。</p>
<p>对于自我意识的探讨长期存在于哲学界。一方面，我们凭借自我意识能够意识到自我，这才产生了这种思考，或者说自我意识本身又产生了对自己的思考；另一方面，自我意识希望能够明白自我意识到底来源于何处，这又牵扯到了二元论和一元论的问题，即它是由大脑的某种生物特性产生的，还是它根本就独立于物质的大脑，是一种非物质的存在？尽管充满争议，但科学还是在一元论的基础上发展起来了，但这事实上是一种反本能的思想，但也许正是依赖这一反本能的突破，人类才在可能存在的大量智慧生物中脱颖而出，因为其他星球的智慧物种可能囿于二元论思维，无法达到我们的科技水平——这在某种意义上指向了强人择原理，似乎这个宇宙就是为了人类的诞生而存在。这种想法是疯狂但有趣的，这样的思考给我们的眼界也是远超出死盯着现实狭隘领域的。</p>
<p>人类的这种对认识自我的渴望一直驱动着我们，而解开这个谜团的最好的办法就是创造像我们一样的事物。很难说人类的创造物背后没有这种潜移默化的驱动力，还记得刘云浩老师曾讲过，人类的一切工具都是对自身的延伸，石斧是对手臂的延伸，而计算机则是对人类智慧的延伸，这一切都指向最终的对于整个的人类自身的延伸，也即以我们自身形象创造的、具有智慧的人造物，或许这就是计算机乃至人工智能被创造的背后动机。</p>
<h3 id="三计算机的过去和未来">三、计算机的过去和未来</h3>
<p>如果要追溯计算机的根源，甚至可以达到亚里士多德。他提出的演绎法指出，给定一个前提，演绎的推理就必然是对的，此外逻辑方法还有归纳、溯因等，而这三种方法构成了计算机的逻辑推理过程，计算机的运行就可以被归结于三步：输入数据或对事物的观察，使用前述的逻辑推理，最后产出结果。</p>
<p>17世纪帕斯卡发明机械计算机器Pascsline，尽管这种机械与现当代的计算机概念几乎全不相似，但一般来讲，人们仍将其视为现代信息学起源标志之一。帕斯卡是当时法国著名的数学家、物理学家，而其创造很难与时代背景撇清关系——当时正值欧陆理性主义占据主流，这种观点认为原则上所有知识都可以通过单纯推理得到，这也激励帕斯卡设想，“是否可以利用纯粹机械的装置，来代替人类的思考和记忆”。随后1801年提花织布机的发明和用打孔卡记录纹样，和后世纸带计算机不谋而合。而19世纪初巴贝奇发明的差分机则是现代数字计算机的真正前兆，于此同时，他的合作伙伴，拜伦的女儿阿达则成为了世界上第一个程序员。
随着电和真空电子管的发明，真正的电子计算机终于得以问世。世界上第一台模拟电子计算机于1930年问世，1943年用于破译德军ENIGMA密码的计算机“巨人”诞生，而第一台通用的、全电子的计算机ENIAC则在1946年问世。1950年，图灵描述了“图灵测试”，第一台基于冯诺依曼结构的计算机EDVAC也在宾夕法尼亚大学诞生。</p>
<p>从1950年后，计算机基本都遵循了冯诺依曼体系，但此时使用真空管的计算机仍然庞大，只有大型机构才负担得起。1956年，达特茅斯会议召开，“人工智能”一词被首次提出，可以说人工智能的提出几乎与计算机的诞生处于同一时代。随后1957年艾伦·纽厄尔和赫伯特·西蒙就发明出了通用问题求解系统，1958年麦卡锡发明LISP语言专用于人工智能编程。60年代，晶体管替代了真空管，计算机体积大幅减小，FORTRAN等高级语言也被发明出来，计算机逐步变得易用。60年代中期，晶体管问世，集成电路的发明促成了小型机的出现，计算机开始走向市场，70年代LSI和VLSI进一步导致计算机进入普通人的生活。但与此同时，人工智能由于感知器和神经网络受到批评进入第一次低谷，直到80年代专家系统和多层神经网络问世，带来了人工智能的一次回暖。与此同时，80年代互联网诞生，万维网也在1989年由伯纳斯-李发明，随后90年代PC出现，计算机走入个人家庭，而且费用低廉，专家系统由于费用高昂、难以维护，导致经费下降，人工智能遇到第二次低谷。直到新近，随着算力提升，数据驱动的统计机器学习和深度学习终于再次点燃了公众对人工智能的热情。而计算机也变得更加微型、智能，各种新型计算平台层出不穷，普适计算、云计算进入日常生活，网络更是将万物联结一体。</p>
<p>就现实结果而言，计算机已经极大地改变了人类的世界。从二元论角度看，计算机本身的体系结构正是硬件软件分离，而在其影响下的现代社会人类也变成了生活在两个世界的生物：物质的、原子的世界，和比特的、信息的世界。那么未来呢？计算机演化的方向正如它被设计制造的初衷一般，一定会指向和我们一样的智慧人造物，但是这种人工智能会遵循二元论的形式吗？答案应该为否，因为作者指出，神经科学已然证明脱离身体的心智是不存在的，要想创造人工意识，身体是其必要不充分条件。</p>
<p>但不论如何，即使没有“意识”，即使只是一台智能的“哲学僵尸”，智能机器也终将有一天比人类更为“智能”。到了那时，新的问题是我们能否信任它们，更进一步，那时我们是否要选择放弃人性而与其融合呢？这也许会是尚可区分人类和智能机器时，最后也是最临界的一个问题。</p>
<hr />
<p>注：原文作于2018年3月19日，为“计算机系统结构”课程作业</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>历史</tag>
        <tag>计算机</tag>
        <tag>人类心智</tag>
      </tags>
  </entry>
  <entry>
    <title>《极乐迪斯科》游戏短评</title>
    <url>/2020/05/17/%E3%80%8A%E6%9E%81%E4%B9%90%E8%BF%AA%E6%96%AF%E7%A7%91%E3%80%8B%E6%B8%B8%E6%88%8F%E7%9F%AD%E8%AF%84/</url>
    <content><![CDATA[<blockquote>
<p>本短评原载于<a
href="https://steamcommunity.com/profiles/76561198100631292/recommended/">本人的Steam游戏评测</a>。有改动。</p>
</blockquote>
<p>真正的好游戏。下载后连续玩了两天半通关，根本无法拒绝其强大的魅力。作为解谜游戏，主线稳定清晰，剧情波折起伏，指向性明确，通关动力充足；支线丰富，有较多隐藏任务和剧情，触发方式和条件多样，任务时间安排自由度高；地图范围足够大，循序开放，有利于在高自由度下协助玩家集中注意力；扔骰子检定机制引入随机性，一定程度上丰富了可玩性，兼具桌游特性。同时作为RPG游戏，技能学习引入成长性，符合角色扮演模式，有限的思维阁空间迫使玩家在探索和利用间做出抉择，增加了因玩家而异的个性化。</p>
<span id="more"></span>
<p>游戏世界观新奇但与现实呼应紧密，熟悉二十世纪苏联历史的玩家，尤其考虑到游戏作者的爱沙尼亚背景，不难从游戏的历史介绍中看出对现实的呈现和反思——更重要的是，游戏把反思的权利较大程度上交给了玩家本人，这是一种难得的“自由度”，一种对游戏世界观和价值观建构权利的自由度，就这一点而言，其冲击远远超过地图或支线任务的自由度——二者完全不在同一维度，这种价值的自由度我几乎未在其他解谜/RPG类游戏中体验过。玩家在选择面对游戏世界历史的zz立场同时，也在选择自己的人生立场：等待末日，或百无聊赖，或摇滚巨星，角色面对人生的态度也全由玩家选择。为什么一个警探不能在勤勉破案的同时，唱歌跳舞，组建club呢？某种意义上，这或许是游戏作者对自己人生经历的投射。</p>
<p>游戏风格化程度很高，作画风格暂且不论，disco、涂鸦在游戏中都可以触发支线剧情，当代艺术形式的隐喻贯穿始终，总有一些选项给予玩家足够的展现个性的机会，伴着阳极音乐拉同伴一起跳舞，面对空墙壁突发艺术灵感，在悲剧过后的广场上点燃混着血的重油涂鸦，这正是“酷”，正是“极乐”和“disco”本身。此外还有脑科学的隐喻，mainframe仿佛蒸汽朋克般的前现代感，远方的真人接线员登录系统，在吸引艺术家的同时也给了工程和科学足够的关照。失败的游戏公司又无处不透露着对作者团队自身的揶揄，能扭曲光线的超高净值者又是怎样一种残酷的幽默。</p>
<p>游戏音乐来自英国摇滚乐队 <em><a
href="https://www.britishseapower.co.uk/">British Sea Power</a></em>
（Indie
Rock/Alt-rock/Post-punk/Post-rock），可以翻译为“不列颠海上力量”，但个人更倾向于“不列颠海军”，尤其是考虑到其首张专辑名为
<em><a
href="https://en.wikipedia.org/wiki/The_Decline_of_British_Sea_Power">The
Decline of British Sea
Power</a></em>（2003），让我想起日不落帝国二战后的衰落和瓦解。乐队组建于千禧初年，风格偏重后摇和氛围摇滚，格外凸显了继承自英伦摇滚的落寞感。不知道其在后摇/另类摇滚圈中知名度如何，可惜我在四年前听后摇时并没有踏足他们的作品。不论如何，看起来游戏作者联系到了这支乐队（或许是他们喜爱的乐队？），2019年该乐队为游戏创作乐谱，在2020年4月的BAFTA奖中，他们因本游戏中的作品获得“最佳音乐奖”<a
href="https://en.wikipedia.org/wiki/British_Sea_Power">^
1</a>。当然，游戏中充满反讽/自嘲的一点是，经常出现对摇滚的贬斥，和对“阳极音乐”的“吹捧”，的确，爱摇滚的人才会说摇滚已死，爱爵士的人才会说爵士已死，爱建筑的人才会说建筑已死。</p>
<p>最后，希望各位能在游戏中尽情探索，尽情挥洒个性，扮演现实中做不到的别人，或是完完全全自我投射。不论是滚青还是geek，只要心里有一个“酷”的幻想，就一定会在某处获得共鸣，深深沉浸在游戏塑造的Elysium里。</p>
<p>顺带一提，游戏里出现了不少法语和法国口音，耐人寻味。</p>
]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>评测</tag>
        <tag>解密游戏</tag>
        <tag>极乐迪斯科</tag>
        <tag>Disco Elysium</tag>
      </tags>
  </entry>
  <entry>
    <title>【转载】透彻理解交叉熵背后的直觉</title>
    <url>/2019/03/04/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E9%80%8F%E5%BD%BB%E7%90%86%E8%A7%A3%E4%BA%A4%E5%8F%89%E7%86%B5%E8%83%8C%E5%90%8E%E7%9A%84%E7%9B%B4%E8%A7%89/</url>
    <content><![CDATA[<blockquote><p>交叉熵（cross
entropy）是深度学习中常用的一个概念，一般用来求目标与预测值之间的差距。以前做一些分类问题的时候，没有过多的注意，直接调用现成的库，用起来也比较方便。最近开始研究起对抗生成网络（GANs），用到了交叉熵，发现自己对交叉熵的理解有些模糊，不够深入。遂花了几天的时间从头梳理了一下相关知识点，才算透彻的理解了，特地记录下来，以便日后查阅。</p>
<footer><strong>史丹利复合田</strong><cite><a href="https://blog.csdn.net/tsyccnh/article/details/79163834">一文搞懂交叉熵在机器学习中的使用，透彻理解交叉熵背后的直觉</a></cite></footer></blockquote>
<span id="more"></span>
<hr />
<p>作者：史丹利复合田 来源：CSDN
原文：https://blog.csdn.net/tsyccnh/article/details/79163834
版权声明：本文为博主原创文章，转载请附上博文链接！</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>交叉熵</tag>
        <tag>理论</tag>
        <tag>直觉</tag>
      </tags>
  </entry>
  <entry>
    <title>【转载】几种梯度下降方法和优化方法对比</title>
    <url>/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<p>我们在训练神经网络模型时，最常用的就是梯度下降，这篇博客主要介绍下几种梯度下降的变种（mini-batch
gradient descent和stochastic gradient descent），关于Batch gradient
descent（批梯度下降，BGD）就不细说了（一次迭代训练所有样本），因为这个大家都很熟悉，通常接触梯队下降后用的都是这个。这里主要介绍Mini-batch
gradient descent和stochastic gradient descent（SGD）以及对比下Batch
gradient descent、mini-batch gradient descent和stochastic gradient
descent的效果。</p>
<span id="more"></span>
<h1
id="part-i-梯度下降方法对比batch-gradient-descentmini-batch-gradient-descent-和-stochastic-gradient-descent">Part
I: 梯度下降方法对比——Batch gradient descent、Mini-batch gradient descent
和 stochastic gradient descent</h1>
<h2 id="一batch-gradient-descent">一、Batch gradient descent</h2>
<p>Batch gradient descent
就是一次迭代训练所有样本，就这样不停的迭代。整个算法的框架可以表示为：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">X = data_input</span><br><span class="line">Y = labels</span><br><span class="line">parameters = initialize_parameters(layers_dims)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_iterations): <span class="comment">#num_iterations--迭代次数</span></span><br><span class="line">    <span class="comment"># Forward propagation</span></span><br><span class="line">    a, caches = forward_propagation(X, parameters)</span><br><span class="line">    <span class="comment"># Compute cost.</span></span><br><span class="line">    cost = compute_cost(a, Y)</span><br><span class="line">    <span class="comment"># Backward propagation.</span></span><br><span class="line">    grads = backward_propagation(a, caches, parameters)</span><br><span class="line">    <span class="comment"># Update parameters.</span></span><br><span class="line">    parameters = update_parameters(parameters, grads)</span><br></pre></td></tr></table></figure>
<p>Batch gradient
descent的优点是理想状态下经过足够多的迭代后可以达到全局最优。但是缺点也很明显，就是如果你的数据集非常的大（现在很常见），根本没法全部塞到内存（显存）里，所以BGD对于小样本还行，大数据集就没法娱乐了。而且因为每次迭代都要计算全部的样本，所以对于大数据量会非常的慢。</p>
<h2 id="二stochastic-gradient-descent">二、stochastic gradient
descent</h2>
<p>为了加快收敛速度，并且解决大数据量无法一次性塞入内存（显存）的问题，stochastic
gradient
descent（SGD）就被提出来了，SGD的思想是每次只训练一个样本去更新参数。具体的实现代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">X = data_input</span><br><span class="line">Y = labels</span><br><span class="line">permutation = <span class="built_in">list</span>(np.random.permutation(m))</span><br><span class="line">shuffled_X = X[:, permutation]</span><br><span class="line">shuffled_Y = Y[:, permutation].reshape((<span class="number">1</span>, m))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_iterations):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, m):  <span class="comment"># 每次训练一个样本</span></span><br><span class="line">        <span class="comment"># Forward propagation</span></span><br><span class="line">        AL,caches = forward_propagation(shuffled_X[:, j].reshape(-<span class="number">1</span>,<span class="number">1</span>), parameters)</span><br><span class="line">        <span class="comment"># Compute cost</span></span><br><span class="line">        cost = compute_cost(AL, shuffled_Y[:, j].reshape(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        <span class="comment"># Backward propagation</span></span><br><span class="line">        grads = backward_propagation(AL, shuffled_Y[:,j].reshape(<span class="number">1</span>,<span class="number">1</span>), caches)</span><br><span class="line">        <span class="comment"># Update parameters.</span></span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate)</span><br></pre></td></tr></table></figure>
<p>如果我们的数据集很大，比如几亿条数据，num_iterationsnum_iterations
基本上
设置1，2，（10以内的就足够了）就可以。但是SGD也有缺点，因为每次只用一个样本来更新参数，会导致不稳定性大些(可以看下图（图片来自ng
deep learning 课），每次更新的方向，不想batch gradient
descent那样每次都朝着最优点的方向逼近，会在最优点附近震荡）。因为每次训练的都是随机的一个样本，会导致导致梯度的方向不会像BGD那样朝着最优点。</p>
<p>注意：代码中的随机把数据打乱很重要，因为这个随机性相当于引入了“噪音”，正是因为这个噪音，使得SGD可能会避免陷入局部最优解中。</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/1.jpg" class="" title="sgd">
<p>下面来对比下SGD和BGD的代价函数随着迭代次数的变化图：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/3.jpg" class="" title="对比">
<p>可以看到SGD的代价函数随着迭代次数是震荡式的下降的（因为每次用一个样本，有可能方向是背离最优点的）</p>
<h2 id="三mini-batch-gradient-descent">三、Mini-batch gradient
descent</h2>
<p>mini-batch gradient descent 是batch gradient descent和stochastic
gradient descent的折中方案，就是mini-batch gradient
descent每次用一部分样本来更新参数，即
batch_sizebatch_size。因此，若batch_size=1batch_size=1
则变成了SGD，若batch_size=mbatch_size=m 则变成了batch gradient
descent。</p>
<p>batch_sizebatch_size通常设置为2的幂次方，通常设置2，4，8，16，32，64，128，256，5122，4，8，16，32，64，128，256，512（很少设置大于512）。因为设置成2的幂次方，更有利于GPU加速。现在深度学习中，基本上都是用
mini-batch gradient descent，（在深度学习中，很多直接把mini-batch
gradient descent（a.k.a stochastic mini-batch gradient
descent）简称为SGD，所以当你看到深度学习中的SGD，一般指的就是mini-batch
gradient descent）。下面用几张图来展示下mini-batch gradient
descent的原理（图片来自ng deep learning 课）：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/4.jpg" class="" title="mini-batch">
<p>下面直接给出mini-batch gradient descent的代码实现：</p>
<ol type="1">
<li>首先要把训练集分成多个batch</li>
</ol>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: random_mini_batches</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_mini_batches</span>(<span class="params">X, Y, mini_batch_size = <span class="number">64</span>, seed = <span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Creates a list of random minibatches from (X, Y)</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input data, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true &quot;label&quot; vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    mini_batch_size -- size of the mini-batches, integer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    np.random.seed(seed)            <span class="comment"># To make your &quot;random&quot; minibatches the same as ours</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]                  <span class="comment"># number of training examples</span></span><br><span class="line">    mini_batches = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 1: Shuffle (X, Y)</span></span><br><span class="line">    permutation = <span class="built_in">list</span>(np.random.permutation(m))</span><br><span class="line">    shuffled_X = X[:, permutation]</span><br><span class="line">    shuffled_Y = Y[:, permutation].reshape((<span class="number">1</span>,m))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.</span></span><br><span class="line">    num_complete_minibatches = m//mini_batch_size <span class="comment"># number of mini batches</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_complete_minibatches):</span><br><span class="line">        mini_batch_X = shuffled_X[:, k * mini_batch_size: (k + <span class="number">1</span>) * mini_batch_size]</span><br><span class="line">        mini_batch_Y = shuffled_Y[:, k * mini_batch_size: (k + <span class="number">1</span>) * mini_batch_size]</span><br><span class="line">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Handling the end case (last mini-batch &lt; mini_batch_size)</span></span><br><span class="line">    <span class="keyword">if</span> m % mini_batch_size != <span class="number">0</span>:</span><br><span class="line">        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]</span><br><span class="line">        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]</span><br><span class="line">        mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">        mini_batches.append(mini_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mini_batches</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>下面是在model中使用mini-batch gradient descent 进行更新参数</li>
</ol>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">seed = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_iterations):</span><br><span class="line">    <span class="comment"># Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch</span></span><br><span class="line">    seed = seed + <span class="number">1</span></span><br><span class="line">    minibatches = random_mini_batches(X, Y, mini_batch_size, seed)</span><br><span class="line">    <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line">        <span class="comment"># Select a minibatch</span></span><br><span class="line">        (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line">        <span class="comment"># Forward propagation</span></span><br><span class="line">        AL, caches = forward_propagation(minibatch_X, parameters)</span><br><span class="line">        <span class="comment"># Compute cost</span></span><br><span class="line">        cost = compute_cost(AL, minibatch_Y)</span><br><span class="line">        <span class="comment"># Backward propagation</span></span><br><span class="line">        grads = backward_propagation(AL, minibatch_Y, caches)</span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate)</span><br></pre></td></tr></table></figure>
<p>下面来看mini-batch gradient descent 和 stochastic gradient descent
在下降时的对比图：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/2.jpg" class="" title="gd">
<p>下面是mini-batch gradient descent的代价函数随着迭代次数的变化图：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/2.jpg" class="" title="gd">
<p>从图中能够看出，mini-batch gradient descent
相对SGD在下降的时候，相对平滑些（相对稳定），不像SGD那样震荡的比较厉害。mini-batch
gradient descent的一个缺点是增加了一个超参数 batch_sizebatch_size
，要去调这个超参数。 以上就是关于batch gradient descent、mini-batch
gradient descent 和 stochastic gradient descent的内容。</p>
<h1
id="part-ii-深度学习中优化方法momentumnesterov-momentumadagradadadeltarmspropadam">Part
II: 深度学习中优化方法——momentum、Nesterov
Momentum、AdaGrad、Adadelta、RMSprop、Adam</h1>
<p>我们通常使用梯度下降来求解神经网络的参数，关于梯度下降前面一篇博客已经很详细的介绍了（几种梯度下降方法对比）。我们在梯度下降时，为了加快收敛速度，通常使用一些优化方法，比如：momentum、RMSprop和Adam等。这篇博客主要介绍：</p>
<ul>
<li>指数加权平均（Exponentially weighted average）</li>
<li>带偏差修正的指数加权平均（bias correction in exponentially weighted
average）</li>
<li>Momentum</li>
<li>Nesterov Momentum</li>
<li>Adagrad</li>
<li>Adadelta</li>
<li>RMSprop</li>
<li>Adam</li>
</ul>
<p>在介绍这几种优化方法之前，必须先介绍下
<strong>指数加权平均（Exponentially weighted average）</strong>
，因为这个算法是接下来将要介绍的三个算法的重要组成部分。</p>
<h2 id="一-指数加权平均exponentially-weighted-average">一、
指数加权平均（Exponentially weighted average）</h2>
<p>指数加权平均是处理时间序列的常用工具，下面用一个例子来引入指数加权平均的概念。下图是一个180天的气温图（图片来自ng
Coursera deep learning 课）：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/8.jpg" class="" title="ewa">
<p>如果我们想找一条线去拟合这个数据，该怎么去做呢。我们知道某一天的气温其实和前几天（前一段时间）相关的，并不是一个独立的随机事件，比如夏天气温都会普遍偏高些，冬天气温普遍都会低一些。我们用<span
class="math inline">\([θ1,θ2,...,θn]\)</span>表示第1，2，…，n天的气温，我们有：
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/9.jpg" class="" title="temperature"></p>
<p>根据上面的公式我们能够画出这条线，如下图所示（图片来自ng deep
learning课）：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/10.jpg" class="" title="fit">
<p>下面来正式的看一下 指数加权平均（Exponentially weighted average）
的定义：</p>
<p><span class="math display">\[V_t=βV_(t−1)+(1−β)θ_t\]</span></p>
<p>可以认为 <span class="math inline">\(V_t\)</span> 近似是 <span
class="math inline">\(\frac{1}{1−β}\)</span>
天的平均气温，所以上面公式设置了 <span
class="math inline">\(β=0.9\)</span> ，当 <span
class="math inline">\(t&gt;10\)</span> 时，则可以认为 <span
class="math inline">\(V_t\)</span> 近似是它前10天的平均气温。
比如，按照上面的公式，我们计算 <span
class="math inline">\(V_{100}\)</span> ，</p>
<p><span class="math display">\[
\begin{aligned}V_{100}&amp;=0.1θ_{100}+0.9V_{99}    \\
        &amp;=0.1θ_{100}+0.9(0.9V_{98}+0.1θ_{99})    \\
        &amp;=0.1θ_{100}+0.9∗0.1θ_{99}+0.9^2V_{98}    \\
        &amp;=0.1θ_{100}+0.9∗0.1θ_{99}+0.9^2(0.9V_{97}+0.1θ_{98})    \\
        &amp;=0.1θ_{100}+0.9∗0.1θ_{99}+0.9^2∗0.1θ_{98}+0.9^3V_{97}    \\
        &amp;=0.1θ_{100}+0.9∗0.1θ_{99}+0.9^2∗0.1θ_{98}+0.9^3∗0.1θ_{97}+0.9^4V_{96}    \\
        &amp;=....    \\
        &amp;=0.1θ_{100}+0.9∗0.1θ_{99}+0.9^2∗0.1θ_{98}+0.9^3∗0.1θ_{97}+...+0.9^{99}∗0.1θ_1+0.9^{100}V_0
\end{aligned}
\]</span></p>
<p>从上面的公式能够看出，实际上是个指数衰减函数。<span
class="math inline">\(0.9^{10} ≈ 0.35 ≈
\frac{1}{e}\)</span>，所以这个就解释了上面的 <span
class="math inline">\(\frac{1}{1−β}\)</span>。</p>
<p>（ps：关于这一点为什么要用0.35及 <span
class="math inline">\(\frac{1}{e}\)</span>，我是不太明白的，搜了下资料也没找到更好的资料，希望路过的有知道的大神，在下面评论交流。）</p>
<p>下面再看下 β 取不同值时，曲线的拟合情况（图片来自ng deep
learning课）：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/11.jpg" class="" title="fit">
<p>从上图能够看出：</p>
<p>当 β 较大时（β=0.98
相当于每一点前50天的平均气温），曲线波动相对较小更加平滑（绿色曲线），因为对很多天的气温做了平均处理，正因为如此，曲线还会右移。
同理，当 β 较小时（β=0.5
相当于每一点前2天的平均气温），曲线波动相对激烈，但是它可以更快的适应温度的变化。
下面直接看实现指数加权平均（Exponentially weighted
average）的伪代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">V0 = 0</span><br><span class="line">repeat</span><br><span class="line">&#123;</span><br><span class="line">    get next theta_t</span><br><span class="line">    V_theta = beta * V_theta + (1 - beta)* theta_t</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关于指数加权平均的优缺点： 当 β=0.9β=0.9
时，我们可以近似的认为当前的数值是过去10天的平均值，但是显然如果我们直接计算过去10天的平均值，要比用指数加权平均来的更加准确。但是如果直接计算过去10天的平均值，我们要存储过去10天的数值，而加权平均只要存储Vt−1Vt−1一个数值即可，而且只需要一行代码即可，所以在机器学习中用的很多。</p>
<h2
id="二带偏差修正的指数加权平均bias-correction-in-exponentially-weighted-average">二、带偏差修正的指数加权平均（bias
correction in exponentially weighted average）</h2>
<p>上一节中介绍了指数加权平均，用的公式是： <span
class="math display">\[V_t=βV_{t−1{+(1−β)θ_t\]</span></p>
<p>我们想得到下图中的“绿线”，实际上我们得到的是下图中的“紫线”。对比这两条线，能够发现在“紫线”的起点相比“绿线”非常的低，也就是说
指数加权平均 不能很好地拟合前几天的数据，因此需要
偏差修正，解决办法就是，再令<span
class="math inline">\(V_t=\frac{V_t}{1-\beta^t}\)</span>. 因此，
带偏差修正的指数加权平均（bias correction in exponentially weighted
average） 公式为：</p>
<p><span class="math display">\[V_t=βV_{t−1}+(1−β)θ_t\]</span> <span
class="math display">\[V_t=\frac{V_t}{1-\beta^t}\]</span></p>
<p>当 <span class="math inline">\(t\to\infty\)</span> 时，<span
class="math inline">\(\beta_t\to0\)</span>，这样在后期 Vt 就和
没有修正的指数加权平均一样了.</p>
<blockquote>
<p>在机器学习中，多数的指数加权平均运算并不会使用偏差修正。因为大多数人更愿意在初始阶段，用一个捎带偏差的值进行运算。不过，如果在初试阶段就开始考虑偏差，指数加权移动均值仍处于预热阶段，偏差修正可以做出更好的估计。</p>
</blockquote>
<p>介绍完上面的准备知识，下面正式进入正题。</p>
<h2 id="三动量momentum">三、动量（momentum）</h2>
<p>        我们使用SGD（stochastic mini-batch gradient
descent，深度学习中一般称之为SGD）训练参数时，有时候会下降的非常慢，并且可能会陷入到局部最小值中，如下图所示（图片来自李宏毅《一天搞懂深度学习》）。</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/12.jpg" class="">
<p>下面给出动量（momentum）的公式：</p>
<p>动量的引入就是为了加快学习过程，特别是对于高曲率、小但一致的梯度，或者噪声比较大的梯度能够很好的加快学习过程。动量的主要思想是积累了之前梯度指数级衰减的移动平均（前面的指数加权平均），下面用一个图来对比下，SGD和动量的区别：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/13.jpg" class="">
<p>区别：
SGD每次都会在当前位置上沿着负梯度方向更新（下降，沿着正梯度则为上升），并不考虑之前的方向梯度大小等等。而动量（moment）通过引入一个新的变量
vv
去积累之前的梯度（通过指数衰减平均得到），得到加速学习过程的目的。</p>
<blockquote>
<p>最直观的理解就是，若当前的梯度方向与累积的历史梯度方向一致，则当前的梯度会被加强，从而这一步下降的幅度更大。若当前的梯度方向与累积的梯度方向不一致，则会减弱当前下降的梯度幅度。</p>
</blockquote>
<p>用一个图来形象的说明下上面这段话（图片来自李宏毅《一天搞懂深度学习》）：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/14.jpg" class="">
<p>下面给出动量（momentum）的公式：</p>
<p><span class="math display">\[\begin{aligned}
&amp;V_{dW}=βV_{dW}+(1−β)dW        \\
&amp;V_{db}=βV_{db}+(1−β)db          \\
&amp;W=W-\alpha V_{dW}, b=b-\alpha V_{db}\end{aligned}\]</span></p>
<p>β的值越大，则之前的梯度对现在的方向影响越大。β一般取值为0.5，0.9，0.99。ng推荐取值0.9。这个公式是ng的在Coursera课上给出的。</p>
<p>关于这个公式目前主要有<strong>两种形式</strong>，*一种是原论文里的公式：（原论文：<a
href="http://www.cs.toronto.edu/~hinton/absps/momentum.pdf">On the
importance of initialization and momentum in deep learning</a>）</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/15.jpg" class="">
<p>使用这个公式的有： 1、 goodfellow和bengio的《deep learning》书：（<a
href="http://www.deeplearningbook.org/contents/optimization.html">8.3.2节
momentum</a>） <img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/16.jpg" class=""> 2、
CS231N课（链接：http://cs231n.github.io/neural-networks-3/）： 3、
keras： 4、Intel的chainer框架</p>
<p>*第二种是类似ng给的：</p>
<p>1、论文《An overview of gradient descent optimization algorithms》：
2、TensorFlow源码里的版本（链接：<a
href="tensorflow/tensorflow/python/training/momentum.py"></a>）：
3、pytorch源码里的版本（链接：<a
href="https://pytorch.org/docs/master/_modules/torch/optim/sgd.html#SGD"></a>
）：</p>
<p>4、当时修hinton的nn课时，hinton给出的版本与TensorFlow这个是一样的，链接见我的博客：</p>
<p>这个版本是和ng在课上给出的版本是一致的，只不过会影响下learning_rate的取值。
综上，应该是哪个版本都可以。大家根据自己的喜好使用。</p>
<p>由于我个人更喜欢ng/TensorFlow/pytorch那个形式，下面无论是代码还是伪代码我都会统一用ng的版本，下面给出momentum的伪代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">initialize VdW = 0, vdb = 0 //VdW维度与dW一致，Vdb维度与db一致</span><br><span class="line">on iteration t:</span><br><span class="line">    compute dW,db on current mini-batch</span><br><span class="line">    VdW = beta*VdW + (1-beta)*dW</span><br><span class="line">    Vdb = beta*Vdb + (1-beta)*db</span><br><span class="line">    W = W - learning_rate * VdW</span><br><span class="line">    b = b - learning_rate * Vdb</span><br></pre></td></tr></table></figure>
<p>具体的代码实现为：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_velocity</span>(<span class="params">parameters</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Initializes the velocity as a python dictionary with:</span></span><br><span class="line"><span class="string">                - keys: &quot;dW1&quot;, &quot;db1&quot;, ..., &quot;dWL&quot;, &quot;dbL&quot;</span></span><br><span class="line"><span class="string">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters.</span></span><br><span class="line"><span class="string">                    parameters[&#x27;W&#x27; + str(l)] = Wl</span></span><br><span class="line"><span class="string">                    parameters[&#x27;b&#x27; + str(l)] = bl</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    v -- python dictionary containing the current velocity.</span></span><br><span class="line"><span class="string">                    v[&#x27;dW&#x27; + str(l)] = velocity of dWl</span></span><br><span class="line"><span class="string">                    v[&#x27;db&#x27; + str(l)] = velocity of dbl</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    L = <span class="built_in">len</span>(parameters) // <span class="number">2</span> <span class="comment"># number of layers in the neural networks</span></span><br><span class="line">    v = &#123;&#125;</span><br><span class="line">    <span class="comment"># Initialize velocity</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(L):</span><br><span class="line">        v[<span class="string">&quot;dW&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] = np.zeros(parameters[<span class="string">&quot;W&quot;</span> + <span class="built_in">str</span>(l+<span class="number">1</span>)].shape)</span><br><span class="line">        v[<span class="string">&quot;db&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] = np.zeros(parameters[<span class="string">&quot;b&quot;</span> + <span class="built_in">str</span>(l+<span class="number">1</span>)].shape)</span><br><span class="line">    <span class="keyword">return</span> v</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update_parameters_with_momentum</span>(<span class="params">parameters, grads, v, beta, learning_rate</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Update parameters using Momentum</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters:</span></span><br><span class="line"><span class="string">                    parameters[&#x27;W&#x27; + str(l)] = Wl</span></span><br><span class="line"><span class="string">                    parameters[&#x27;b&#x27; + str(l)] = bl</span></span><br><span class="line"><span class="string">    grads -- python dictionary containing your gradients for each parameters:</span></span><br><span class="line"><span class="string">                    grads[&#x27;dW&#x27; + str(l)] = dWl</span></span><br><span class="line"><span class="string">                    grads[&#x27;db&#x27; + str(l)] = dbl</span></span><br><span class="line"><span class="string">    v -- python dictionary containing the current velocity:</span></span><br><span class="line"><span class="string">                    v[&#x27;dW&#x27; + str(l)] = ...</span></span><br><span class="line"><span class="string">                    v[&#x27;db&#x27; + str(l)] = ...</span></span><br><span class="line"><span class="string">    beta -- the momentum hyperparameter, scalar</span></span><br><span class="line"><span class="string">    learning_rate -- the learning rate, scalar</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your updated parameters</span></span><br><span class="line"><span class="string">    v -- python dictionary containing your updated velocities</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    L = <span class="built_in">len</span>(parameters) // <span class="number">2</span> <span class="comment"># number of layers in the neural networks</span></span><br><span class="line">    <span class="comment"># Momentum update for each parameter</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(L):</span><br><span class="line">        <span class="comment"># compute velocities</span></span><br><span class="line">        v[<span class="string">&quot;dW&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] = beta * v[<span class="string">&quot;dW&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta) * grads[<span class="string">&#x27;dW&#x27;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)]</span><br><span class="line">        v[<span class="string">&quot;db&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] = beta * v[<span class="string">&quot;db&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] + (<span class="number">1</span> - beta) * grads[<span class="string">&#x27;db&#x27;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)]</span><br><span class="line">        <span class="comment"># update parameters</span></span><br><span class="line">        parameters[<span class="string">&quot;W&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] = parameters[<span class="string">&quot;W&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] - learning_rate * v[<span class="string">&quot;dW&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)]</span><br><span class="line">        parameters[<span class="string">&quot;b&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] = parameters[<span class="string">&quot;b&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)] - learning_rate * v[<span class="string">&quot;db&quot;</span> + <span class="built_in">str</span>(l + <span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">return</span> parameters, v</span><br></pre></td></tr></table></figure>
<h2 id="四nesterov-momentum">四、Nesterov Momentum</h2>
<p>Nesterov
Momentum是对Momentum的改进，可以理解为nesterov动量在标准动量方法中添加了一个校正因子。用一张图来形象的对比下momentum和nesterov
momentum的区别（图片来自：http://ttic.uchicago.edu/~shubhendu/Pages/Files/Lecture6_pauses.pdf）：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/17.jpg" class="">
<p>公式：</p>
<p><span class="math display">\[\begin{aligned}\\
v_{t+1}&amp;=\mu v_t - \varepsilon \nabla f(\theta_t + \mu v_t) \\
\theta_{t+1} &amp;= \theta_{t} + v_{t+1}\end{aligned}\]</span></p>
<blockquote>
<p>但是，我们仔细观察这个算法，你会发现一个很大的缺点，这个算法会导致运行速度巨慢无比，因为这个算法每次都要计算<span
class="math inline">\(\nabla_{\theta} \sum_i{L(f({x}^{i}; \theta +
\alpha v),
y^{i})}\)</span>，这个相当于又要把fp、bp走一遍。这样就导致这个算法的运行速度比momentum要慢两倍，因此在实际实现过程中几乎没人直接用这个算法，而都是采用了变形版本。</p>
</blockquote>
<p>变形版本：把上面的公式第一步代入第二步可以得到相同的公式：<span
class="math inline">\(w = w + {\beta}^2 V - (1+\beta)\alpha *
\nabla\)</span>。我这里直接使用keras风格公式了，其中 β 是动量参数，α
是学习率。</p>
<p><span class="math display">\[\begin{aligned}
V_{\mathrm{d}W} &amp;= \beta V_{\mathrm{d}W} - \alpha \mathrm{d}W \\
V_{\mathrm{d}b} &amp;= \beta V_{\mathrm{d}b} - \alpha \mathrm{d}b \\
W &amp;= W + \beta V \mathrm{d}W - \alpha \mathrm{d}W \\
b &amp;= b + \beta V \mathrm{d}b - \alpha \mathrm{d}b
\\\end{aligned}\]</span></p>
<blockquote>
<p>这样写的高明之处在于，我们没必要去计算 <span
class="math inline">\(∇_θ\)</span> 了，直接利用当前已求得的 <span
class="math inline">\(\mathrm{d}θ\)</span>
去更新参数即可。这样就节省了一半的时间。</p>
</blockquote>
<h2 id="五adagradadaptive-gradient">五、AdaGrad（Adaptive
Gradient）</h2>
<p>通常，我们在每一次更新参数时，对于所有的参数使用相同的学习率。而AdaGrad算法的思想是：每一次更新参数时（一次迭代），不同的参数使用不同的学习率。AdaGrad
的公式为：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/18.jpg" class="">
<blockquote>
<p>关于AdaGrad，goodfellow和bengio的《deep
learning》书中对此的描述是：在凸优化中，AdaGrad算法具有一些令人满意的理论性质。但是，在实际使用中已经发现，对于训练深度神经网络模型而言，从训练开始时累积梯度平方会导致学习率过早过量的减少。AdaGrad算法在某些深度学习模型上效果不错，但不是全部。</p>
</blockquote>
<h2 id="六adadelta">六、Adadelta</h2>
<p>Adadelta是对Adagrad的改进，主要是为了克服Adagrad的两个缺点（摘自Adadelta论文《AdaDelta:
An Adaptive Learning Rate Method》）：</p>
<ul>
<li>the continual decay of learning rates throughout training</li>
<li>the need for a manually selected global learning rate</li>
</ul>
<p>为了解决第一个问题，Adadelta只累积过去 w
窗口大小的梯度，其实就是利用前面讲过的指数加权平均</p>
<p>为了解决第二个问题，Adadelta最终的公式不需要学习率
α。Adadelta的具体算法如下所示（来自论文《AdaDelta: An Adaptive Learning
Rate Method》）</p>
<h2 id="七rmsproproot-mean-square-prop">七、RMSprop（root mean square
prop）</h2>
<p>RMSprop是hinton老爷子在Coursera的《Neural Networks for Machine
Learning》lecture6中提出的，这个方法并没有写成论文发表（不由的感叹老爷子的强大。。以前在Coursera上修过这门课，个人感觉不算简单）。同样的，RMSprop也是对Adagrad的扩展，以在非凸的情况下效果更好。和Adadelta一样，RMSprop使用指数加权平均（指数衰减平均）只保留过去给定窗口大小的梯度，使其能够在找到凸碗状结构后快速收敛。直接来看下RMSprop的算法（来自lan
goodfellow 《deep learning》）</p>
<blockquote>
<p>在实际使用过程中，RMSprop已被证明是一种有效且实用的深度神经网络优化算法。目前它是深度学习人员经常采用的优化算法之一。keras文档中关于RMSprop写到：This
optimizer is usually a good choice for recurrent neural networks.</p>
</blockquote>
<h2 id="八adamadaptive-moment-estimation">八、Adam（Adaptive Moment
Estimation）</h2>
<p>Adam实际上是把momentum和RMSprop结合起来的一种算法，算法流程是（摘自adam论文）：</p>
<img data-src="/2019/03/11/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%87%A0%E7%A7%8D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95%E5%92%8C%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/19.jpg" class="">
<blockquote>
<p>实践表明，Adam算法在很多种不同的神经网络结构中都是非常有效的。</p>
</blockquote>
<h2 id="八该如何选择优化算法">八、该如何选择优化算法</h2>
<p>介绍了这么多算法，那么我们到底该选择哪种算法呢？目前还没有一个共识，schaul
et al
在大量学习任务上比较了许多优化算法，结果表明，RMSprop，Adadelta和Adam表现的相当鲁棒，不分伯仲。Kingma
et
al表明带偏差修正的Adam算法稍微好于RMSprop。总之，Adam算法是一个相当好的选择，通常会得到比较好的效果。</p>
<p>下面是论文《An overview of gradient descent optimization
algorithms》对各种优化算法的总结：</p>
<blockquote>
<p>In summary, RMSprop is an extension of Adagrad that deals with its
radically diminishing learning rates. It is identical to Adadelta,
except that Adadelta uses the RMS of parameter updates in the numerator
update rule. Adam, finally, adds bias-correction and momentum to
RMSprop. Insofar, RMSprop, Adadelta, and Adam are very similar
algorithms that do well in similar circumstances. Kingma et al. [10]
show that its bias-correction helps Adam slightly outperform RMSprop
towards the end of optimization as gradients become sparser. Insofar,
Adam might be the best overall choice</p>
</blockquote>
<hr />
<p>作者：天泽28 来源：CSDN 原文： -
https://blog.csdn.net/u012328159/article/details/80252012 -
https://blog.csdn.net/u012328159/article/details/80311892
版权声明：本文为博主原创文章，转载请附上博文链接！</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>梯度下降</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title>【转载】哪些句子拯救了你的英文邮件？</title>
    <url>/2019/03/22/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%93%AA%E4%BA%9B%E5%8F%A5%E5%AD%90%E6%8B%AF%E6%95%91%E4%BA%86%E4%BD%A0%E7%9A%84%E8%8B%B1%E6%96%87%E9%82%AE%E4%BB%B6%EF%BC%9F/</url>
    <content><![CDATA[<p>近日因为申请、填表等缘故，经常要与外方学校邮件交流，虽然之前在外企实习时有一定的英文邮件经验，有些地方还是拿捏不好。在知乎上看到一篇优质文章，转载至此以备查用。</p>
<span id="more"></span>
<hr />
<p>本文原作者： <a
href="https://www.zhihu.com/people/stevenc214">史蒂芬</a>
原文链接：https://www.zhihu.com/question/34147404/answer/140038805
转载自：知乎</p>
<hr />
<div class="List-item" tabindex="0">
<div class="ContentItem AnswerItem" data-za-index="0"
data-zop="{&quot;authorName&quot;:&quot;史蒂芬&quot;,&quot;itemId&quot;:140038805,&quot;title&quot;:&quot;哪些句子拯救了你的英文邮件？&quot;,&quot;type&quot;:&quot;answer&quot;}"
name="140038805" itemprop="acceptedAnswer"
itemtype="http://schema.org/Answer" itemscope=""
data-za-detail-view-path-module="AnswerItem"
data-za-detail-view-path-index="0"
data-za-extra-module="{&quot;card&quot;:{&quot;has_image&quot;:false,&quot;has_video&quot;:false,&quot;content&quot;:{&quot;type&quot;:&quot;Answer&quot;,&quot;token&quot;:&quot;140038805&quot;,&quot;upvote_num&quot;:13038,&quot;comment_num&quot;:262,&quot;publish_timestamp&quot;:null,&quot;parent_token&quot;:&quot;34147404&quot;,&quot;author_member_hash_id&quot;:&quot;9a0d32ca87e589d004846094579ee95f&quot;}}}">
<div class="ContentItem-meta">
<div
class="AuthorInfo AnswerItem-authorInfo AnswerItem-authorInfo--related"
itemprop="author" itemscope="" itemtype="http://schema.org/Person">
<meta itemprop="name" content="史蒂芬">
<meta itemprop="image" content="https://pic2.zhimg.com/v2-a69e9d4bcf48901a824ea8778268ee15_is.jpg">
<meta itemprop="url" content="https://www.zhihu.com/people/stevenc214">
<meta itemprop="zhihu:followerCount" content="129454">
<span class="UserLink AuthorInfo-avatarWrapper">
<div class="Popover">
<div id="Popover14-toggle" aria-haspopup="true" aria-expanded="false"
aria-owns="Popover14-content">
<a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/stevenc214"><img class="Avatar AuthorInfo-avatar" width="38" height="38" data-src="https://pic2.zhimg.com/v2-a69e9d4bcf48901a824ea8778268ee15_xs.jpg" srcset="https://pic2.zhimg.com/v2-a69e9d4bcf48901a824ea8778268ee15_l.jpg 2x" alt="史蒂芬"></a>
</div>
</div>
</span>
<div class="AuthorInfo-content">
<div class="AuthorInfo-head">
<span class="UserLink AuthorInfo-name">
<div class="Popover">
<div id="Popover15-toggle" aria-haspopup="true" aria-expanded="false"
aria-owns="Popover15-content">
<a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="//www.zhihu.com/people/stevenc214">史蒂芬</a>
</div>
</div>
</span>
</div>
<div class="AuthorInfo-detail">
<div class="AuthorInfo-badge">
<div class="ztext AuthorInfo-badgeText">
公众号:stehouse，按赞同数排序看我历史回答。
</div>
</div>
</div>
</div>
</div>
<div class="AnswerItem-extraInfo">
<span class="Voters"><span><span class="UserLink">
<div class="Popover">
<div id="Popover43-toggle" aria-haspopup="true" aria-expanded="false"
aria-owns="Popover43-content">
</span>
</div>
</div>
<meta itemprop="image">
<meta itemprop="upvoteCount" content="13038">
<meta itemprop="url" content="https://www.zhihu.com/question/34147404/answer/140038805">
<meta itemprop="dateCreated" content="2017-01-09T10:04:40.000Z">
<meta itemprop="dateModified" content="2018-01-09T07:17:29.000Z">
<meta itemprop="commentCount" content="262">
<div class="RichContent RichContent--unescapable">
<div class="RichContent-inner">
<span class="RichText ztext CopyrightRichText-richText" itemprop="text">
<p>
作为一名天天和老外同事打交道的美资公司工程师，这些年写过的英文邮件没有一万封也有五千封了，看过的邮件没有十万也五万封了，看了一些回答特别是某位自称外企人的，我只想呵呵，和书上写的好像哦，你试试这样写看看，看看别人什么反应。我来说说实际美国人是怎么写邮件的。
</p>
<p>
大家还可以关注我的<b>微信公众号「史蒂芬的专栏」（id:
stehouse)</b>或者参加我的课程<b>《<a href="https://zhuanlan.zhihu.com/p/30216242" class="internal" data-za-detail-view-id="1043">你要的商务英语、英文邮件写作都在这里了</a>》</b>，获取更多实用的英语表达技巧。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>我举的例子都是美国人写的邮件原文，比那些书上写的要清新脱俗得多。</b>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
先来一封我们CEO最近发的邮件，全篇没有装逼词，但是就是显得很有水平。
</p>
<blockquote>
<b>Happy New Year—I hope you and your family had a great holiday and
enjoyed some well-deserved time off. Thank you again for a terrific
effort and a strong result last year!</b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
再来一封老美写的开发客户的邮件，我以前兼职做过外贸，有一次打电话给美国客户，因为英语不好所以别人以为我是采购商，反而发一封邮件给我和我做生意o(╯□╰)o。这邮件也是写得清新自然，没有书上写的套话。
</p>
<blockquote>
<b>Hello Steven,</b> <b>It was my pleasure to talk with you earlier
today – thank you for contacting XXXX.</b> <b>I am writing to share more
information with you about XXXX and our digital signage systems. The
attached corporate brochure will provide you with an overview of our
most popular system features – you can also learn more by visiting our
website at
<a href="https://link.zhihu.com/?target=http%3A//www.janusdisplays.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">X</a>XXX.com.
As you will see, XXX has been providing industry-leading digital signage
systems for the past 25 years and we are honored to have our systems in
place with over 2,500 hotels, resorts and casinos around the world. </b>
<b>We would be very interested in exploring a relationship with XXXX in
order to explore digital signage opportunities in China. As I’ve
mentioned, our primary customer focus is with hotels, resorts and
casinos. Our digital display systems are designed to meet the needs of
the hospitality market. We are fortunate to have earned preferred-vendor
status with many of the leading hotel brands including: Hyatt, Hilton,
Sheraton, Westin, Marriott, Four Seasons, Ritz Carlton, Renaissance and
many more. Please let me know if you have relationships with any hotels
and we can develop a plan to pursue the opportunity together. </b>
<b>Please review our information at your earliest convenience and let me
know if you have any questions. I look forward to our next
communication.</b> <b>Regards,</b> <b>xxxx</b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b><u>一、基本邮件礼仪(Email etiquette)</u></b>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
英文邮件的礼仪成千上万条，大多其实都已经超出了“英文”的范畴，而是不管什么语言都要注意的，那我就不说了，我只说和印象最深刻的，而且和中文邮件有明显区别的，那就是感谢和道歉。
</p>
<p>
<b>1）感谢</b>
</p>
<p>
中文邮件不喜欢太多客套话，废话少说，直入正题，但是美国人写邮件，哪怕是和熟悉的人，回邮件第一句话，都要感谢，所以他们的邮件都是
thank来thank去的，中文邮件没这种习惯。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
开头，感谢别人回复自己的邮件（也可以用thank
you，用在稍微正式场合，比如和陌生人发邮件）
</p>
<ul>
<li>
<b>Thanks for the quick reply.<br></b>
</li>
<li>
<b>Thanks for getting back to me.<br></b>
</li>
<li>
<b>Thanks for the update on the situation.</b>
</li>
<li>
<b>Thanks for the updated information.<br></b>
</li>
<li>
<b>Thanks for gathering the information this week on this issue.</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
别人发邮件提供信息给你，中文邮件是懒得回的，英文邮件也习惯感谢，简单回复一个。
</p>
<ul>
<li>
<b>Thank you.</b>
</li>
<li>
<b>Well noted. <br></b>
</li>
<li>
<b>Noted/Received with thanks.</b>
</li>
<li>
<b>Good information.</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>2）道歉</b>
</p>
<p>
如果是回邮件回得晚了，先道歉，貌似中文很少有这个习惯(以下sorry也可以替换成apologize，更正式一点，发给重要的人或者群发）
</p>
<ul>
<li>
<b>Sorry for the late
reply.（中国人普遍这这一种，也有老外用，不过下面两种更多）<br></b>
</li>
<li>
<b>Sorry I haven’t got back to you sooner . <br></b>
</li>
<li>
<b>Sorry for the delay getting back to you.</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
如果是临时通知别人是什么事情
</p>
<ul>
<li>
<b>Apologies for the late/short notice.</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
如果是上一封邮件没写清楚导致收件人误解了
</p>
<ul>
<li>
<b>I apologize if this was not made clear </b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
提前给别人预警如果自己的措辞过于强硬。
</p>
<ul>
<li>
<b>I apologize if this may make you feel uncomfortable/bad.</b>
</li>
<li>
<b>I apologize if this may sound a little harsh.</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>3）收尾套路</b>
</p>
<p>
最后收尾的套路，一般都是问别人意下如何。(不要用please tell me
...这种句式，从来没见过老外用的）
</p>
<ul>
<li>
<b>Please let me know what you think.</b>
</li>
<li>
<b>Please let me know your thoughts.</b>
</li>
<li>
<b>Let me know if you have any questions or concerns. (最常见）<br></b>
</li>
<li>
<b>Please let me know if there are questions.</b>
</li>
<li>
<b>Looking forward to your input/insight(用insight/input代替opinion)</b>
</li>
<li>
<b>That’s my idea, what's your idea?(也有直接这样说的）</b>
</li>
<li>
<b>Please review the lengthy e-mail and provide feedback on how we can
proceed.(如果邮件太长了）</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
或者，干脆下面的话结尾，
</p>
<blockquote>
<b>I'll let you know more
tomorrow(表示今天没说完，明天再说更多)<br>Please call me if you
like.(有什么事打我电话）<br></b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>4）称呼</b>
</p>
<p>
普通工作邮件，直接称呼名字字就好了，比如Hi Steven，不需要用Mr.，
甚至写给总裁的邮件，也是直接说Hi Bill，不需要Hi President
Johnson。<b>否则真的真的太令人不自在了。</b>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
只有德国人是个例外，喜欢加Mr./Ms.
我以前在德资企业工作，发给女性的邮件居然要称呼Ms. Zhang。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
学术场合才需要加抬头，比如Prof. Johnson. 政客的Congressman Johnson.
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
记住，一般不加Dear，只有公司HR群发邮件才说Dear all, 发给个人的，一般就Hi
Steven或者直接说Steven,
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
抓住这几点就够了，其他礼仪说多了都是正确的废话。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
另外再看看我这篇文章，弄清楚什么时候该用正式用语，什么时候可以用非正式。
</p>
<h2>
<a href="https://zhuanlan.zhihu.com/p/24030595" class="internal" data-za-detail-view-id="1043">英语
| 到底什么是正式场合和非正式场合</a>
</h2>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>5）告别邮件主题</b>
</p>
<p>
离职时发邮件感谢同事，我见过老外用以下两种
</p>
<ul>
<li>
<b>Thank you</b>
</li>
<li>
<b>Farewell</b>
</li>
</ul>
<p>
两种都可以。注意farewell并非永别，也可以表示<b>以后很难见面</b>。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b><u>二、邮件基本术语</u></b>
</p>
<p>
很多国人凭自己的想象力在创造一些表达，以下才是地道的用语。
</p>
<p>
<b>1）抄送别人怎么说？</b>
</p>
<p>
中国人喜欢说cc，美国人直接说copy.
</p>
<p>
cc是 carbon
copy（复写纸）的简称，以前还没有电子邮件时候，用复写纸抄送，所以本质上还是copy.
</p>
<ul>
<li>
<b>I have put John on copy. (记住put on copy的固定搭配）</b>
</li>
<li>
<b>You can copy Steven going forward.</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
如果是分别抄送给某些人，但是又不想让他们互相知道对方的联系方式，可以用暗送(BCC也就是blind
cc),比如同时发给几个供应商，邮件开头直接写
</p>
<blockquote>
<b>BCC vendors</b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>2）群发邮件增加联系人怎么说？</b>
</p>
<p>
我看到台湾香港人大陆人都是用add xxx in the
loop.从来没见过美国人这样说的。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
一般都是在邮件开头，无称呼，直接说
</p>
<ul>
<li>
<b>Looping in Steven.</b>
</li>
<li>
<b>Adding/Added Steven.</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
甚至直接用 “+”都可以
</p>
<ul>
<li>
<b>+ Steven</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
把某个人删除（涉及到保密的信息）,用remove
</p>
<ul>
<li>
<b>Removed Mike from this email</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>3)转发邮件怎么说？</b>
</p>
<blockquote>
<b>forward the email to someone(大部分中国人只会用这种)<br>pass me the
email(老外也经常用这种)</b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>4)回复邮件怎么说？</b>
</p>
<p>
get back比 reply常用
</p>
<blockquote>
<b>I will get back to you tomorrow.</b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>5）附件怎么说？</b>
</p>
<p>
附件的英文是attachment.但是如果你说please find the
attachment实在是恶俗至极。
</p>
<p>
一般直接用动词attached, enclosed. 我比较喜欢用attached.
</p>
<blockquote>
<b>Attached/Enclosed please find the report.<br>I attached the report
and let me know what you think.</b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>6)文件怎么说?</b>
</p>
<p>
excel, pdf, word
如果你说file也是恶俗至极，正确的说法是document.（excel可以说spreadsheet,
ppt可以说presentation)
</p>
<blockquote>
<b>Attached please find the document.</b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b><u>三、和陌生人发邮件如何自我介绍？</u></b>
</p>
<p>
不要说 This is xxx和I
am这种句式，开头也不要太多客套话，老外开头都是直接说My name is xxx
</p>
<blockquote>
<b>Hi Mike,<br></b> <b>My name is Steven Gates. I work in the R&amp;D
department and am in charge of ...</b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b><u>四、群发邮件如何称呼？</u></b>
</p>
<p>
书上百分之一万告诉你用Dear all, Hi
all这种，实际，只有群发给整个公司的邮件，比如公司新闻之类的才用这种称呼，其他时候用下面的，
</p>
<ul>
<li>
<b>Team, (最常用）</b>
</li>
<li>
<b>Gents, (如果全部是男的）</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
全部都是女的，我还真不知道怎么称呼，我也没在女人堆里待过。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>五、邮件里插话怎么说？</b>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
本来你只是在cc列表里作为旁观者，但是你也想进来插一句话怎么说？用chime in
</p>
<blockquote>
<b>Just to chime in, xxxx<br>I'd like to chime in with my idea,
xxxx<br></b>
</blockquote>
<p>
如果邀请别人发表意见怎么说，用 please chime in here with your
thoughts/comments/idea.
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<blockquote>
<b>Steven, please chime in here with correct information.</b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b><u>六、邮件如何更加礼貌？</u></b>
</p>
<p>
参考史蒂芬这个3000赞的回答
</p>
<p>
<b><a href="https://www.zhihu.com/question/30964795/answer/137634710" class="internal" data-za-detail-view-id="1043">在日常英语对话中有哪些细节中国人不会注意，但是外国人却觉得很重要，并可能认为中国人很无礼？
- 史蒂芬的回答 - 知乎</a></b>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
另外补充
</p>
<p>
<ol type="1">
<li>问别人一个问题时，前面加个wondering表示想知道，比直接问一个问题更加委婉。
</p>
<ul>
<li>
<b>I was wondering </b>what your thoughts are changing this design.
</li>
<li>
<b>I am wondering</b> if you are using the same material.
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<ol start="2" type="1">
<li>请求别人做一件事，用<b>If you could xxx, that would be great.</b>
更加礼貌
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<ol start="3" type="1">
<li>请别人帮忙做一件事时，在前面加<b>(by) any
chance</b>，意思是如果有时间/有机会，很委婉。
</p>
<ul>
<li>
<b>By any chance</b>, could you help check the data?
有时间可不可以帮忙看看数据？
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b><u>六、起承转合常用词</u></b>
</p>
<p>
我就不说However, Nevertheless, on one hand, on the other hand,
firstly这种老师教的恶俗至极的老八股了。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>1）lastly/finally</b>
</p>
<p>
很少看到邮件用说firstly的，一般有话就直说,
但是lastly很常见，在说完前面一大堆之后，说最后一件事的时候，说lastly,finally表示最后你想说什么
</p>
<ul>
<li>
<b>Lastly, could you confirm that there is no additional change?
最后一件事，你可不可以确认一下不会再改了？</b>
</li>
<li>
<b>Finally, the most important thing is
...(不知道怎么翻译这个finally)</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>2）as/on a side note </b>
</p>
<p>
原意是边注，引申为补充说明某件事情，特别是你想提醒别人做某件事，这样更加委婉，可以翻译成“友情提示”。
</p>
<ul>
<li>
<b>Also, on a side note, can you xxxx?</b>
</li>
<li>
<b>As a side note, I'm beginning to think our current measurement method
doesn't seem to be accurate enough .</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
类似的还有 on a related point（相关说明）
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>3) specifically </b>
</p>
<p>
特别说明一件事时，用这个词开头，另写一个自然段。
</p>
<ul>
<li>
<b>Specifically , we are interested in xxxx.</b>
</li>
<li>
<b>Specifically , we'd like to xxxx.</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>4) all said/ with all that said</b>
</p>
<p>
中文意思就是“说了那么多”，用于总结。
</p>
<ul>
<li>
<b>All said, I think we are in an enviable position going into the 2017
sales season with xxxx.
说了那么多，我想我们处在一个令人羡慕的市场地位。</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>5) that being said</b>
</p>
<p>
中文意思是“话虽如此',
</p>
<ul>
<li>
<b>That being said, we still need to ...(话虽如此，我们还是需要...)</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>6) on another front</b>
</p>
<p>
代替on another side
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b><u>七、邮件里常用的词汇</u></b>
</p>
<p>
待我逐一讲解。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>1) highlight</b>
</p>
<p>
这真是个妙词，本意是高亮显示，也就是给字体加点背景颜色，引申为强调以引起注意。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
以下都叫highlight，前者是真正的highlight，后者虽然是画圈，但是也是框起来引起人注意，也叫highlight.
下面区域就叫highlighted area.
</p>
<figure data-size="normal">
<noscript>
<img data-src="https://pic3.zhimg.com/50/v2-6bfad9c740b00fbdca561ddb36efce9b_hd.jpg" data-caption="" data-size="normal" data-rawwidth="420" data-rawheight="191" class="content_image" width="420"/>
</noscript>
<img data-src="https://pic3.zhimg.com/80/v2-6bfad9c740b00fbdca561ddb36efce9b_hd.jpg" data-caption="" data-size="normal" data-rawwidth="420" data-rawheight="191" class="content_image lazy" width="420" data-actualsrc="https://pic3.zhimg.com/50/v2-6bfad9c740b00fbdca561ddb36efce9b_hd.jpg">
</figure>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
所以，任何事情只要你想强调，以引起别人注意，都可以用highlight.就连足球比赛精彩回顾也叫highlight.
</p>
<ul>
<li>
I have to <b>highlight</b> the issue that the deadline is close whereas
up to date we haven't come up with a solution<br>
</li>
<li>
One of my concerns is that the factory is not <b>highlighting</b> the
challenges in production.
</li>
<li>
Can you provide some pictures and videos <b>highlighting </b>the xxx
area of the product?(就是要你特写拍一下某个区域)
</li>
<li>
I would like you to put a report together highlighting what caused the
issue and how you expect to correct the issue.
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>2) issue</b>
</p>
<p>
邮件里很少说problem,一般都用issue代替，更加正式，表示值得注意的问题。
</p>
<p>
比如品质问题是quality issue.
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
例句参照上面。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>3) bullet points</b>
</p>
<ul>
<li>
现在左边这个黑色的点就是bullet
point，这是它的本意，中文叫做项目符号，引申为重点内容。
</li>
</ul>
<p>
<b>Let's discuss all the bullet points tomorrow.</b>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>4) callout</b>
</p>
<p>
记住下面这这种有箭头或者线条的标注文字叫做callout，不叫remark, comment,
note.
</p>
<figure data-size="normal">
<noscript>
<img data-src="https://pic3.zhimg.com/50/v2-f9fd62df77f09f00adf6bee999e8cbf5_hd.jpg" data-caption="" data-size="normal" data-rawwidth="600" data-rawheight="259" class="origin_image zh-lightbox-thumb" width="600" data-original="https://pic3.zhimg.com/v2-f9fd62df77f09f00adf6bee999e8cbf5_r.jpg"/>
</noscript>
<img data-src="https://pic3.zhimg.com/80/v2-f9fd62df77f09f00adf6bee999e8cbf5_hd.jpg" data-caption="" data-size="normal" data-rawwidth="600" data-rawheight="259" class="origin_image zh-lightbox-thumb lazy" width="600" data-original="https://pic3.zhimg.com/v2-f9fd62df77f09f00adf6bee999e8cbf5_r.jpg" data-actualsrc="https://pic3.zhimg.com/50/v2-f9fd62df77f09f00adf6bee999e8cbf5_hd.jpg">
</figure>
<p>
把call
out分开变成动词，就是标注，学工科的都知道工程图很多尺寸公差是需要标注的。
</p>
<blockquote>
<b>The tolerance/spec wasn't called out.<br></b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>5) with regard to/ regarding</b>
</p>
<p>
关于....的话题，不要用about
</p>
<blockquote>
I'll have a business trip regarding the quality issue.
</blockquote>
<p>
<b>6) echo</b>
</p>
<p>
本意是“回声”，也就是唱KTV或者打电话经常出现的回声，引申为“附和，邮件经常用这个词来表示“我只是重复一下某人观点”，谦虚的说法
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<blockquote>
To echo John's <b>direction</b>, our plan is
xxxx（John的邮件在前面，如果在John的邮件上再回复就可以这样说。<br>Just
to confirm and <b>echo</b> John, please xxxx.<br>I can only <b>echo</b>
David's email. I also think xxx.
</blockquote>
<p>
<b>7) address</b>
</p>
<p>
不要只知道是"
地址“的意思，邮件和日常工作中经常用这个词表达”考虑、讨论（以尝试解决）“，意思介于think/talk
about和solve之间，并不承诺一定能解决，只是表示"需要引起注意并解决”，固定搭配address
the issue/ problem/question/ concern
</p>
<ul>
<li>
This issue needs to <b>be addressed.
</b>（这个问题需要引起注意并解决）<br>
</li>
<li>
The products <b>address </b>the needs of beginners.
（这个产品考虑到了新用户的需求）<br>
</li>
<li>
A question we‘ll need to <b>address</b> is whether we can afford
XXXX<br>
</li>
<li>
I <b>addressed </b>the quality issue in the
meeting(我在会议中讨论了质量问题）
</li>
<li>
All other questions/issues will be addressed by
Kevin.(其他问题将由Kevin来讨论）
</li>
<li>
Items to be <b>addressed </b>Wednesday（星期三要讨论的事项）<br>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>8) bring up</b>
</p>
<p>
表示把一个问题/话题提出来，这个是最常用的表达，隐含提出来供大家讨论的意思，比mention的意思更丰富。
</p>
<ul>
<li>
I also <b>brought up</b> a<br>few concerns with John about XXXX.<br>
</li>
<li>
One thing I'd like to <b>bring up</b> is XXXX<br>
</li>
<li>
We are looking to save some cost on XXX project and one of the ideas
<b>brought up</b> by the team was to look at XXXX.
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>9 )involve</b>
</p>
<p>
把某人(某事）包含到某事来，很难用某个中文单词翻译，意思就是把他牵扯进来（非贬义），比include的语气要弱。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<ul>
<li>
We would<b> involve </b>members from purchasing team as well.<br>
</li>
<li>
When there is delivery issue, please <b>involve</b> the sales team.
</li>
<li>
I would like for the root causes and<br>corrective actions to
<b>involve</b> some engineering controls in the process instead<br>of
just increased inspections.
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>10) direction </b>
</p>
<p>
字面意思是“方向”，引申义为“指示”，不一定是上级对下级，任何“做某件事的方法”都可以叫direction.
</p>
<ul>
<li>
I will follow David's <b>direction.</b>
</li>
<li>
Thanks for your <b>direction.</b>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>11) concern</b>
</p>
<p>
字面意思是“担心”，和worry的意思差不多，还隐含“担心而值得注意的事”，邮件中很少用worry这个词，一般都用concern.
</p>
<blockquote>
quality concern<br>delivery concern<br>cost concern
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>12) input</b>
</p>
<p>
本意是「输入」的意思，但是实际工作中，经常做「提供信息/建议」理解。
</p>
<blockquote>
比如你给别人提供建议/信息，他会说Thanks for your <b>input.
</b><br>比如《纸牌屋》里，幕僚长对副总统说 We<br>value your
<b>input</b>, Mr. Vice
President.<br>比如你想问别人对这件事的看法，你可以说 I'd like your
<b>input </b>on it.
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>13) insight </b>
</p>
<p>
翻译成「洞见」，不接地气，但也找不出更好的表达（或者是「高见」？）
</p>
<p>
工作中，经常用来拔高别人，可以看做是opinion和input的升级版.
</p>
<blockquote>
比如 provide some <b>insight</b> for it, <br>Look forward to your
<b>insight.</b><br>That's valuable <b>insight</b>.
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>14) dig into</b>
</p>
<p>
"深入研究“、”深挖“的意思。
</p>
<ul>
<li>
We need to <b>dig into</b> the root cause.<br>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>15) expedite</b>
</p>
<p>
加快，邮件中多用这个词代替accelerate和speed up
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<ul>
<li>
<b>expedite</b> the order (加快订单）
</li>
<li>
<b>expedite </b>the process (加快流程）
</li>
<li>
We appreciate whatever<br>you are able to do in order to help<b>
expedite</b> these samples.<br>
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>16）due</b>
</p>
<p>
很多人知道due to，但是不知道 due原来还有“预期”的意思,代替expect，due
date是“预计日期”，而不是通常理解的"截止日期“，比如预产期也是due date.
</p>
<ul>
<li>
The parts are <b>due</b> in Shanghai on Friday = The parts are expected
to arrive in Shanghai on Friday.
</li>
<li>
Our annual report is <b>due</b> to be shared early next
year.(财报明年年初公布）
</li>
<li>
The samples are <b>due</b> to ship(或者be shipped) on
Monday.（样品预计星期一寄出）
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>17）part</b>
</p>
<p>
制造业用part代替product，没为什么
</p>
<blockquote>
The <b>parts </b>were made in January.
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>18)
timing</b><br>时间安排，和time有相同和不同的地方，,很难翻译，用来代替time。看字典里怎么解释的。<br>Timing
is used to refer to<b> the time at which something happens</b> or is
planned to happen, or to the <b>length of time</b> that something takes.
</p>
<ul>
<li>
Because the manufacturing<b> timing</b> is too long, we would come up
with a better idea(这里和time是一样的意思）<br>
</li>
<li>
My July visit <b>timing</b> has not yet been
decided(我七月份来访的时间还没确定）
</li>
<li>
That's perfect <b>timing</b>.(真是个好时候）
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>19） check
in</b><br>不要以为只是酒店入住登记的意思，在邮件里经即可表示”获取信息“也可以表示“汇报“<br>老外有时候发邮件主题就是check
in两个字，邮件的内容就是问一个问题。
</p>
<p>
字典上的释义<br>to talk with (someone) in order to report or find out
new information &lt;I have to go to a meeting now, but I'll check in
with you later.
</p>
<ul>
<li>
I wanted to <b>check in</b> to ensure xxx.
我发邮件过来只是想了解一下状况，确保xxxx
</li>
<li>
David <b>checked in</b> with me on what we can do.
大卫找我问我我们能够做什么。<br>
</li>
<li>
I'll <b>check in</b> with our team to confirm expected ship date and let
you know. 我要去问一下我们团队。<br>
</li>
<li>
I'll <b>check in</b> with you tomorrow. 我明天再告诉你。
</li>
</ul>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
口语里也常说I'll check in with you later（我稍后再和你联系）I'm<br>just
calling to check
in（我打电话来也没什么事，了解你的近况而已）。你问别人在吗，别人说what's
up？你说没什么事就是I'm<br>just checking in.
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
consolidate
</p>
<p>
align
</p>
<p>
specifics
</p>
<p>
generalities
</p>
<p>
documentation
</p>
<p>
reflect
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
还可以参考我另外一个回答
</p>
<p>
<a href="https://www.zhihu.com/question/22454692/answer/137447632" class="internal" data-za-detail-view-id="1043">有哪些英语用一个单词就能表达清楚但是用中文表达却很难表达的例子？</a>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b>对商务英语感兴趣的小伙伴，移步我一个课程，我把多年积累的职场商务英语都写在这个课程里了，里面有100个职场英语核心词汇。</b>
</p>
<blockquote>
<b><a href="https://zhuanlan.zhihu.com/p/30216242" class="internal" data-za-detail-view-id="1043">你要的商务英语、英文邮件写作都在这里了</a></b>
</blockquote>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
<b><u>八、英语邮件如何显得更加专业，给人留下好的印象。</u></b>
</p>
<ul>
<li>
主题必须要“标题党”，必须包含必要信息，让人有打开的欲望。有些台湾人甚至在标题上加-&gt;Steven表示这封邮件是发给谁的。比如<b>
XXXX Delay notice -&gt; Steven</b>
</li>
<li>
一定不要用任何简写，比如c.u(see
you)之类，除了pls(please),thx(thanks),当然能不用尽量不用。
</li>
<li>
一定不要用gonna, wanna这种形式，恶俗至极，请变成原形 going to, want to
</li>
<li>
回复别人邮件，要把过往邮件的内容recap一遍，防止别人忘记。
</li>
<li>
多用bullet point, table 让邮件更加清晰。
</li>
<li>
多用callout，一目了然。
</li>
<li>
有附件的话，把附件做一个summary贴在正文。
</li>
<li>
附件的命名一定要规范，让人知道里面是什么，也方便别人保存
</li>
<li>
任何邮件，当天必须回、必须回
</li>
</ul>
<p>
<b>（未完待续）</b>
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<p>
================================================================
</p>
<p>
史蒂芬其他回答和文章<br>
</p>
<p>
<a href="https://zhuanlan.zhihu.com/p/22821654" class="internal" data-za-detail-view-id="1043">写工作邮件的几点建议（一目了然，高效沟通）
- 史蒂芬的专栏 - 知乎专栏</a>
</p>
<p>
<a href="https://www.zhihu.com/question/19666878/answer/137952334" class="internal" data-za-detail-view-id="1043">外企面试的时候英语自我介绍该说点什么？</a>重点推荐
</p>
<h2>
<a href="https://www.zhihu.com/question/28932627/answer/139288384" class="internal" data-za-detail-view-id="1043">有哪些美剧的台词是高水平的、值得反复学习的？</a>
</h2>
<p>
<a href="https://zhuanlan.zhihu.com/p/24689680" class="internal" data-za-detail-view-id="1043">如何把《经济学人》《纽约时报》学到的词汇正确理解和使用？</a>
</p>
<p>
<a href="https://zhuanlan.zhihu.com/p/24455667" class="internal" data-za-detail-view-id="1043">如何把每天最新英文版《纽约时报》推送到kindle上？</a>
</p>
<p>
<a href="https://www.zhihu.com/question/27372528/answer/133749576" class="internal" data-za-detail-view-id="1043">受汉语思维影响的英语错误表达有哪些？</a>
</p>
<p>
<a href="https://zhuanlan.zhihu.com/p/23301750" class="internal" data-za-detail-view-id="1043">英语表达如何假装很地道（一）？</a>
装X专用
</p>
<p>
<a href="https://www.zhihu.com/question/30996617/answer/124501743" class="internal" data-za-detail-view-id="1043">学英语有什么用？
- 史蒂芬的回答</a> 英语面试的经历
</p>
<p>
<a href="https://www.zhihu.com/question/20097263/answer/25859411" class="internal" data-za-detail-view-id="1043">怎么练好英语口语？
- 史蒂芬的回答</a> 通过拆分法和自言自语法练口语
</p>
<p>
<a href="https://zhuanlan.zhihu.com/p/22770335" class="internal" data-za-detail-view-id="1043">关于英语的一些误区澄清-是敲门砖还是锦上添花？-史蒂芬的专栏-知乎专栏</a>
</p>
<p>
<a href="https://zhuanlan.zhihu.com/p/24030595" class="internal" data-za-detail-view-id="1043">英语
| 到底什么是正式场合和非正式场合</a>
</p>
<p>
<a href="https://www.zhihu.com/question/36343659/answer/135887771" class="internal" data-za-detail-view-id="1043">有哪些人际关系方面的小技巧可以保护自己？</a>
推荐
</p>
<p>
<a href="https://zhuanlan.zhihu.com/p/24165963" class="internal" data-za-detail-view-id="1043">面试官鄙视毕业的学校怎么办？</a>
<a href="https://zhuanlan.zhihu.com/p/23729536" class="internal" data-za-detail-view-id="1043">面试时如何回答“你为什么要换工作？”（一种新思路）</a>
<a href="https://zhuanlan.zhihu.com/p/23605146" class="internal" data-za-detail-view-id="1043">给文科专业的一些职业选择建议</a>
<a href="https://zhuanlan.zhihu.com/p/23491212" class="internal" data-za-detail-view-id="1043">给理工科专业的一些职业选择建议</a>
</p>
<p>
更多精彩，请关注史蒂芬微信公众号「史蒂芬的专栏」（ID：stehouse），聊点职场和英文。
</p>
<p>
史蒂芬，湖南人士，前某500强外企工程师，现某知名品牌外企工程师，对职场、管理、英语有些感悟
。
</p>
<p class="ztext-empty-paragraph">
<br>
</p>
<figure data-size="normal">
<noscript>
<img data-src="https://pic3.zhimg.com/50/v2-4fc55fea65ca77384d7c00e729d5e7e7_hd.jpg" data-caption="" data-size="normal" data-rawwidth="650" data-rawheight="384" class="origin_image zh-lightbox-thumb" width="650" data-original="https://pic3.zhimg.com/v2-4fc55fea65ca77384d7c00e729d5e7e7_r.jpg"/>
</noscript>
<img data-src="https://pic3.zhimg.com/80/v2-4fc55fea65ca77384d7c00e729d5e7e7_hd.jpg" data-caption="" data-size="normal" data-rawwidth="650" data-rawheight="384" class="origin_image zh-lightbox-thumb lazy" width="650" data-original="https://pic3.zhimg.com/v2-4fc55fea65ca77384d7c00e729d5e7e7_r.jpg" data-actualsrc="https://pic3.zhimg.com/50/v2-4fc55fea65ca77384d7c00e729d5e7e7_hd.jpg">
</figure>
</span>
</div>
<div>
<div class="ContentItem-time">
<a target="_blank" href="/question/34147404/answer/140038805"><span
data-tooltip="发布于 2017-01-09 18:04">编辑于 2018-01-09</span></a>
</div>
</div>
<div>
<div class="ContentItem-actions Sticky RichContent-actions is-bottom"
style="">
<span><span
style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--ArrowDown ContentItem-arrowIcon is-active" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M12 13L8.285 9.218a.758.758 0 0 0-1.064 0 .738.738 0 0 0 0 1.052l4.249 4.512a.758.758 0 0 0 1.064 0l4.246-4.512a.738.738 0 0 0 0-1.052.757.757 0 0 0-1.063 0L12.002 13z" fill-rule="evenodd"></path></svg></span></button>
</div>
</div>
</div>
</div>
</div></li>
</ol></li>
</ol></li>
</ol>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
]]></content>
      <categories>
        <category>外语</category>
      </categories>
      <tags>
        <tag>英语</tag>
        <tag>邮件</tag>
      </tags>
  </entry>
  <entry>
    <title>一年又一年</title>
    <url>/2024/04/04/%E4%B8%80%E5%B9%B4%E5%8F%88%E4%B8%80%E5%B9%B4/</url>
    <content><![CDATA[<p>转眼已经 2024 年清明了。从 2021
年秋招开始，就没怎么得空更新博客，两年多忙忙碌碌，尝试且完成了太多事，只是都没有落笔记录。毕业前换了电脑，连
hexo
都没装，最近发现之前博客的访客记录和评论区都没了，才又翻教程回忆当初的配置，所幸关键信息都有记录，博客得以起死回生。</p>
<span id="more"></span>
<p>两年前同一天，我为毕业论文殚精竭虑，感冒了还硬拉着合作者学弟在北馆咖啡厅讨论了一下午，晚饭后又转战独峰书院继续聊到九点。七小时高强度科研终于弥合了证明里一直过不去的
gap，整个工作有了比较坚实的基础，一直忧虑毕业问题的我终于放心——「毕业论文这下能写完了」——尽管当时距离论文提交只剩不到两周，我还卡在理论部分，整篇论文大概只完成了四分之一。第二天我的嗓子完全哑了，之后连续几天只能手语和食堂大妈交流。</p>
<p>一年前的清明假期，全组加班（三倍工资真香），此前不久我在公司的第一篇论文投稿刚被审稿人喷得体无完肤，这时正在紧锣密鼓重写论文赶
4.7 的截稿日。与此同时，千辛万苦合入项目里的功能也因触发 bug 而被
revert，一个巨大的烂摊子还等着我投稿完成后回去收拾。</p>
<p>时间来到 2024 年，就在昨晚，我拖着连续 debug
三天终于成功的疲惫身心回家，九点钟一沾枕头就陷入沉睡，半梦半醒间还在想，一觉醒来论文就该出结果了。晚上
11
点睁眼，看到手机上十条工作消息，心想一定是审稿结果出来了，一点开就看到群里合作者表示「不用倒立洗头了」——论文终于中了。</p>
<p>在公司完成的这篇历时一年半投稿 4 次的论文，从 2022
年投稿被审稿人喷，到 2024 年 rebuttal
里我喷审稿人，见证了许多。这同一篇文章上一次投稿被接收为
poster，让我得以第一次参加学术会议，如今又为我带来不到半年后再次以长文作者身份参加学术会议的机会。而我的毕业论文，在毕业后我又与优秀且耐心的合作者们继续完善，历经一次
major revision
后终于在去年年底被领域顶会接收（可惜两个会议时间相隔太近，这篇文章的会议只能请合作者前往参加了）。</p>
<p>两年来，业余生活也算“沧海桑田”。2022
上半年于毕业论文之外，在音乐和乐队上投入了巨量精力，当时的若干演出视频如今还可在
b 站看到。2023
年，经历了疾病的转折，在乐器演奏上几乎完全懈怠了，转向了单纯的音乐欣赏。“感谢”吴氏策划，这一年成为我给国家大剧院送钱最多的一年，古典音乐欣赏水平也上了几个台阶，有了自己最喜欢的歌剧唱段，多次在长途旅程中反复聆听。</p>
<p>2022 下半年出差期间看了《边缘行者》，受其启发买了《赛博朋克
2077》，年底通关了全部结局，这可能是将近十年来我第一个通关的 3A
大作。2023 又买了 Switch
和最新两部《塞尔达传说》，大半年拖拖拉拉，今年过年后的一个周末终于连续通关《王国之泪》和《旷野之息》——没错，这两部是并行玩的。2023
TGA 后开始玩《博德之门
3》，上个月也通关了。工作后业余时间更加自由，加上一台自己装的高性能 ITX
和人生中第一台游戏机，终于无拘无束大过游戏瘾。这期间，还接着 2010
年存的档打通了初中玩的《天之痕》，以硬核模式不知道第几周目再次通关《Disco
Elysium》并上传几条游戏视频到 b
站收获了一些好评，还花一个周末飞速通关「语言学小游戏」《巴别塔圣歌》。</p>
<p>去年又重新启用了我尘封已久的护照，逮着东南亚和中亚的免签国家，五一在吴哥窟暴晒，十一在哈萨克乌兹别克猛吃。啊，至今晚上临睡前饿了，还会想念塔什干手抓饭中心的
Pilaf，和暹粒 Malis
的高棉菜。今年更是借着开会，在爱丁堡他乡遇故知，下次开会还有望在京都继续他乡遇故知。</p>
<p>毕业后的第一个小章节似乎要告一段落，这或许正是重启博客更新的最佳时机。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>论文</tag>
        <tag>游戏</tag>
        <tag>音乐</tag>
        <tag>旅游</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>关于深度学习中的正则化</title>
    <url>/2021/09/10/%E5%85%B3%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96/</url>
    <content><![CDATA[<p>简单串一下“花书”里的正则化相关内容。本篇主要关注范数正则化，之后有机会再整理bagging、dropout和BN。</p>
<p>总体而言，设关于参数<span
class="math inline">\(w\in\mathbb{R}^n\)</span>的正则化项为<span
class="math inline">\(\Omega(w)\)</span>，设原始损失函数为<span
class="math inline">\(J(w; X, y)\)</span>，则加入正则化项后的优化目标为
<span class="math display">\[\arg\min_{w}J(w; X,
y)+\alpha\Omega(w).\]</span> 另外假设原始损失函数对应的最优解为<span
class="math inline">\(w^\ast\)</span>.</p>
<span id="more"></span>
<h3 id="l2-norm">L2 norm</h3>
<p>L2 norm，即weight decay，即Ridge regression， <span
class="math display">\[\Omega(w)=\frac{1}{2}\Vert{w}\Vert_2^2 =
\frac{\alpha}{2}w^\top w.\]</span></p>
<p>单步效果上，每次更新为 <span
class="math display">\[w\gets(1-\eta\alpha)w - \nabla_w J(w; X,
y),\]</span> 其中<span
class="math inline">\(\eta\)</span>为学习率，即先将<span
class="math inline">\(w\)</span>放缩<span
class="math inline">\((1-\eta\alpha)\)</span>倍（decay），再更新梯度。</p>
<p>总体效果上，原始损失函数<span
class="math inline">\(J\)</span>的Hessian为<span
class="math inline">\(H\)</span>，考虑<strong>二阶近似</strong>，<span
class="math inline">\(J\)</span>在<span
class="math inline">\(w^\ast\)</span>处展开： <span
class="math display">\[\hat{J}(w)=J(w^\ast)+\frac{1}{2}(w-w^\ast)^\top H
(w-w^\ast) + o(w^2),\]</span> 由于取得最优，一次项为0，且<span
class="math inline">\(H\)</span>正定。那么加入正则化项后的近似目标为
<span class="math display">\[\tilde{J}(w) := J(w^\ast) +
\frac{1}{2}(w-w^\ast)^\top H (w-w^\ast) + \frac{\alpha}{2}w^\top
w.\]</span></p>
<p>设<span class="math inline">\(H\)</span>的特征值为<span
class="math inline">\(\lambda_i\)</span>，L2找到的二阶近似最优解是 <span
class="math display">\[\tilde{w} = Q(\Lambda+\alpha I)^{-1}\Lambda
Qw^\ast,\]</span> 其中<span
class="math inline">\(Q\)</span>为特征向量矩阵。</p>
<p>可见<span class="math inline">\(\tilde{w}\)</span>在第<span
class="math inline">\(i\)</span>个特征向量方向上，将<span
class="math inline">\(w^\ast\)</span>在该方向分量缩放了<span
class="math inline">\(\frac{\lambda_i}{\lambda_i+\alpha}\)</span>倍。<span
class="math inline">\(\lambda_i\gg\alpha\)</span>的特征方向上几乎不变，
<span
class="math inline">\(\lambda_i\ll\alpha\)</span>的特征方向上趋向于0（但只要<span
class="math inline">\(w^\ast_i\not=0\)</span>，就不会变成0）。</p>
<p>直观上，L2
norm对曲率（体现为Hessian的特征值大小）表现出偏好，曲率小的方向，即沿该方向移动无助于减小损失函数值的方向，<span
class="math inline">\(w\)</span>在该方向对应的分量会由于weight
decay效应而衰减。大曲率方向上的衰减则小得多。</p>
<blockquote>
<p>从分量角度， <span
class="math display">\[\tilde{w}_i=\frac{H_{i,i}}{H_{i,i}+\alpha}w^\ast_i,\]</span>
可见若<span class="math inline">\(w^\ast_i\not=0\)</span>，则<span
class="math inline">\(\tilde{w}_i\not=0\)</span>。</p>
</blockquote>
<p>L2 norm等价于以高斯分布为先验的MAP估计。（请参考下一篇文章）</p>
<h3 id="l1-norm">L1 norm</h3>
<p>L1 norm，即Lasso， <span
class="math display">\[\Omega(w)=\Vert{w}\Vert_1=\sum_i{|w_i|}.\]</span></p>
<p>总体效果上，同样考虑二阶近似，正则化后的解为 <span
class="math display">\[\tilde{w}_i=\mathrm{sign}(w^\ast_i)\max\left\{|w^\ast_i|-\frac{\alpha}{H_{i,i}},
0\right\},\]</span> 其中<span
class="math inline">\(H_{i,i}\)</span>是Hessian的对角线元素。</p>
<p>可见若 <span
class="math display">\[w^\ast_i\leq\frac{\alpha}{H_{i,i}},\]</span>
则最优 <span class="math inline">\(\tilde{w}_i\)</span> 为0（cf. L2
norm不会强制变为0）。</p>
<p>否则方向不变，绝对值减少<span
class="math inline">\(\frac{\alpha}{H_{i,i}}\)</span>。这就是L1
norm导致的“稀疏性”。</p>
<p>L1
norm等价于以各向同的Laplace分布为先验的MAP。（请参考下一篇文章）</p>
<h3
id="范数正则化项和带约束的优化之间的关联">范数正则化项和带约束的优化之间的关联</h3>
<p>从带约束的优化出发，假设给定一个常数<span
class="math inline">\(k&gt;0\)</span>，对范数有约束<span
class="math inline">\(\Omega(w) &lt; k\)</span>，记KKT乘子为<span
class="math inline">\(\alpha\geq 0\)</span>，则构造目标函数 <span
class="math display">\[\mathcal{L}(w, \alpha; X, y)=J(w; X,
y)+\alpha(\Omega(w)-k),\]</span> 对应的无约束优化最优解为 <span
class="math display">\[w^\ast = \arg\min_{w}\max_{\alpha, \alpha\geq 0}
\mathcal{L}(w, \alpha; X, y).\]</span></p>
<p>假设我们已经确定了最优解中的<span
class="math inline">\(\alpha^\ast&gt;0\)</span>，正的<span
class="math inline">\(\alpha\)</span>体现了约束的意义（如果<span
class="math inline">\(\alpha=0\)</span>，则约束不起作用）。
在给定该<span
class="math inline">\(\alpha^\ast\)</span>时，优化问题转化为 <span
class="math display">\[w^\ast = \arg\min_{w}\mathcal{L}(w, \alpha^\ast;
X, y) = \arg\min_{w} J(w; X, y)+\alpha^\ast\Omega(w).\]</span> 注意<span
class="math inline">\(-\alpha^\ast k\)</span>一项因为与<span
class="math inline">\(w\)</span>无关而省略。</p>
<p>上式从形式上与前面讨论的带Lp范数正则化项的损失函数<span
class="math inline">\(\tilde{J}(\cdot)\)</span>完全一致，只不过在“正则化”语境下，我们预先给定了这个<span
class="math inline">\(\alpha^\ast\)</span>。也即，Lp范数正则化相当于给原问题附加了
<em>``<span class="math inline">\(w\)</span>在某个半径为<span
class="math inline">\(k\)</span>的Lp-ball内"</em> 这一约束条件，<span
class="math inline">\(k\)</span>理论上可以由损失函数<span
class="math inline">\(J\)</span>和我们给定的<span
class="math inline">\(\alpha\)</span>确定，但一般不会确切求解。只需要注意一个原则：alpha越大，对应的k越小。这是一种隐式约束。</p>
<p>如果需要显式约束，可以用重投影优化，即每次更新一步后，将更新后的<span
class="math inline">\(w\)</span>重新投影回约束空间内（如L2-ball）。比如要求对权重矩阵每列（i.e.
神经网络一层中的一个神经元的权重）的范数单独约束，则一般需要显式约束。</p>
<h3 id="reference">Reference</h3>
<p><a href="https://www.deeplearningbook.org/">[1]</a> Goodfellow, Ian,
Yoshua Bengio, and Aaron Courville. Deep learning. MIT press, 2016.</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>优化</tag>
        <tag>深度学习</tag>
        <tag>正则化</tag>
      </tags>
  </entry>
  <entry>
    <title>关于深度学习中的优化目标</title>
    <url>/2021/09/10/%E5%85%B3%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87/</url>
    <content><![CDATA[<p>前一篇文章提到了L2 norm（weight
decay）和以高斯分布为先验的最大后验估计（Maximum a
Posteriori，MAP）的等价性，顺手整理一下和深度学习优化目标相关的几个概念。</p>
<span id="more"></span>
<p>记朴素的损失函数（loss function）为<span
class="math inline">\(J(w;X,y)\)</span>。一般意义上容易想到的“损失”如均方误差（Mean
Square Error，MSE）： <span
class="math display">\[\mathrm{MSE}=\frac{1}{m}\sum_{i=1}^m
\Vert\hat{y}^{(i)} - y^{(i)}\Vert_2^2,\]</span> 其中，假设模型为<span
class="math inline">\(f(x;w)\)</span>，则预测结果<span
class="math inline">\(\hat{y}^{(i)}=f(x^{(i)};w)\)</span>.
深度学习/机器学习可以直接优化这个损失函数。</p>
<p>更广义而言，深度学习/机器学习所优化的函数又不限于“损失”，不妨称为优化目标函数（target
function），当然也可以称为（广义的）损失函数。针对不同情况，优化目标可以如以下几类：</p>
<ul>
<li>狭义的损失函数，如MSE；</li>
<li>负对数似然，对应于最大似然估计（Maximum Likelihood
Estimation，MLE）；</li>
<li>两个分布的距离，如交叉熵（Cross Entropy）、KL散度（KL
Divergence）；</li>
<li>带正则项的目标函数：<span class="math inline">\(J(w;X,y) +
\alpha\Omega(w), \alpha&gt;0\)</span>；</li>
<li>带先验的负对数似然，对应于最大后验估计（MAP）：<span
class="math inline">\(-\ell(w;X,y)-\log p(w)\)</span>。</li>
</ul>
<p>以上各目标函数都应当最小化以取得最优参数值。</p>
<h3 id="香农熵交叉熵和kl散度">香农熵、交叉熵和KL散度</h3>
<p>单点取值对应的<strong>自信息</strong>： <span
class="math display">\[I(x) = -\log P(x).\]</span></p>
<p>随机变量分布的<strong>香农熵</strong>： <span
class="math display">\[H(X) = \mathbb{E}_{X\sim
P}[I(x)]=-\mathbb{E}_{X\sim P}[\log P(x)].\]</span></p>
<p>KL散度： <span class="math display">\[\mathrm{KL}(P||Q) =
\mathbb{E}_{X\sim P}\left[\log\frac{P(x)}{Q(x)}\right] =
\mathbb{E}_{X\sim P}\left[\log P(x) - \log Q(x)\right].\]</span></p>
<p>交叉熵： <span class="math display">\[H(P,Q) = -\mathbb{E}_{X\sim
P}[\log Q(x)].\]</span></p>
<blockquote>
<p>注意：交叉熵衡量任意两个分布，不绑定于softmax层输出预测概率和one-hot
label之间的交叉熵形式。（“花书”注）</p>
</blockquote>
<p>因此有 <span class="math display">\[H(P, Q) = H(P) +
\mathrm{KL}(P||Q).\]</span></p>
<h3 id="mle交叉熵和kl散度的等价性">MLE、交叉熵和KL散度的等价性</h3>
<p>在机器学习语境下，假设数据服从的经验（empirical）分布为<span
class="math inline">\(\hat{p}(x)\)</span>，模型预测分布为<span
class="math inline">\(q(x;\theta)\)</span>.</p>
<p>MLE估计优化目标为 <span class="math display">\[\arg\max_\theta
\sum_{i=0}^m\log q(x^{(i)};\theta).\]</span>
这等价于在训练数据的经验分布上的期望： <span
class="math display">\[\arg\max_\theta \mathbb{E}_{X\sim \hat{p}}[\log
q(x^{(i)};\theta)].\]</span></p>
<p>而用KL散度作为优化目标，有： <span
class="math display">\[\arg\min_\theta \mathrm{KL}(\hat{p}||q)=
\arg\min_\theta \mathbb{E}_{X\sim \hat{p}}[\log \hat{p}(x^{(i)}) - \log
q(x^{(i)};\theta)].\]</span></p>
<p>假设数据生成过程固定，则优化目标与<span class="math inline">\(\log
\hat{p}(x^{(i)})\)</span>一项无关，那么该优化目标等价于 <span
class="math display">\[\arg\min_\theta -\mathbb{E}_{X\sim \hat{p}}[\log
q(x^{(i)};\theta)],\]</span> 这与MLE完全等价。</p>
<p>当优化目标为交叉熵<span class="math inline">\(H(\hat{p},
q)\)</span>时，假设数据生成过程固定，则最小化交叉熵<span
class="math inline">\(H(\hat{p}, q)\)</span>等价于最小化KL散度<span
class="math inline">\(\mathrm{KL}(\hat{p}||q)\)</span>。</p>
<p>因此，MLE、交叉熵和KL散度作为优化目标函数相互等价。</p>
<h3
id="高斯分布假设下mse和mle的等价性">高斯分布假设下MSE和MLE的等价性</h3>
<p>MSE的使用场合大多为有监督学习下，对条件概率<span
class="math inline">\(p(y|x;\theta)\)</span>进行建模的情况。因此这里考虑条件似然。以MLE作为目标函数，假设样本i.i.d.，则优化目标为
<span class="math display">\[\arg\max_\theta \log p(Y|X;\theta) =
\arg\max_\theta\sum_{i=1}^m \log p(y^{(i)}|x^{(i)};\theta).\]</span></p>
<p>假设模型预测结果为<span
class="math inline">\(\hat{y}(x;w)\)</span>，定义模型输出概率服从以预测结果为均值的高斯分布：<span
class="math inline">\(p(y|x;w)=\mathcal{N}(y;\hat{y}(x;w),
\sigma^2)\)</span>，其中方差<span
class="math inline">\(\sigma^2\)</span>给定. 代入MLE优化目标： <span
class="math display">\[\arg\max_\theta\sum_{i=1}^m \log
q(y^{(i)}|x^{(i)};\theta)=\arg\min_\theta\sum_{i=1}^m\frac{\vert\hat{y}^{(i)}(x^{(i)};w)
- y^{(i)}\vert^2}{2\sigma^2},\]</span> 其中忽略了一些不含<span
class="math inline">\(w\)</span>的项。</p>
<p>该函数的最优解与MSE最优解完全等价。</p>
<blockquote>
<p>简单起见，这里假设label <span
class="math inline">\(y\)</span>为标量。<span
class="math inline">\(y\)</span>为向量的情况下，假设模型输出概率为一多维高斯分布，给定协方差矩阵（如对角阵<span
class="math inline">\(I\)</span>）即可。</p>
</blockquote>
<h3
id="带正则项的优化目标与map的等价性">带正则项的优化目标与MAP的等价性</h3>
<p>MAP优化目标为 <span class="math display">\[\arg\max_\theta
p(\theta|x)=\arg\max_\theta p(x|\theta)+\log p(\theta).\]</span></p>
<p>假设先验<span
class="math inline">\(p(\theta)\)</span>服从高斯分布<span
class="math inline">\(\mathcal{N}(\theta; 0,
\frac{1}{\alpha}I)\)</span>，则 <span class="math display">\[-\log
p(\theta)\propto \alpha \theta^\top \theta,\]</span> 即weight
decay惩罚项，也即L2 norm正则项。</p>
<p>类似的，假设先验<span
class="math inline">\(p(\theta)\)</span>服从各向同的Laplace分布<span
class="math inline">\(\mathrm{Laplace}(\theta_i; 0,
\frac{1}{\alpha})\)</span>，则 <span class="math display">\[-\log
p(\theta)\propto \alpha \Vert\theta\Vert_1,\]</span> 即L1
norm正则项。</p>
<h3 id="reference">Reference</h3>
<p><a href="https://www.deeplearningbook.org/">[1]</a> Goodfellow, Ian,
Yoshua Bengio, and Aaron Courville. Deep learning. MIT press, 2016.</p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>交叉熵</tag>
        <tag>优化</tag>
        <tag>深度学习</tag>
        <tag>损失函数</tag>
        <tag>KL散度</tag>
        <tag>MLE估计</tag>
        <tag>MAP估计</tag>
      </tags>
  </entry>
  <entry>
    <title>华为暑期实习软件开发笔试复盘</title>
    <url>/2021/03/31/%E5%8D%8E%E4%B8%BA%E6%9A%91%E6%9C%9F%E5%AE%9E%E4%B9%A0%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E7%AC%94%E8%AF%95%E5%A4%8D%E7%9B%98/</url>
    <content><![CDATA[<p><strong>声明</strong>：本文只是本人笔试后对试题的复盘反思，从未由此牟利.如侵犯任何一方权利，请通过本站提供的联系方式联系本人，本人将立刻删除本文。</p>
<span id="more"></span>
<hr />
<p>3月30号大清早，正准备出门去北京植物园春游，就收到华为HR消息，说3月31号笔试...不过还是去春游了，玩了一天:-)</p>
<p>虽然上周就知道会有笔试，也稍微复健了一下，但最近实在太忙了，基本等于没复习。昨晚到牛客网练了一下输入输出，今天上午去公司忙项目，中午回学校把图形学作业的收尾工作写完、写了报告交了作业，之后上法语课，课后还和同学编排了下节课的对话。晚饭吃了个水煮肉，这就该回宿舍开始考试了。</p>
<p>一共三道题两小时，自己处理IO，经典套路，第一题水题，第二题看起来花哨实际很简单，第三题是个很传统的DP，可以说中规中矩吧，甚至有点偏简单？但对于一向算法题废物还毫无准备的我，今天提前挺久做完了也是挺意外。</p>
<h3 id="第一题足球循环赛">第一题：足球循环赛</h3>
<p>输入比分</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">A-B 1:2</span><br><span class="line">B-C 3:0</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>胜得3分，平得1分，负得0分。最终输出排行榜和积分</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">B 6,A 0,C 0...</span><br></pre></td></tr></table></figure>
<p>对于写Python的我，实在是水题...但是遇到了两个意外情况（一看就是平时不刷题）。首先是我习惯读这种不知道多少行输入时用<code>ErrorEOF</code>控制，但牛客网似乎把异常直接接管了...还好昨天练了一下IO，改成了</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>另一个更可笑了，卡了我十多分钟的问题竟然是我忘了<code>sorted</code>怎么传参了...<code>key</code>和<code>reverse</code>都必须用keyword传入，不能用位置传。还好可以用自己的IDE，我倒是真没有Python
IDE，就在VS
Code的terminal里打开Python，用<code>help(sorted)</code>看了一眼才想起来...</p>
<h3 id="第二题有多少人来party">第二题：有多少人来party</h3>
<p>没见过的新奇问题。输入一个list如<code>[1,2,1]</code>，每个数字是一个人报告的party上和自己戴的帽子颜色相同的人数。只有部分人报告了。求party至少来了多少人。</p>
<p>其实很简单，如果一个人报告了1，那么这个颜色一共也就2个人。那么如果有三个1，说明至少有两种不同颜色都各有2个人。所以考场上想到的一个方法是把list排个序，然后给数字加括号：</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">(1,1),(2)</span><br></pre></td></tr></table></figure>
<p>每组括号是一个颜色，所以例子里有两种颜色，颜色A有2个人，颜色B有3个人（尽管其中只有1个人报告了）。</p>
<p>这样的复杂度是<span class="math inline">\(O(n\log
n)\)</span>，因为要排序。但交了卷吃夜宵的时候回想这个问题，其实根本不用排序，本质上就是个往桶里扔球的问题。报告的每个unique的数字是一个桶（i表示有i+1个人同一种颜色），扔完所有球以后，如果桶i有n个球，那么这个桶可以分成<span
class="math inline">\(ceil(\frac{n}{i+1})\)</span>组，一组是一种颜色，这个桶至少代表了<span
class="math inline">\((i+1) \times ceil(\frac{n}{i+1})\)</span>人。</p>
<p>所以又用哈希表（Python的<code>dict</code>）重写了一遍，只用10行代码左右就能写完...复杂度降到了<span
class="math inline">\(O(n)\)</span>。</p>
<h3 id="第三题游标寻找字符">第三题：游标寻找字符</h3>
<p>给定一个字符串src，一个目标字符串dst，和指向src中某字符的游标的起始位置pos。游标可以左右移动，每次一步，最左边往左一步可以到最右边，最右边同理（循环数组）。现要用游标在src中依次找到dst中所有字符，求最少步数。</p>
<p>一开始很intuitively想用greedy，但是转念一想这么明显的坑...随便找了个例子就发现greedy肯定不行，比如</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">src: axxxxxxxyzby</span><br><span class="line">pos:          ^</span><br><span class="line">dst: ya</span><br></pre></td></tr></table></figure>
<p>应该先找最右边的y，但greedy会先找z左边的y。那自然是DP了。递推关系式很简单：</p>
<p><span
class="math display">\[\text{min_step}(j,i)=\min_{p:src[p]=dst[j]}\left\{\text{min_step}(j+1,p)+\text{loop_dist}(i,p)\right\},\]</span></p>
<p>其中<span
class="math inline">\(i\)</span>表示当前游标在src中的位置，<span
class="math inline">\(j\)</span>表示下一个要匹配字符在的dst中的位置。<code>loop_dist</code>表示在循环游标设定下两点的距离。</p>
<p>一个技巧是先扫描一遍src串，记下每个字符出现的所有位置，以此决定上式中求<span
class="math inline">\(\min\)</span>时<span
class="math inline">\(p\)</span>的范围。</p>
<p>DP有两个变量，复杂度是<span
class="math inline">\(O(mn)\)</span>，<span
class="math inline">\(m,n\)</span>分别表示src和dst的长度。</p>
<h3 id="写在最后">写在最后</h3>
<p>用Python写这些东西其实真的很简单。比如DP可以直接搞个<code>dict</code>当memory，用<span
class="math inline">\((i,j)\)</span>二元组当key就行，传统写C/C++一般会开个二维数组来存。当然当代C++鼓励大家多用STL，那么<code>std::map</code>之类的用起来应该也挺方便。但不得不说，同样的东西，用C++来写总会长一点，而且C++时间要求相对更严格（也可能是更宽松了？不知道开O3的C++
11到底能比Python 3.9快多少倍...），感觉还是写Python更轻松一点。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>华为</tag>
        <tag>面经</tag>
        <tag>哈希表</tag>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title>【整理】卷积本质和运算</title>
    <url>/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/</url>
    <content><![CDATA[<p>CMU 的 16720 "Computer Vision"
第二节课“复习”了卷积相关概念，当然对我来说基本是预习:-)
而且因为太累了上课还睡着了一会儿，导致基本没咋听懂。今天看PPT发现上面除了图啥也无，还真有我自己做PPT的风范:-)
于是在知乎上学习了一下卷积的定义、本质和运算方法。</p>
<p>来源： <a
href="https://www.zhihu.com/question/22298352">如何通俗易懂地解释卷积？</a></p>
<span id="more"></span>
<p>有两个回答基本讲清楚了，一个是从“反褶”的角度，角度是输出信号在每个时间点上的信号的计算方法；另一个是从“平移+叠加”的角度，角度是输入信号通过响应的每个时间点后在输出信号上的分量。</p>
<h2 id="平移叠加">平移+叠加</h2>
<p>作者：张俊博
链接：https://www.zhihu.com/question/22298352/answer/34267457 来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>不推荐用“反转/翻转/反褶/对称”等解释卷积。好好的信号为什么要翻转？导致学生难以理解卷积的物理意义。这个其实非常简单的概念，国内的大多数教材却没有讲透。直接看图，不信看不懂。以离散信号为例，连续信号同理。已知</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/1-1.jpg" class="">
<p>已知</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/1-2.jpg" class="">
<p>下面通过演示求的过程，揭示卷积的物理意义。第一步，乘以并平移到位置0：</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/1-3.jpg" class="">
<p>第二步，乘以并平移到位置1：</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/1-4.jpg" class="">
<p>第三步，乘以并平移到位置2：</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/1-5.jpg" class="">
<p>最后，把上面三个图叠加，就得到了：</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/1-6.jpg" class="">
<p>简单吧？无非是平移（没有反褶！）、叠加。</p>
<p>从这里，可以看到卷积的重要的物理意义是：一个函数（如：单位响应）在另一个函数（如：输入信号）上的加权叠加。</p>
<p>重复一遍，这就是卷积的意义：加权叠加。对于线性时不变系统，如果知道该系统的单位响应，那么将单位响应和输入信号求卷积，就相当于把输入信号的各个时间点的单位响应
加权叠加，就直接得到了输出信号。</p>
<p>通俗的说：</p>
<p><strong>在输入信号的每个位置，叠加一个单位响应，就得到了输出信号。这正是单位响应是如此重要的原因。</strong></p>
<p><strong>在输入信号的每个位置，叠加一个单位响应，就得到了输出信号。这正是单位响应是如此重要的原因。</strong></p>
<p><strong>在输入信号的每个位置，叠加一个单位响应，就得到了输出信号。这正是单位响应是如此重要的原因。</strong></p>
<blockquote>
<p>一个很有价值的评论：楼主这种做法和通常教材上的区别在于：书上先反褶再平移，把输入信号当作一个整体，一次算出一个时间点的响应值；而楼主把信号拆开，一次算出一个信号在所有时间的响应值，再把各个信号相加。两者本质上是相同的。
—— <a href="https://www.zhihu.com/people/he-he-42-16"><span
class="citation" data-cites="吃玉米的粥">@吃玉米的粥</span></a></p>
</blockquote>
<h2 id="反褶">反褶</h2>
<p>作者：palet
链接：https://www.zhihu.com/question/22298352/answer/637156871
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<h3 id="对卷积的困惑">对卷积的困惑</h3>
<p>卷积这个概念，很早以前就学过，但是一直没有搞懂。教科书上通常会给出定义，给出很多性质，也会用实例和图形进行解释，但究竟为什么要这么设计，这么计算，背后的意义是什么，往往语焉不详。作为一个学物理出身的人，一个公式倘若倘若给不出结合实际的直观的通俗的解释（也就是背后的“物理”意义），就觉得少了点什么，觉得不是真的懂了。</p>
<p>教科书上一般定义函数 <span class="math inline">\(f,g\)</span> ​的卷积
<span class="math inline">\(f*g(n)\)</span> ​如下：</p>
<p>连续形式：</p>
<p><span
class="math display">\[(f*g)(n)=\int_{-\infty}^{\infty}{f(\tau)g(n-\tau)\mathrm{d}\tau}\]</span></p>
<p>​​​离散形式：</p>
<p><span class="math display">\[(f*g)(n)=\sum_{\tau =
-\infty}^{\infty}{f(\tau)g(n-\tau)}\]</span></p>
<p>​​并且也解释了，先对g函数进行翻转，相当于在数轴上把g函数从右边褶到左边去，也就是卷积的“卷”的由来。然后再把g函数平移到n，在这个位置对两个函数的对应点相乘，然后相加，这个过程是卷积的“积”的过程。这个只是从计算的方式上对公式进行了解释，从数学上讲无可挑剔，但进一步追问，为什么要先翻转再平移，这么设计有何用意？还是有点费解。</p>
<p>在知乎，已经很多的热心网友对卷积举了很多形象的例子进行了解释，如卷地毯、丢骰子、打耳光、存钱等等。读完觉得非常生动有趣，但过细想想，还是感觉有些地方还是没解释清楚，甚至可能还有瑕疵，或者还可以改进（这些后面我会做一些分析）。带着问题想了两个晚上，终于觉得有些问题想通了，所以就写出来跟网友分享，共同学习提高。不对的地方欢迎评论拍砖。。。</p>
<p>明确一下，这篇文章主要想解释两个问题：1.
卷积这个名词是怎么解释？“卷”是什么意思？“积”又是什么意思？2.
卷积背后的意义是什么，该如何解释？</p>
<h3 id="考虑的应用场景">考虑的应用场景</h3>
<p>为了更好地理解这些问题，我们先给出两个典型的应用场景：</p>
<ol type="1">
<li>信号分析一个输入信号 <span class="math inline">\(f(t)\)</span>
，经过一个线性系统（其特征可以用单位冲击响应函数<span
class="math inline">\(g(t)\)</span>描述）以后，输出信号应该是什么？实际上通过卷积运算就可以得到输出信号。</li>
<li>图像处理输入一幅图像<span
class="math inline">\(f(x,y)\)</span>，经过特定设计的卷积核<span
class="math inline">\(g(x,y)\)</span>进行卷积处理以后，输出图像将会得到模糊，边缘强化等各种效果。</li>
</ol>
<h3 id="对卷积的理解">对卷积的理解</h3>
<p>对卷积这个名词的理解：所谓两个函数的卷积，本质上就是先将一个函数翻转，然后进行滑动叠加。在连续情况下，叠加指的是对两个函数的乘积求积分，在离散情况下就是加权求和，为简单起见就统一称为叠加。</p>
<p>整体看来是这么个过程：
翻转——&gt;滑动——&gt;叠加——&gt;滑动——&gt;叠加——&gt;滑动——&gt;叠加.....</p>
<p>多次滑动得到的一系列叠加值，构成了卷积函数。</p>
<p>卷积的“卷”，指的的函数的翻转，从 <span
class="math inline">\(g(t)\)</span> 变成 <span
class="math inline">\(g(-t)\)</span>
的这个过程；同时，“卷”还有滑动的意味在里面（吸取了网友李文清的建议）。如果把卷积翻译为“褶积”，那么这个“褶”字就只有翻转的含义了。</p>
<p>卷积的“积”，指的是积分/加权求和。有些文章只强调滑动叠加求和，而没有说函数的翻转，我觉得是不全面的；有的文章对“卷”的理解其实是“积”，我觉得是张冠李戴。</p>
<p>对卷积的意义的理解：</p>
<ol type="1">
<li>从“积”的过程可以看到，我们得到的叠加值，是个全局的概念。以信号分析为例，卷积的结果是不仅跟当前时刻输入信号的响应值有关，也跟过去所有时刻输入信号的响应都有关系，考虑了对过去的所有输入的效果的累积。在图像处理的中，卷积处理的结果，其实就是把每个像素周边的，甚至是整个图像的像素都考虑进来，对当前像素进行某种加权处理。所以说，“积”是全局概念，或者说是一种“混合”，把两个函数在时间或者空间上进行混合。</li>
<li>那为什么要进行“卷”？直接相乘不好吗？我的理解，进行“卷”（翻转）的目的其实是施加一种约束，它指定了在“积”的时候以什么为参照。在信号分析的场景，它指定了在哪个特定时间点的前后进行“积”，在空间分析的场景，它指定了在哪个位置的周边进行累积处理。</li>
</ol>
<h3 id="举例说明">举例说明</h3>
<p>下面举几个例子说明为什么要翻转，以及叠加求和的意义。</p>
<h4 id="例1信号分析">例1：信号分析</h4>
<p>如下图所示，输入信号是 <span class="math inline">\(f(t)\)</span>
，是随时间变化的。系统响应函数是 <span
class="math inline">\(g(t)\)</span>
，图中的响应函数是随时间指数下降的，它的物理意义是说：如果在 <span
class="math inline">\(t=0\)</span>
的时刻有一个输入，那么随着时间的流逝，这个输入将不断衰减。换言之，到了
<span class="math inline">\(t=T\)</span> 时刻，原来在 <span
class="math inline">\(t=0\)</span> 时刻的输入 <span
class="math inline">\(f(0)\)</span> 的值将衰减为<span
class="math inline">\(f(0)g(T)\)</span>。</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/2-1.jpg" class="">
<p>​​考虑到信号是连续输入的，也就是说，每个时刻都有新的信号进来，所以，最终输出的是所有之前输入信号的累积效果。如下图所示，在
<span class="math inline">\(T=10\)</span>
时刻，输出结果跟图中带标记的区域整体有关。其中，f(10)因为是刚输入的，所以其输出结果应该是
<span class="math inline">\(f(10)g(0)\)</span>，而时刻<span
class="math inline">\(t=9\)</span>的输入<span
class="math inline">\(f(9)\)</span>，只经过了1个时间单位的衰减，所以产生的输出应该是
<span
class="math inline">\(f(9)g(1)\)</span>，如此类推，即图中虚线所描述的关系。这些对应点相乘然后累加，就是<span
class="math inline">\(T=10\)</span>时刻的输出信号值，这个结果也是<span
class="math inline">\(f\)</span>和<span
class="math inline">\(g\)</span>两个函数在<span
class="math inline">\(T=10\)</span>时刻的卷积值。​</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/2-2.jpg" class="">
<p>​​显然，上面的对应关系看上去比较难看，是拧着的，所以，我们把<span
class="math inline">\(g\)</span>函数对折一下，变成了<span
class="math inline">\(g(-t)\)</span>，这样就好看一些了。看到了吗？这就是为什么卷积要“卷”，要翻转的原因，这是从它的物理意义中给出的。​</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/2-3.jpg" class="">
<p>上图虽然没有拧着，已经顺过来了，但看上去还有点错位，所以再进一步平移<span
class="math inline">\(T\)</span>个单位，就是下图。它就是本文开始给出的卷积定义的一种图形的表述：</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/2-4.jpg" class="">
<p>所以，在以上计算T时刻的卷积时，要维持的约束就是： <span
class="math inline">\(t+ (T-t) = T\)</span>
。这种约束的意义，大家可以自己体会。</p>
<h4 id="例3图像处理">例3：图像处理</h4>
<p>还是引用知乎问题 如何通俗易懂地解释卷积？中 马同学的例子。</p>
<p>图像可以表示为矩阵形式（下图摘自马同学的文章）：</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/2-5.jpg" class="">
<p>对图像的处理函数（如平滑，或者边缘提取），也可以用一个<span
class="math inline">\(g\)</span>矩阵来表示，如：</p>
<p><span class="math display">\[g=\left[
    \begin{matrix}
    b_{-1,-1} &amp; b_{-1,0} &amp; b_{-1,1} \\
    b_{0,-1} &amp; b_{0,0} &amp; b_{0,1} \\
    b_{1,-1} &amp; b_{1,0} &amp; b_{1,1}
\end{matrix}
\right]\]</span></p>
<p>注意，我们在处理平面空间的问题，已经是二维函数了，相当于：</p>
<p><span
class="math display">\[f(x,y)=a_{x,y}g(x,y)=b_{x,y}\]</span></p>
<p>那么函数<span class="math inline">\(f\)</span>和<span
class="math inline">\(g\)</span>的在<span
class="math inline">\((u，v)\)</span>处的卷积 <span
class="math inline">\(f*g(u,v)\)</span> 该如何计算呢？​</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/2-6.jpg" class="">
<p>首先我们在原始图像矩阵中取出<span
class="math inline">\((u，v)\)</span>处的矩阵：</p>
<p><span class="math display">\[f=\left[
    \begin{matrix}
    b_{u-1,v-1} &amp; b_{u-1,v} &amp; b_{u-1,v+1} \\
    b_{u,v-1} &amp; b_{u,v} &amp; b_{u,v+1} \\
    b_{u+1,v-1} &amp; b_{u+1,v} &amp; b_{u+1,v+1}
\end{matrix}
\right]\]</span></p>
<p>然后将图像处理矩阵翻转（这个翻转有点意思，不是延x轴和y轴两个方向翻转，而是沿右上到左下的对角线翻转，这是为了凑后面的内积公式。），如下：</p>
<p><span class="math display">\[g&#39;=\left[
    \begin{matrix}
    b_{1,1} &amp; b_{0,1} &amp; b_{-1,1} \\
    b_{1,0} &amp; b_{0,0} &amp; b_{-1,0} \\
    b_{1,-1} &amp; b_{0,-1} &amp; b_{-1,-1}
\end{matrix}
\right]\]</span></p>
<p>可对比下图：</p>
<img data-src="/2019/08/31/%E5%8D%B7%E7%A7%AF%E6%9C%AC%E8%B4%A8%E5%92%8C%E8%BF%90%E7%AE%97/2-7.jpg" class="">
<p>计算卷积时，就可以用 <span class="math inline">\(f\)</span> 和 <span
class="math inline">\(g&#39;\)</span> 的内积：</p>
<p><span class="math display">\[f*g(u,v)=a_{u-1,v-1}\times
b_{1,1}+a_{u-1,v}\times b_{1,0} +...+ a_{u+1,v+1}\times
b_{-1,-1}\]</span></p>
<p>请注意，以上公式有一个特点，做乘法的两个对应变量a,b的下标之和都是<span
class="math inline">\((u，v)\)</span>，其目的是对这种加权求和进行一种约束。这也是为什么要将矩阵g进行翻转的原因。</p>
<p>以上矩阵下标之所以那么写，并且进行了翻转，是为了让大家更清楚地看到跟卷积的关系。这样做的好处是便于推广，也便于理解其物理意义。实际在计算的时候，都是用翻转以后的矩阵，直接求矩阵内积就可以了。</p>
<p>以上计算的是<span
class="math inline">\((u，v)\)</span>处的卷积，延x轴或者y轴滑动，就可以求出图像中各个位置的卷积，其输出结果是处理以后的图像（即经过平滑、边缘提取等各种处理的图像）。</p>
<p>再深入思考一下，在算图像卷积的时候，我们是直接在原始图像矩阵中取了<span
class="math inline">\((u，v)\)</span>处的矩阵，为什么要取这个位置的矩阵，本质上其实是为了满足以上的约束。因为我们要算<span
class="math inline">\((u，v)\)</span>处的卷积，而g矩阵是3x3的矩阵，要满足下标跟这个3x3矩阵的和是<span
class="math inline">\((u，v)\)</span>，只能是取原始图像中以<span
class="math inline">\((u，v)\)</span>为中心的这个3x3矩阵，即图中的阴影区域的矩阵。</p>
<p>推而广之，如果如果g矩阵不是3x3，而是5x5，那我们就要在原始图像中取以<span
class="math inline">\((u，v)\)</span>为中心的5x5矩阵进行计算。由此可见，这种卷积就是把原始图像中的相邻像素都考虑进来，进行混合。相邻的区域范围取决于g矩阵的维度，维度越大，涉及的周边像素越多。而矩阵的设计，则决定了这种混合输出的图像跟原始图像比，究竟是模糊了，还是更锐利了。</p>
<p>比如说，如下图像处理矩阵将使得图像变得更为平滑，显得更模糊，因为它联合周边像素进行了平均处理：</p>
<p><span class="math display">\[g=\left[
    \begin{matrix}
    \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9} \\
    \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9} \\
    \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9}
\end{matrix}
\right]\]</span></p>
<p>而如下图像处理矩阵将使得像素值变化明显的地方更为明显，强化边缘，而变化平缓的地方没有影响，达到提取边缘的目的：</p>
<p><span class="math display">\[g=\left[
    \begin{matrix}
    -1 &amp; -1 &amp; -1 \\
    -1 &amp; 9 &amp; -1 \\
    -1 &amp; -1 &amp; -1
\end{matrix}
\right]\]</span></p>
<blockquote>
<p>注：观察到上面两个矩阵，所有元素和为1</p>
</blockquote>
<blockquote>
<p>另一个评论：层主解释的很好，图像处理中二维矩阵为什么要翻转还是不能完全理解，记得图像处理中好多滤波过程都没有翻转矩阵，而直接定义成相关，而不是卷积，不知道这样定义有何意义。
—— <a href="https://www.zhihu.com/people/feng-yun-gang-pao"><span
class="citation" data-cites="风云钢炮">@风云钢炮</span></a>
回复：图像处理的二维矩阵和的下标之所以那么写，并且进行了翻转，是为了让大家更清楚地看到跟卷积的关系。这样做的好处是便于推广，也便于理解其物理意义。实际在计算的时候，直接求矩阵内积就可以。
这解释了Lucey说的为什么实际上python库中对图像卷积的操作实际上是corr而不是conv，因为其关于副对角线其实是对称的</p>
</blockquote>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>卷积</tag>
      </tags>
  </entry>
  <entry>
    <title>一年后</title>
    <url>/2021/03/09/%E4%B8%80%E5%B9%B4%E5%90%8E/</url>
    <content><![CDATA[<p>快一年没有更新blog了。一年来发生了很多，生活和想法也有了若干变化。近来感觉记性越来越不好了，有些未来或许有用但又没什么理由/门类写到OneNote里的东西，似乎还是可以放在这里。</p>
<p>之后或许会多写一些这样的流水账，也会有些可以公开的技术文章，但写长文很累，或许有空会写一篇吧。毕竟上周法语课学了一句谚语，«
Petit à petit, l'oiseau fait son nid. »</p>
<p>春天来了，上上周下雪前拍到了第一朵迎春花，今天逸夫馆前的山桃，顶端的枝条也零星开了几多小花。春天真好，每天都觉得充满希望。</p>
<span id="more"></span>
<figure>
<img data-src="2-27-迎春.jpg" alt="2月27日的迎春花" />
<figcaption aria-hidden="true">2月27日的迎春花</figcaption>
</figure>
<figure>
<img data-src="3-8-山桃.jpg" alt="3月8日的山桃" />
<figcaption aria-hidden="true">3月8日的山桃</figcaption>
</figure>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>2021赏花</tag>
      </tags>
  </entry>
  <entry>
    <title>哈希表碰撞（溢出）概率计算</title>
    <url>/2021/03/09/%E5%93%88%E5%B8%8C%E8%A1%A8%E7%A2%B0%E6%92%9E%E6%A6%82%E7%8E%87%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<p>这篇文章简单谈谈目前业界使用的密码学库中，是如何计算哈希表（Hash
table）的桶（bin）碰撞（溢出）概率的。</p>
<p>昨天遇到这样一个问题：在GitHub中，<a
href="https://github.com/osu-crypto/BaRK-OPRF">osu-crypto/BaRK-OPRF</a>这个密码学相关repo中，有如下<a
href="https://github.com/osu-crypto/BaRK-OPRF/blob/6fe35ee9a38a5dcfbad171678e68fa0b539b1589/bOPRFlib/Common/Defines.cpp#L148">代码</a>：</p>
<span id="more"></span>
<figure class="highlight cpp"><figcaption><span>BaRK-OPRF/bOPRFlib/Common/Defines.cpp</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">double</span> <span class="title">getBinOverflowProb</span><span class="params">(u64 numBins, u64 numBalls, u64 binSize, <span class="type">double</span> epsilon = <span class="number">0.0001</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (numBalls &lt;= binSize)</span><br><span class="line">        <span class="keyword">return</span> std::numeric_limits&lt;<span class="type">double</span>&gt;::<span class="built_in">max</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (numBalls &gt; <span class="built_in">unsigned</span>(<span class="number">-1</span>))</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">auto</span> msg = (<span class="string">&quot;boost::math::binomial_coefficient(...) only supports &quot;</span> + std::<span class="built_in">to_string</span>(<span class="built_in">sizeof</span>(<span class="type">unsigned</span>) * <span class="number">8</span>) + <span class="string">&quot; bit inputs which was exceeded.&quot;</span> LOCATION);</span><br><span class="line">        std::cout &lt;&lt; msg &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(msg);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">typedef</span> boost::multiprecision::number&lt;boost::multiprecision::backends::cpp_bin_float&lt;<span class="number">16</span>&gt;&gt; T;</span><br><span class="line">    T sum = <span class="number">0.0</span>;</span><br><span class="line">    T sec = <span class="number">0.0</span>;<span class="comment">// minSec + 1;</span></span><br><span class="line">    T diff = <span class="number">1</span>;</span><br><span class="line">    u64 i = binSize + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (diff &gt; <span class="built_in">T</span>(epsilon) &amp;&amp; numBalls &gt;= i <span class="comment">/*&amp;&amp; sec &gt; minSec*/</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        sum += numBins * boost::math::<span class="built_in">binomial_coefficient</span>&lt;T&gt;(numBalls, i)</span><br><span class="line">            * boost::multiprecision::<span class="built_in">pow</span>(<span class="built_in">T</span>(<span class="number">1.0</span>) / numBins, i) * boost::multiprecision::<span class="built_in">pow</span>(<span class="number">1</span> - <span class="built_in">T</span>(<span class="number">1.0</span>) / numBins, numBalls - i);</span><br><span class="line"></span><br><span class="line">        T sec2 = boost::multiprecision::<span class="built_in">log2</span>(sum);</span><br><span class="line">        diff = boost::multiprecision::<span class="built_in">abs</span>(sec - sec2);</span><br><span class="line">        sec = sec2;</span><br><span class="line"></span><br><span class="line">        i++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">max</span>&lt;<span class="type">double</span>&gt;(<span class="number">0</span>, (<span class="type">double</span>)-sec);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从函数名能看出是在计算哈希表的桶溢出概率（溢出和碰撞其实是一个意思），但就是这个简简单单的<code>while</code>循环，看的人云里雾里。但稍加分析，我们就可以还原出来这段代码其实是在计算这样一个式子：
<span class="math display">\[P\{Hash\; overflows\}=numBins \cdot
\sum_{k=binSize+1}^{numBalls}C_{numBalls}^{i}(1/numBins)^i(1-1/numBins)^{numBalls
- i}.\]</span> 最后的输出结果其实是<span class="math inline">\(-\log_2
P\{Hash\;
overflows\}\)</span>，至于为何如此，后文详谈。先来说说这个式子是怎么来的。</p>
<p>为了方便叙述，我们规范化一下这个问题。</p>
<h3 id="问题设置">问题设置</h3>
<p>一个哈希表可以看成是<span
class="math inline">\(M\)</span>个桶（bin），元素可以看成放进桶里的球（ball），假设每个桶容量（size）相同且固定为<span
class="math inline">\(k\)</span>（很多情况下<span
class="math inline">\(k=1\)</span>）。假设我们已知共有<span
class="math inline">\(N\)</span>个元素（球）要放进桶里，那么哈希表的碰撞概率就等价于</p>
<blockquote>
<p><span class="math inline">\(N\)</span>个球放进<span
class="math inline">\(M\)</span>个桶里，每个桶最多放<span
class="math inline">\(k\)</span>个球，有任意一个桶溢出（放了超过<span
class="math inline">\(k\)</span>个球）的概率。</p>
</blockquote>
<p>下面分步求解。</p>
<h3 id="选定一个桶bin_j里面放了ileq-n个球的概率">选定一个桶<span
class="math inline">\(bin_j\)</span>，里面放了<span
class="math inline">\(i\leq N\)</span>个球的概率？</h3>
<p>这就是一个简单的二项分布：重复<span
class="math inline">\(N\)</span>次把球放进桶的实验，成功（球放进桶<span
class="math inline">\(bin_j\)</span>）的次数为<span
class="math inline">\(i\)</span>的概率为 <span
class="math display">\[P\{X=i\}=C_{N}^{i}(1/M)^i(1-1/M)^{N -
i},\]</span> 不用多说，请查阅“二项分布”相关资料。</p>
<p>一定注意，这里的前提是我们选定了一个桶，就这个桶而言讨论“成功”。</p>
<h3 id="选定一个桶bin_j这个桶溢出的概率">选定一个桶<span
class="math inline">\(bin_j\)</span>，这个桶溢出的概率？</h3>
<p>溢出，即这个桶里放了<span
class="math inline">\(i&gt;k\)</span>个球，那么对上面的<span
class="math inline">\(P\\{X=i\\}\)</span>求和 <span
class="math display">\[P\{bin_j\; overflows\}=\sum_{i=k+1}^{N}
P\{X=i\}=\sum_{i=k+1}^{N}C_{N}^{i}(1/M)^i(1-1/M)^{N - i}.\]</span>
是不是已经看起来很像最开始的式子了？但是还差个系数<span
class="math inline">\(M\)</span>，这是哪里来的？</p>
<h3
id="任意一个桶溢出的概率的上界">任意一个桶溢出的概率（的上界）？</h3>
<p>前面的讨论都是基于已经选定了某一个桶，但事实上我们有<span
class="math inline">\(M\)</span>个桶，其中任意一个溢出都算哈希表溢出，那么我们要用的工具就是取并集。因此哈希表溢出概率为
<span class="math display">\[P\{Hash\;
overflows\}=P\{\cup_{j\in[M]}bin_j\; overflows\}.\]</span></p>
<p>那么问题来了，这个并集怎么算呢？</p>
<p>事实上，很多情况下我们讨论哈希表溢出问题，并不需要确切地知道这个数值，而是要利用这个概率估计哈希表容量应该有多大。我们只需要估计溢出概率的上界，只要容量能满足这个上界，就可以满足我们对哈希表的要求。</p>
<p>为了解决事件的并集概率问题，我们需要借助布尔不等式（Boole's
inequality），也叫联合边界（Union Bound）（其实我之前只知道Union
Bound这个名字，其他都是现查的）。其实很简单，事件并集的概率不超过单独事件发生的概率之和（不要求事件相互独立）。那么上式进一步化为
<span class="math display">\[\begin{aligned}
P\{Hash overflows\}&amp;=P\{\cup_{j\in[M]}bin_j\; overflows\}\leq
\sum_{j=1}^{M}P\{bin_j\; overflows\}\\
&amp;=\sum_{j=1}^{M}\sum_{i=k+1}^{N}C_{N}^{i}(1/M)^i(1-1/M)^{N - i}\\
&amp;=M\sum_{i=k+1}^{N}C_{N}^{i}(1/M)^i(1-1/M)^{N - i}.
\end{aligned}
\]</span> 这不就是我们要求的式子吗？</p>
<p>不过代码里为了加速，用了一个小量<code>epsilon</code>控制精度，如果精度够了就可以及时截断。</p>
<h3 id="为什么要取负对数">为什么要取负对数？</h3>
<p>这个问题要继续往代码下面看。在<a
href="https://github.com/osu-crypto/BaRK-OPRF/blob/6fe35ee9a38a5dcfbad171678e68fa0b539b1589/bOPRFlib/Common/Defines.cpp#L202">这里</a>：</p>
<figure class="highlight cpp"><figcaption><span>BaRK-OPRF/bOPRFlib/Common/Defines.cpp</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="function">u64 <span class="title">get_bin_size</span><span class="params">(u64 numBins, u64 numBalls, u64 statSecParam)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> B = std::<span class="built_in">max</span>&lt;u64&gt;(<span class="number">1</span>, numBalls / numBins);</span><br><span class="line"></span><br><span class="line">    <span class="type">double</span> currentProb = <span class="number">0</span>;</span><br><span class="line">    u64 step = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> doubling = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (currentProb &lt; statSecParam || step &gt; <span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (!step)</span><br><span class="line">            <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(LOCATION);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (statSecParam &gt; currentProb)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (doubling) step = std::<span class="built_in">max</span>&lt;u64&gt;(<span class="number">1</span>, step * <span class="number">2</span>);</span><br><span class="line">            <span class="keyword">else</span>          step = std::<span class="built_in">max</span>&lt;u64&gt;(<span class="number">1</span>, step / <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">            B += step;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            doubling = <span class="literal">false</span>;</span><br><span class="line">            step = std::<span class="built_in">max</span>&lt;u64&gt;(<span class="number">1</span>, step / <span class="number">2</span>);</span><br><span class="line">            B -= step;</span><br><span class="line">        &#125;</span><br><span class="line">        currentProb = <span class="built_in">getBinOverflowProb</span>(numBins, numBalls, B);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> B;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的<code>statSecParam</code>是密码学里的统计安全参数，类似经常听说的SHA256、SHA512里的数字，数字代表bit位数，越大越安全。在这个实现里，这一参数取值范围是<code>uint64</code>的非负整数。</p>
<p>安全参数越大越安全，密码学里碰撞概率（两个本来不同的明文Hash之后结果相同，其实也就是溢出概率）越小越安全；安全参数是非负整数，概率是<span
class="math inline">\([0,1]\)</span>间的实数。如何建立映射关系呢？很简单，就是对概率取负对数，就变成了<span
class="math inline">\([0,\infty)\)</span>的实数，而且越大越安全。这就和安全参数产生了对应关系。</p>
<p>因此，在前面算概率时，就直接返回这个映射过的“概率”，稍后求哈希表容量时，就可以直接和安全参数比较了。</p>
<h3 id="题外话">题外话</h3>
<p>这个问题其实最早是我在CMU的15-451/651
Algorithms课上，Sleator给我们布置的作业题。当时我真是毫无头绪，多亏了John和Wael两位大哥认真讲解，我才搞明白为啥要用那个之前听都没听说过的Union
Bound。没想到这次又在实际中遇到了这个问题，第一次发现Sleator讲的东西是有用的，而不是为了难为我们。</p>
<p>离开美国时走得太仓促，很多东西都没能带走，似乎Algo的lecture
notes我是扔下了。想到这里，多少有点惋惜。只能安慰自己，东隅已逝桑榆非晚。</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>哈希表</tag>
        <tag>密码学</tag>
        <tag>概率</tag>
        <tag>碰撞</tag>
      </tags>
  </entry>
  <entry>
    <title>奇怪的修乐器经历</title>
    <url>/2021/04/19/%E5%A5%87%E6%80%AA%E7%9A%84%E4%BF%AE%E4%B9%90%E5%99%A8%E7%BB%8F%E5%8E%86/</url>
    <content><![CDATA[<p>从小我就深受姥爷影响，什么东西坏了都喜欢试着自己修，也常常能修好。小学好像修过小饭桌的椅子，初中时修的最多的是改正带，当时技术娴熟到时不时帮同学修。修过的钢笔、中性笔等等更是数不胜数。高中之后生活逐渐粗糙，修东西的频率越来越低，但没想到在乐队里，还得时不时修修乐器。</p>
<p>恰好今天修了个奇怪的问题，就简单写写近一年来的修乐器经历，都挺奇怪的。</p>
<span id="more"></span>
<h3 id="年久失修的中音单簧管">年久失修的中音单簧管</h3>
<p>去年从美国回来，归队以后发现黑管声部竟然如此壮大了，三声部塞满了刚升一队的小朋友们，一二声部也有点坐不下了。作为老人，就主动腾腾地方，去吹中音单簧管了（其实我本来想吹低黑，但没抢过前首席——她之前也很欣赏小号来着，怎么现在跟我一样开始喜欢低音乐器了）。</p>
<p>这根中音单簧管相当上乘，布菲RC银牌，但是中音单簧管（中黑）这种乐器实在一言难尽（请参考<a
href="https://youtu.be/q2OJ8eTCPZ4">此视频</a>），常常缺乏存在感，所以如果不是编制如此庞大一般没人吹。结果在我这次接手之前，这件乐器已经两年没人动过了。木管如果很久不吹是需要上油保养的，但显然队里没人管过这件事，所以刚打开就看到管身都发霉变白了，后来还发现上手管裂了将近10cm的缝...修管师傅来了都诧异我是怎么吹响这玩意儿的。当然今天不讲裂缝，讲讲另一个毛病。</p>
<p>中黑在机械结构上和降B黑管有很大差异，一个最明显的地方是泛音键控制两个孔而非一个，正常情况下两个孔同时最多打开一个，开哪个由la键（正面最上面的键）决定，目的是调节降si的音高（这也是为了适应降B黑管的指法，事实上中黑在下手管加了一个键可以吹降si，或许还更准一点）。以上这段话都是我在修下文这个奇怪的毛病时自己研究出来的。</p>
<p>中黑刚上手，我就发现开了泛音键以后经常吹不动，物理意义上的吹不动——好像在吹一根实心木棍，就是振动不起来。当时还完全不明白这就是漏气的重要特征，也还没发现管裂了。就在这种艰苦条件下，我硬是能勉强吹响，还能试图跟大家一起合拍，但吹出来的质量完全是学员班水平...更奇怪的时，这个毛病时有时无，有时候就还能吹，有时候就完全吹不响，非常离谱。</p>
<p>后来摸索清楚了机械结构，逐渐把问题缩小到了泛音键上。这两个孔的盖子就像跷跷板，连在同一根杆的两端，按下la键会抬起跷跷板的一端，另一端的孔就会合上，松开以后一根小弹簧会抬起另一端，进而换另一个孔合上。但因为温度等等的原因，这个跷跷板的弹簧没有足够的弹力抬起应该抬起的一端，导致开错了孔，最终导致意外的漏气。时好时坏也是因为同样原因——如果我从未用过la键，那么每次都会打开正确的孔，一旦按过一次la键，那个打开的孔就再也合不上了，因此吹不响；过一会儿可能因为无意碰到之类的原因，这个孔又合上了，就有好了。</p>
<p>发现问题是最难的，修起来其实还算容易，拿一个小螺丝刀松松杆上的螺丝，减小杆回弹的阻力，弹簧就有足够的弹力把跷跷板推回原位了。</p>
<h3 id="忒修斯的降b木管">忒修斯的降B木管</h3>
<p>升一队也一段时间了，但因为上学期一直在吹中黑，队里就没给我分降B木管。但这学期中国曲子多，全都没写中黑，二声部又有点缺人，于是中国曲子我又回来吹降B。但我自己也一直没买木管，所以还在用大约14年前买的胶管（不得不说，虽然这个胶管没什么牌子，但音色还真可以，至少以我目前的水平，吹它和吹木管感受到的音色差异不算大，主要差异还是木管吹起来更通畅更灵活一点）。</p>
<p>然而这学期还带了一个徒弟，发现徒弟的管比我的还好...而且我的胶管也实在是太老了，很多磨损之类的毛病，修管师傅都说没救了。于是三天前队里终于还是给我分了个贵重乐器（相对贵重，其实不过是布菲C12而已，但比起去年新买的雅马哈木管应该还是要好一些），那天试音没吹超高音区，感觉没啥问题。不过这根管应该也有一年半（算上疫情）没人用过了。</p>
<p>今天背歌唱祖国的谱子，想试试新到手的木管。歌唱祖国奇高无比，主歌基本一直浮在超高音区，吹高音mi时，突然听到奇怪的振动声，高音fa也是，但re和sol就没有——只要下手管有键按住就没事，如果只有上手管按键就有奇怪的振动。这个问题如此离谱，以至于我吹了这么多年黑管从来没听说过。</p>
<p>为了找到问题出在哪，我从二节开始，逐级向下，把木管和我的胶管拼起来吹（上面是木管下面是胶管），发现如果用我的下手管就没问题，一换上木管的下手管就出毛病，但是下手管并不漏气，吹普通音区也没有任何不正常——离谱。考虑到超高音区的奇怪振动声，我初步判断应该是某个部件的固有频率和超高音相近导致共振。结合高音re和sol没有问题的事实，我尝试在吹mi的时候按住下手管的几个键试试，最终锁定了是低音mi键年久松动，恰好和超高音区产生共振。</p>
<p>问题找到了，但是怎么修呢？换一个键子不太现实，解决共振问题要么就在这个键子上贴一块东西或者磨掉一部分改变固有频率，但都会对乐器本身大动干戈，不太好。这时我突然想到，队里有一个木管和这根管是同一批买进的同型号，只要换一下这两个乐器的下手管说不定就好了。更进一步，上周这一批管都被送去保养了，说不定是修管师傅装反了盒子，也许没问题的下手管才是原来属于这根管的。</p>
<p>一试果然没问题，但是另一个哲学问题出现了：是什么决定了一根黑管是它本身？既然换笛头、二节、喇叭口都是常规操作，那么是上手管和下手管决定吗？但是我对调了两根管的下手管后，它们还是原来的自己吗？</p>
]]></content>
      <categories>
        <category>音乐</category>
      </categories>
      <tags>
        <tag>乐器</tag>
        <tag>单簧管</tag>
        <tag>修理</tag>
      </tags>
  </entry>
  <entry>
    <title>法语基本读音规则表</title>
    <url>/2019/03/19/%E6%B3%95%E8%AF%AD%E5%9F%BA%E6%9C%AC%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99%E8%A1%A8/</url>
    <content><![CDATA[<p>主体基于清华大学单飞老师课件，添加了少量未收录的辅音字母。</p>
<span id="more"></span>
<img data-src="/2019/03/19/%E6%B3%95%E8%AF%AD%E5%9F%BA%E6%9C%AC%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99%E8%A1%A8/%E6%B3%95%E8%AF%AD%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99_%E9%A1%B5%E9%9D%A2_1.png" class="">
<img data-src="/2019/03/19/%E6%B3%95%E8%AF%AD%E5%9F%BA%E6%9C%AC%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99%E8%A1%A8/%E6%B3%95%E8%AF%AD%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99_%E9%A1%B5%E9%9D%A2_2.png" class="">
<img data-src="/2019/03/19/%E6%B3%95%E8%AF%AD%E5%9F%BA%E6%9C%AC%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99%E8%A1%A8/%E6%B3%95%E8%AF%AD%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99_%E9%A1%B5%E9%9D%A2_3.png" class="">
<img data-src="/2019/03/19/%E6%B3%95%E8%AF%AD%E5%9F%BA%E6%9C%AC%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99%E8%A1%A8/%E6%B3%95%E8%AF%AD%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99_%E9%A1%B5%E9%9D%A2_4.png" class="">
<img data-src="/2019/03/19/%E6%B3%95%E8%AF%AD%E5%9F%BA%E6%9C%AC%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99%E8%A1%A8/%E6%B3%95%E8%AF%AD%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99_%E9%A1%B5%E9%9D%A2_5.png" class="">
<img data-src="/2019/03/19/%E6%B3%95%E8%AF%AD%E5%9F%BA%E6%9C%AC%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99%E8%A1%A8/%E6%B3%95%E8%AF%AD%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99_%E9%A1%B5%E9%9D%A2_6.png" class="">
<img data-src="/2019/03/19/%E6%B3%95%E8%AF%AD%E5%9F%BA%E6%9C%AC%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99%E8%A1%A8/%E6%B3%95%E8%AF%AD%E8%AF%BB%E9%9F%B3%E8%A7%84%E5%88%99_%E9%A1%B5%E9%9D%A2_7.png" class="">
]]></content>
      <categories>
        <category>外语</category>
      </categories>
      <tags>
        <tag>读音规则</tag>
        <tag>法语</tag>
      </tags>
  </entry>
  <entry>
    <title>第一篇blog</title>
    <url>/2019/03/03/%E7%AC%AC%E4%B8%80%E7%AF%87blog/</url>
    <content><![CDATA[<h2 id="这是我的第一篇blog">这是我的第一篇blog</h2>
<p>测试图片插入</p>
<img data-src="/2019/03/03/%E7%AC%AC%E4%B8%80%E7%AF%87blog/test.jpg" class="" title="测试">
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>基于Nginx配置Web视频流媒体服务器</title>
    <url>/2019/03/05/%E5%9F%BA%E4%BA%8ENginx%E9%85%8D%E7%BD%AEWeb%E8%A7%86%E9%A2%91%E6%B5%81%E5%AA%92%E4%BD%93%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<p>本来在一心折腾基于Hexo的自建博客，恰好室友提出这样一个需求：在自己的作品集里放一个二维码，扫一下就可以转到一个网页播放自己的视频，但是又要求不能有广告，因此商业性质的视频网站都不能使用。手头刚好有一个AWS的服务器，于是决心尝试一下这类还没碰过的技术。</p>
<p>Web视频流媒体服务器主要应该满足以下几个功能：</p>
<ol type="1">
<li>提供http服务</li>
<li>具备传输视频流的能力</li>
<li>可以在浏览器中播放视频</li>
</ol>
<span id="more"></span>
<p>一般来说，会将视频传输和视频播放<a
href="https://stackoverflow.com/questions/39407346/video-on-demand-websites-server-setup">放置在两个服务器上</a>，因为视频的解码、传输本身就要消耗大量资源。但现在资源有限，因此先拿一个服务器将就一下。</p>
<h3 id="技术选型">技术选型</h3>
<p>查阅资料发现，Nginx本身就提供了视频流传输和播放功能，对于mp4格式，只需要借用现成插件即可。</p>
<ul>
<li>Nginx: nginx-1.15.9</li>
<li>mp4: nginx_mod_h264_streaming-2.2.7</li>
</ul>
<p>另外，在尝试使用Nginx自带播放器播放，发现加载速度极慢难以忍受后，选择使用JW
Player</p>
<ul>
<li>播放器: <a href="https://www.jwplayer.com/">JW Player</a></li>
</ul>
<h3 id="安装nginx">安装nginx</h3>
<p>需要手动编译，以包含一些需要的附加功能（如mp4等）</p>
<p>nginx_mod_h264_streaming的下载地址:
http://h264.code-shop.com/trac/wiki/Mod-H264-Streaming-Nginx-Version2</p>
<p>nginx-rtmp-module下载地址:
https://github.com/arut/nginx-rtmp-module</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install libpcre3 libpcre3-dev     <span class="comment"># nginx需要</span></span><br><span class="line">$ sudo apt install libssl-dev</span><br><span class="line">$ sudo apt-get install zlib1g-dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 nginx</span></span><br><span class="line">$ wget http://nginx.org/download/nginx-1.15.9.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 h264 mod</span></span><br><span class="line">$ wget http://h264.code-shop.com/download/ngi7.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 rtmp</span></span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/arut/nginx-rtmp-module</span><br><span class="line"></span><br><span class="line">$ tar -zxvf nginx-1.15.9.tar.gz</span><br><span class="line">$ tar -zxvf nginx_mod_h264_streaming-2.2.7.tar.gz</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> nginx-1.15.9/</span><br><span class="line">$ ./configure --prefix=/usr/local/nginx --add-module=../nginx_mod_h264_streaming-2.2.7 \</span><br><span class="line"> --add-module=../nginx-rtmp-module --with-http_flv_module --with-http_mp4_module \</span><br><span class="line"> --with-http_gzip_static_module --with-http_stub_status_module</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>此时如果执行<code>make</code>会报错：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">In file included from ../nginx_mod_h264_streaming-2.2.7/src/ngx_http_h:</span><br><span class="line">../nginx_mod_h264_streaming-2.2.7/src/ngx_http_streaming_module.c: In ndler’:</span><br><span class="line">../nginx_mod_h264_streaming-2.2.7/src/ngx_http_streaming_module.c:158:st_t &#123;aka struct ngx_http_request_s&#125;’ has no member named ‘zero_in_uriri’?</span><br><span class="line">   <span class="keyword">if</span> (r-&gt;zero_in_uri)</span><br><span class="line">          ^~~~~~~~~~~</span><br><span class="line">          plus_in_uri</span><br><span class="line">objs/Makefile:1262: recipe <span class="keyword">for</span> target <span class="string">&#x27;objs/addon/src/ngx_http_h264_st</span></span><br><span class="line"><span class="string">make[1]: *** [objs/addon/src/ngx_http_h264_streaming_module.o] Error 1</span></span><br><span class="line"><span class="string">make[1]: Leaving directory &#x27;</span>/home/username/downloads/nginx-1.15.9<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Makefile:11: recipe for target &#x27;</span>install<span class="string">&#x27; failed</span></span><br><span class="line"><span class="string">make: *** [install] Error 2</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>
<p>编辑<code>objs/Makefile</code>，去掉编译选项的<code>-Werror</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo make install</span><br><span class="line">$ sudo ln -s /usr/local/nginx/sbin/nginx /usr/bin/nginx</span><br><span class="line">$ sudo nginx</span><br></pre></td></tr></table></figure>
<p>此时通过浏览器访问服务器，若看到默认欢迎页面，说明nginx安装成功。</p>
<h3 id="配置nginx">配置nginx</h3>
<p>在若干次尝试中借鉴了多篇文章，最终的配置如下：</p>
<figure class="highlight plaintext"><figcaption><span>/usr/local/nginx/conf/nginx.conf</span></figcaption><table><tr><td class="code"><pre><span class="line">#user  nobody;</span><br><span class="line">worker_processes  4;</span><br><span class="line"></span><br><span class="line">error_log  logs/error.log;</span><br><span class="line">#error_log  logs/error.log  notice;</span><br><span class="line">#error_log  logs/error.log  info;</span><br><span class="line"></span><br><span class="line">pid        logs/nginx.pid;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    use epoll;</span><br><span class="line">    worker_connections  65535;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rtmp &#123;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 1935;</span><br><span class="line">        application vod &#123;</span><br><span class="line">            play /home/username/web_service/rtmp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    #keepalive_timeout  0;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line">    server_names_hash_bucket_size 128;</span><br><span class="line">    client_header_buffer_size 32k;</span><br><span class="line">    large_client_header_buffers 4 32k;</span><br><span class="line"></span><br><span class="line">    gzip  on;</span><br><span class="line">    gzip_min_length 1k;</span><br><span class="line">    gzip_buffers 4 16k;</span><br><span class="line">    gzip_comp_level 2;</span><br><span class="line">    gzip_types text/plain application/x-javascript text/css application/xml;</span><br><span class="line">    gzip_vary on;</span><br><span class="line"></span><br><span class="line">    output_buffers 1 32k;</span><br><span class="line">    postpone_output 1460;</span><br><span class="line">    client_header_timeout 3m;</span><br><span class="line">    client_body_timeout 3m;</span><br><span class="line">    send_timeout 3m;</span><br><span class="line">    tcp_nopush on;</span><br><span class="line">    tcp_nodelay on;</span><br><span class="line"></span><br><span class="line">    open_file_cache max=64 inactive=30d;</span><br><span class="line">    open_file_cache_min_uses 1;</span><br><span class="line">    open_file_cache_valid 3m;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       8081;</span><br><span class="line">        server_name  x.x.x.x;</span><br><span class="line"></span><br><span class="line">        charset utf-8;</span><br><span class="line"></span><br><span class="line">        location ~ \.mp4$ &#123;</span><br><span class="line">            root   /home/username/web_service/mp4/;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        location ~ \.m4v$ &#123;</span><br><span class="line">            root   /home/username/web_service/m4v/;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location ~ \.flv$ &#123;</span><br><span class="line">            root   /home/username/web_service/flv/;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location /stat &#123;</span><br><span class="line">            rtmp_stat all;</span><br><span class="line">            rtmp_stat_stylesheet stat.xsl;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location /stat.xsl</span><br><span class="line">            root /home/username/downloads/nginx-rtmp-module;</span><br><span class="line">        &#125;</span><br><span class="line">        #error_page  404              /404.html;</span><br><span class="line"></span><br><span class="line">        # redirect server error pages to the static page /50x.html</span><br><span class="line">        #</span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  x.x.x.x;</span><br><span class="line"></span><br><span class="line">        charset utf-8;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            root   /home/username/web_service/html/;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        # redirect server error pages to the static page /50x.html</span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>主要思路是，在8081端口提供视频文件的HTTP服务，在80端口提供视频播放的页面以供访问。</p>
<p>本来试图通过rtmp推流，但不知道为什么，ffmpeg可以正常读取原视频，写流时也未报错，但无法正常推流，最终作罢。</p>
<p>通过这样的设置，重启nginx：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo nginx -s reload</span><br></pre></td></tr></table></figure>
<p>访问<code>http://x.x.x.x:8081/xxx.mp4</code>即可播放mp4格式的视频。但由于使用了nginx自带的播放器，所以卡顿非常明显，体验不好，考虑使用专用播放器。</p>
<h3 id="播放">播放</h3>
<p>播放器选择了JW
Player，似乎以前是开源的，但现在变为免费试用六个月。只需要在官网注册，即可获得专用代码，复制到html中即可。</p>
<p>编辑<code>/home/username/web_service/html/index.html</code>如下</p>
<figure class="highlight html"><figcaption><span>index.html</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">heml</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 在这里替换自己的JW Player id --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jwplayer.com/libraries/xxxx.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;getParam.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;Content-Type&quot;</span> <span class="attr">content</span>=<span class="string">&quot;text/html;charset=utf-8&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span> <span class="attr">bgcolor</span>=<span class="string">&quot;#000000&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;myElement&quot;</span>&gt;</span>Loading the page...<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">var</span> file_name=<span class="title function_">getParam</span>(<span class="string">&#x27;id&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">log</span>(file_name);</span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">jwplayer</span>(<span class="string">&quot;myElement&quot;</span>).<span class="title function_">setup</span>(&#123;</span></span><br><span class="line"><span class="language-javascript">                <span class="attr">file</span>: <span class="string">&quot;http://x.x.x.x:8081/&quot;</span> + file_name,</span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// image: &quot;data/myposter.jpg&quot;,</span></span></span><br><span class="line"><span class="language-javascript">                <span class="attr">title</span>: file_name,</span></span><br><span class="line"><span class="language-javascript">            &#125;);</span></span><br><span class="line"><span class="language-javascript">        </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>方便起见，编写了一个js函数用来获取GET请求参数，从而指定播放文件</p>
<figure class="highlight js"><figcaption><span>getParam.js</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">getParam</span>(<span class="params">paramName</span>) &#123;</span><br><span class="line">    paramValue = <span class="string">&quot;&quot;</span>, isFound = !<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="variable language_">this</span>.<span class="property">location</span>.<span class="property">search</span>.<span class="title function_">indexOf</span>(<span class="string">&quot;?&quot;</span>) == <span class="number">0</span> &amp;&amp; <span class="variable language_">this</span>.<span class="property">location</span>.<span class="property">search</span>.<span class="title function_">indexOf</span>(<span class="string">&quot;=&quot;</span>) &gt; <span class="number">1</span>) &#123;</span><br><span class="line">        arrSource = <span class="built_in">unescape</span>(<span class="variable language_">this</span>.<span class="property">location</span>.<span class="property">search</span>).<span class="title function_">substring</span>(<span class="number">1</span>, <span class="variable language_">this</span>.<span class="property">location</span>.<span class="property">search</span>.<span class="property">length</span>).<span class="title function_">split</span>(<span class="string">&quot;&amp;&quot;</span>), i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt; arrSource.<span class="property">length</span> &amp;&amp; !isFound) arrSource[i].<span class="title function_">indexOf</span>(<span class="string">&quot;=&quot;</span>) &gt; <span class="number">0</span> &amp;&amp; arrSource[i].<span class="title function_">split</span>(<span class="string">&quot;=&quot;</span>)[<span class="number">0</span>].<span class="title function_">toLowerCase</span>() == paramName.<span class="title function_">toLowerCase</span>() &amp;&amp; (paramValue = arrSource[i].<span class="title function_">split</span>(<span class="string">&quot;=&quot;</span>)[<span class="number">1</span>], isFound = !<span class="number">0</span>), i++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> paramValue == <span class="string">&quot;&quot;</span> &amp;&amp; (paramValue = <span class="literal">null</span>), paramValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么通过<code>http://x.x.x.x/?id=xxx.mp4</code>就可以直接用JW
Player播放目标视频了。效果如下：</p>
<img data-src="/2019/03/05/%E5%9F%BA%E4%BA%8ENginx%E9%85%8D%E7%BD%AEWeb%E8%A7%86%E9%A2%91%E6%B5%81%E5%AA%92%E4%BD%93%E6%9C%8D%E5%8A%A1%E5%99%A8/result.jpg" class="" title="result">
<h3 id="生成二维码">生成二维码</h3>
<p>最后也是最简单的一步，我直接使用了Chrome的插件 "Quick QR Code
Generator!"，打开目标页面，即可直接生成二维码。</p>
<h3 id="结果">结果</h3>
<p>一开始在校园网测试发现还是有卡顿，但室友用4G表示非常流畅……所以还是校园网太垃圾了。室友很满意，承诺要请我吃饭😀</p>
<h3 id="references">References</h3>
<h4 id="核心部分">核心部分</h4>
<p>利用该文安装了支持mp4的Nginx:</p>
<p><a
href="https://www.cnblogs.com/czrwxw/p/3790966.html?utm_source=tuicool&amp;utm_medium=referral">nginx搭建flv、mp4流媒体服务</a></p>
<p>利用这两篇文章完成了Nginx配置和JW Player的使用:</p>
<p><a
href="https://blog.51cto.com/5iqiong/1132639">利用nginx搭建http和rtmp协议的流媒体服务器</a>
<a
href="https://www.cnblogs.com/wanghetao/p/3418744.html">Nginx搭建flv视频点播服务器</a>
（以前文为基础）</p>
<h4 id="nginx">Nginx</h4>
<p><a
href="https://blog.csdn.net/u010889616/article/details/82870076">Ubuntu18.04安装Nginx</a>
<a
href="https://www.cnblogs.com/codingcloud/p/5095066.html">Nginx的启动、停止与重启</a>
<a href="https://www.cnblogs.com/cmfwm/p/7659179.html">Nginx Open File
Cache</a></p>
<h4 id="视频流">视频流</h4>
<p><a
href="https://blog.csdn.net/heng615975867/article/details/80519274">Linux
nginx+rtmp服务器配置实现直播点播</a>
（应该是最成熟的方案，但我最终没有使用rtmp） <a
href="https://www.jianshu.com/p/32417d8ee5b6">理解RTMP、HttpFlv和HLS的正确姿势</a></p>
<h4 id="页面实现">页面实现</h4>
<p><a
href="http://www.php.cn/php-weizijiaocheng-392555.html">PHP如何与js交互数据</a>
（但没有用到） <a
href="https://blog.csdn.net/coloriy/article/details/47394771">开源网页播放器JWplayer使用</a>
<a
href="https://www.cnblogs.com/karila/p/5991340.html">js获取url传递参数，js获取url？号后面的参数</a>
<a
href="https://www.cnblogs.com/godtrue/p/5843093.html">JS-获取URL请求参数</a></p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>视频</tag>
        <tag>流媒体</tag>
        <tag>nginx</tag>
        <tag>linux</tag>
        <tag>服务器</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux安装gmpy2</title>
    <url>/2021/03/11/%E5%AE%89%E8%A3%85gmpy2/</url>
    <content><![CDATA[<p>今天下午花了点时间配环境，主要困难是安装Python的gmpy2包。这是一个多精度浮点数快速计算库，因为依赖很多，所以在Linux上源码编译安装比较麻烦，而在Windows上则比较简单，直接下载预编译的wheel即可。本文参考了一篇<a
href="https://www.cnblogs.com/pcat/p/5746821.html">网络文章</a>，一些细节有所不同。</p>
<p>本文基于的环境是64位的Ubuntu 20.04
LTS，其他版本Linux可能会有出入。一些遇到"permission
denied"的操作（如<code>make install</code>），请更换安装目录，或用<code>sudo</code>。</p>
<p>另外对于多核的机器，可以用类似<code>make -j4</code>的命令并行编译加快速度。</p>
<span id="more"></span>
<h3 id="确定依赖库的安装位置">确定依赖库的安装位置</h3>
<p>编译gmpy2需要许多依赖，但是因为以静态库方式编译，所以这些依赖可以不安装在系统库目录里，随后也可以删除。因此可以自行确定方便的目录。本文中，库的安装目录为<code>$HOME/static</code>，如果需要，记得更换为读者自己的目录。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">mkdir</span> <span class="variable">$HOME</span>/static</span><br></pre></td></tr></table></figure>
<h3 id="安装m4依赖">安装m4依赖</h3>
<p>这是<a
href="https://www.gnu.org/software/m4/m4.html">官方网站</a>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ wget https://ftp.gnu.org/gnu/m4/m4-1.4.18.tar.xz</span><br><span class="line">$ tar Jxf m4-1.4.18.tar.xz</span><br><span class="line">$ <span class="built_in">cd</span> m4-1.4.18</span><br><span class="line">$ ./configure -prefix=<span class="variable">$HOME</span>/static</span><br><span class="line">$ make &amp;&amp; make check &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<h4 id="可能出现的bug">可能出现的bug</h4>
<p>我在编译m4时出现了类似如下bug：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">freadahead.c:91:3: error: #error &quot;Please port gnulib freadahead.c to your platform! Look at the definition of fflush, fread, ungetc on your system, then report this to bug-gnulib.&quot;</span><br><span class="line">   91 |  #error &quot;Please port gnulib freadahead.c to your platform! Look at the definition of fflush, fread, ungetc on your system, then report this to bug-gnulib.&quot;</span><br><span class="line">      |   ^~~~~</span><br></pre></td></tr></table></figure>
<p>经过查询相关资料，根据<a
href="https://blog.csdn.net/Jun626/article/details/104870430">这篇文章</a>提供的方案解决问题。只需在m4源码目录（在这一目录下存在<code>lib</code>目录）下执行</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;s/IO_ftrylockfile/IO_EOF_SEEN/&#x27;</span> lib/*.c</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;#define _IO_IN_BACKUP 0x100&quot;</span> &gt;&gt; lib/stdio-impl.h</span><br></pre></td></tr></table></figure>
<p>给源文件打上补丁即可。（后来回忆或许是我不小心下载了老版本的m4？不过本文给出的1.4.18应该是目前的最新版本了）</p>
<h3 id="安装gmp">安装GMP</h3>
<p>这是<a href="https://gmplib.org/">官方网站</a>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ wget https://gmplib.org/download/gmp/gmp-6.2.1.tar.xz</span><br><span class="line">$ tar Jxf gmp-6.2.1.tar.xz</span><br><span class="line">$ <span class="built_in">cd</span> gmp-6.2.1</span><br><span class="line">$ ./configure --prefix=<span class="variable">$HOME</span>/static --enable-static --disable-shared --with-pic</span><br><span class="line">$ make &amp;&amp; make check &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<h3 id="安装mpfr">安装MPFR</h3>
<p>这是<a href="https://www.mpfr.org/">官方网站</a>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ wget https://www.mpfr.org/mpfr-current/mpfr-4.1.0.tar.xz</span><br><span class="line">$ tar Jxf mpfr-4.1.0.tar.xz</span><br><span class="line">$ <span class="built_in">cd</span> mpfr-4.1.0</span><br><span class="line">$ ./configure --prefix=<span class="variable">$HOME</span>/static --enable-static --disable-shared --with-pic --with-gmp=<span class="variable">$HOME</span>/static</span><br><span class="line">$ make &amp;&amp; make check &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<p>相信读者也看出来了，其实就是每次增加依赖的静态库路径。</p>
<h3 id="安装mpc">安装MPC</h3>
<p>这是<a
href="http://www.multiprecision.org/mpc/download.html">官方网站</a>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ wget https://ftp.gnu.org/gnu/mpc/mpc-1.2.1.tar.gz</span><br><span class="line">$ tar xzf mpc-1.2.1.tar.gz</span><br><span class="line">$ <span class="built_in">cd</span> mpc-1.2.1</span><br><span class="line">$ ./configure --prefix=<span class="variable">$HOME</span>/static --enable-static --disable-shared --with-pic --with-gmp=<span class="variable">$HOME</span>/static --with-mpfr=<span class="variable">$HOME</span>/static</span><br><span class="line">$ make &amp;&amp; make check &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<h3 id="安装gmpy2">安装gmpy2</h3>
<p>终于可以安装gmpy2了。GitHub repo是<a
href="https://github.com/aleaxit/gmpy">aleaxit/gmpy</a>，本文安装的是目前最新release
2.1.0b5。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ wget https://github.com/aleaxit/gmpy/releases/download/gmpy2-2.1.0b5/gmpy2-2.1.0b5.tar.gz</span><br><span class="line">$ tar xzf gmpy2-2.1.0b5.tar.gz</span><br><span class="line">$ <span class="built_in">cd</span> gmpy2-2.1.0b5</span><br><span class="line">$ python setup.py build_ext --static-dir=<span class="variable">$HOME</span>/static</span><br><span class="line">$ python setup.py install</span><br></pre></td></tr></table></figure>
<p>这里官方的<code>INSTALL</code>似乎有点问题，<code>--static-dir</code>选项写错了。到这为止应该已经安装完成了，可以用输出100以内质数测试一下（来源见参考文献[1]）：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gmpy2</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">if</span> gmpy2.is_prime(i):</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>
<h4 id="保存gmpy2.egg">保存<code>gmpy2.egg</code></h4>
<p>如果和队友合作，或者要在不同的几台机器上配相同的环境，每次重复一遍这个流程也太麻烦了。因此可以把这次build的<code>.egg</code>保存下来，之后可以分发，在新机器上用<code>easy_install</code>即可安装。执行完上面的安装以后，应该可以在gmpy2源码目录下的<code>build/bdist.linux-x86_64/gmpy2-2.1.0b5-py3.8-linux-x86_64.egg</code>找到<code>.egg</code>文件。下次安装时可以用</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ easy_install gmpy2-2.1.0b5-py3.8-linux-x86_64.egg</span><br></pre></td></tr></table></figure>
<h3 id="参考文献">参考文献</h3>
<p>[1] <a href="https://www.cnblogs.com/pcat/p/5746821.html">pcat -
gmpy2安装使用方法</a></p>
<p>[2] <a
href="https://github.com/aleaxit/gmpy/blob/ebe32822fdd27b23ce33fa7c1cbade093203d59e/INSTALL">gmpy2开发者
- Installing gmpy2 on Unix/Linux</a></p>
<p>[3] <a
href="https://blog.csdn.net/Jun626/article/details/104870430">Jun626 -
NUC980开源项目24-Please port gnulib freadahead.c to your
platform!</a></p>
]]></content>
      <categories>
        <category>配环境</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>gmpy2</tag>
        <tag>浮点数</tag>
      </tags>
  </entry>
  <entry>
    <title>逻辑右移：不同语言与架构对边界条件的处理</title>
    <url>/2024/12/08/%E9%80%BB%E8%BE%91%E5%8F%B3%E7%A7%BB%EF%BC%9A%E4%B8%8D%E5%90%8C%E8%AF%AD%E8%A8%80%E4%B8%8E%E6%9E%B6%E6%9E%84%E5%AF%B9%E8%BE%B9%E7%95%8C%E6%9D%A1%E4%BB%B6%E7%9A%84%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>讨论一个问题：一个 32 位的整数，如果逻辑右移 32 位，结果如何？</p>
<p>先说结论：对于 C++
是未定义行为，不同架构有不同处理，某些处理从数学角度看可能有问题；对于
CUDA (PTX) 和 Python，行为定义得更好，这个 case 下结果为 0.</p>
<span id="more"></span>
<h3 id="逻辑右移数学视角-vs-硬件视角">逻辑右移：数学视角 vs
硬件视角</h3>
<p>大胆揣测一下，提到“移位”，大部分计算机专业学生的第一反应都是硬件视角，即二进制表示层面，将各
bit 逐个向左或向右移动一个整数 n 位。 这就涉及到 n 的合法范围问题。</p>
<p><strong>注意</strong>，这涉及两个层面的考量，其一是编程语言层面，其二是处理器硬件架构层面，需要区分的地方将特别注明。
另外，主要讨论无符号整数的逻辑右移，也就不涉及有符号数的补 0 还是补 1
问题，也不考虑舍入问题了。</p>
<h4 id="硬件视角">硬件视角</h4>
<p>在 32 位语境下，寄存器位宽最大 32 位，一条 32
位整数的右移指令，原则上只应允许 <span
class="math inline">\(n\in[31]\)</span>，即 1~31 的整数。
当然，这很容易扩展到 <span class="math inline">\(n=0\)</span>
的情况——右移 0 位，相当于什么都不做，也就是一个 nop. 对于 <span
class="math inline">\(n&gt;32\)</span> 的场景，以及 <span
class="math inline">\(n&lt;0\)</span>
的场景，似乎也很好处理，只要禁止这些取值——具体怎么禁止，后文讨论。
事实上，如果定义 n 是一个无符号数，可以直接绕过 <span
class="math inline">\(n&lt;0\)</span> 的场景。
现实中，<strong>架构</strong>层面上，常见的架构应该都是视其为无符号数。</p>
<p>那么 <span class="math inline">\(n=32\)</span> 怎么办呢？
一种直觉的处理是，视为 <span class="math inline">\(n&gt;32\)</span>
的同类——移动 32 或更多位，意味着原始值的任一 bit 都不在输出中，那么 32
和 33 甚至 100 也没什么区别。 尤其是考虑到 31 是一个 5 位无符号数，而从
32 开始就是 6 位及以上的无符号数了（后文将展示为什么位宽有影响）。</p>
<h4 id="数学视角">数学视角</h4>
<p>数学上，一个 N-bit 无符号数 <span
class="math inline">\(x&lt;2^N\)</span> 逻辑右移 <span
class="math inline">\(n\ge 0\)</span> 位，等价于计算 <span
class="math display">\[\left\lfloor \frac{x}{2^n}
\right\rfloor.\]</span></p>
<p>从这个角度看，最合理的做法，首先是将 <span
class="math inline">\(n\)</span>
定义为无符号数，毕竟不应该“右移”之后结果反而变大了——那是左移该做的事。</p>
<p>其次，就是对于 <span class="math inline">\(n\ge
N\)</span>，最合理的做法是直接返回 0 ——这和上面的数学定义是一致的。
因此，完全可以将 <span class="math inline">\(n&gt;N\)</span> 直接看作
<span class="math inline">\(n=N\)</span>，因为效果是相同的。</p>
<p>因此从数学视角，对于 32 位无符号整数，应该将 <span
class="math inline">\(n=32\)</span> 定义为合理场景，并返回 0（所有 bit
都移出寄存器了）。对于 <span
class="math inline">\(n&gt;32\)</span>，直接当成 32 处理即可。</p>
<h3 id="定义和实现">定义和实现</h3>
<p>怎么定义和实现逻辑右移，尤其是 <span
class="math inline">\(n=32\)</span>
这个边界条件？对于正常范围的定义和实现都很明确了，问题其实是讨论“怎么禁止”前述的不合法情况。</p>
<p>在<strong>编程语言</strong>层面，如果编译期（或汇编期）发现 n
是一个不合法取值，可以告警或直接报错。 如果 n
是一个运行时变量，那么编程语言可以做两个选择：</p>
<ol type="1">
<li>不管了，直接当成未定义行为——很直接，但很不负责任，没错，我们 <a
href="https://en.cppreference.com/w/cpp/language/operator_arithmetic">C++</a>
就是这么厉害的语言:-)</li>
<li>对 n 做
clamp（好像没有共识的翻译，或许可以叫“压缩”，但也不应该叫“截断”，毕竟截断应该是一个二进制层面的操作），即小于最小值的视为最小值，大于最大值的视为最大值；<a
href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#logic-and-shift-instructions-shr">CUDA
(PTX)</a> 是这样做的，而且它将 n 定义为无符号数，所以不存在 <span
class="math inline">\(n&lt;0\)</span> 的 case，而 <span
class="math inline">\(n&gt;32\)</span> 将被 clamp 到 32.</li>
</ol>
<blockquote>
<p>C++:</p>
<p><code>lhs &gt;&gt; rhs</code></p>
<p>If the value of <code>rhs</code> is negative or is not less than the
number of bits in <code>lhs</code>, the behavior is
<strong>undefined</strong>.</p>
<hr />
<p>PTX:</p>
<p><code>shr.type d, a, b;</code></p>
<p>Shift <code>a</code> right by the amount specified by unsigned 32-bit
value in <code>b</code>.</p>
</blockquote>
<p><strong>硬件</strong>层面，能想到的处理是 mask 或 clamp. <a
href="https://www.felixcloutier.com/x86/sal:sar:shl:shr">x86</a>
继承了古老的遗产，选择的方案是最简单的 mask，唯一合理的 mask 是 <span
class="math inline">\(2^5-1\)</span>=<code>0x1f</code>.
首先，这确实解决了 <span class="math inline">\(n&lt;0\)</span> 的
case，因为 32 位整数用这个 mask 视角看其实是无符号数。 其次，这导致 x86
上 <span class="math inline">\(n=32\)</span> 只能和 <span
class="math inline">\(n&gt;32\)</span> 归为一类，x86 为这种 case
选择的处理是“无事发生”——相当于 nop. 从结果上看，<span
class="math inline">\(n=0\)</span> 和 <span
class="math inline">\(n&gt;31\)</span> 都是 nop，这还真是最硬件的视角。
<a
href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#logic-and-shift-instructions-shr">NVIDIA
GPU</a> 和 <a
href="https://developer.arm.com/documentation/ddi0406/latest/">Armv7</a>
的处理更现代一点，选择了 clamp，首先视为无符号数，然后 <span
class="math inline">\(n&gt;32\)</span> 将被 clamp 到 32.</p>
<p>到这里，其实可以看出，硬件指令集和编程语言之间有着紧密的联系，C/C++
和 x86 作为古老组，倾向于“未定义”和 mask
这种简单做法，或许也受制于当时的条件。
而更现代的指令集和语言则倾向于通过 clamp 扩展到 <span
class="math inline">\(n\in\{0\}\cup[32]\)</span>
的支持，并做了明确定义。</p>
<blockquote>
<p>x86:</p>
<p><code>SHR r/m32, CL</code></p>
<p><code>SHR r/m32, imm8</code></p>
<p>The count operand can be an immediate value or the CL register. The
count is masked to 5 bits (or 6 bits with a 64-bit operand). The count
range is limited to 0 to 31 (or 63 with a 64-bit operand).</p>
<hr />
<p>NVIDIA GPU:</p>
<p>同上文的 PTX 定义.</p>
<hr />
<p>Armv7:</p>
<p><code>LSR&#123;S&#125;&#123;cond&#125; Rd, Rm, Rs</code></p>
<p><code>LSR&#123;S&#125;&#123;cond&#125; Rd, Rm, #sh</code></p>
<p><code>Rs</code> is a register holding a shift value to apply to the
value in <code>Rm</code>. Only the least significant byte is used.</p>
<p><code>sh</code> is a constant shift. The range of values permitted is
1-32.</p>
</blockquote>
<p>虽然 Armv7 <code>Rs</code> 只说了用最低的 byte（类似 x86 CL
寄存器），没说到底是 mask 还是
clamp，但从和立即数保持一致考虑，以及实验验证，判断应该是 clamp 到 1-32
区间。 实验中也发现，虽然定义没说右移 0 位的情况，但立即数取 0
可以通过汇编，不论是立即数还是寄存器，右移 0 位结果是无事发生，相当于
nop.</p>
<p>而对于 <a
href="https://docs.python.org/3/reference/expressions.html#shifting-operations">Python
3</a> 这种解释器/虚拟机语言，直接按照数学定义即可。</p>
<blockquote>
<p>Python:</p>
<p>A right shift by <em>n</em> bits is defined as floor division by
<code>pow(2,n)</code>.</p>
</blockquote>
<h3 id="评价">评价</h3>
<p>综合上面的讨论，可以看出现代指令集和语言的处理基本都是将无符号数 n
通过 clamp 限定在 <span class="math inline">\(n\in\{0\}\cup[32]\)</span>
区间，从而符合逻辑右移的数学定义。 但 C/C++ 和 x86 则是未定义 <span
class="math inline">\(n\ge 32\)</span>
的情况，导致边界条件上和数学定义不一致。</p>
<p>具体实现中，对于 C++，如果编译器发现 <span class="math inline">\(n\ge
32\)</span>，会编译器告警，在 GCC 上，如果开启 <code>-O3</code>
优化，结果会被编译器优化为 0，也算是符合数学定义。 但运行时遇到 <span
class="math inline">\(n\ge 32\)</span>
以及不开启编译器优化时，则依赖于目标架构的逻辑右移实现。 在 Armv7
这类架构上，应该返回 0，和数学定义一致。 而对于 x86
架构，这种情况则会当作无事发生，与数学定义不符。</p>
<p>这种不一致，在特定算法中可能导致意料之外的麻烦，比如“除数为常数的无符号整数除法”。如果有空，且听下回分解。</p>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>x86</tag>
        <tag>Arm</tag>
        <tag>C++</tag>
        <tag>CUDA</tag>
        <tag>PTX</tag>
        <tag>Python</tag>
        <tag>体系结构</tag>
      </tags>
  </entry>
  <entry>
    <title>面试中的C++问题（1）</title>
    <url>/2021/09/03/%E9%9D%A2%E8%AF%95%E4%B8%AD%E7%9A%84C-%E9%97%AE%E9%A2%98%EF%BC%881%EF%BC%89/</url>
    <content><![CDATA[<p>虽然大部分面试都是问项目，然后一道代码题，但还是有少量公司很喜欢问“基础的”技术问题，比如C++、体系结构之类。因此开个新系列，记录一下面试里遇到的一些技术类问题。有一些很简单，也有一些可能也没那么常见。</p>
<span id="more"></span>
<h3 id="explicit"><code>explicit</code></h3>
<p>很基础的问题，用于避免隐式类型转换。遇到过的一个坑是图形学光线追踪大作业的框架，里面<code>Color</code>类构造函数RGB三个值都给了默认值然后没加<code>explicit</code>，导致<code>3.0f * Color(...)</code>时会把<code>3.0f</code>隐式转化成<code>Color</code>...</p>
<h3 id="数组初始化默认值">数组初始化默认值</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> a[<span class="number">8</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br></pre></td></tr></table></figure>
<p>那么没有显式写出来的值都是0.</p>
<h3 id="char类型转换"><code>char</code>类型转换</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">char</span> a = <span class="number">-1</span>;</span><br><span class="line"><span class="type">int</span> b = a;</span><br></pre></td></tr></table></figure>
<p>问<code>b &gt; 0</code>是否成立。显然不成立，<code>char</code>是有符号的。</p>
<h3 id="null-nullptr"><code>0</code>, <code>NULL</code>,
<code>nullptr</code></h3>
<p>这个问题没有那么显然。在C里，<code>NULL</code>定义为</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> NULL ((void *) 0)</span></span><br></pre></td></tr></table></figure>
<p>因此<code>NULL</code>在C中可以安全地当成空指针使用。</p>
<p>但C++没那么轻松，因为C++不允许<code>void *</code>隐式转换成其他类型的指针，所以不能沿用C的做法；只能简单地定义为0：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NULL 0</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NULL ((void *) 0)</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<p>但C++支持同名函数重载，如果一个函数定义为</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">int</span> a)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">(<span class="type">int</span> *p)</span></span>;</span><br></pre></td></tr></table></figure>
<p>那么<code>func(NULL)</code>就会导致二义性问题：预期调用指针版本的函数，但实际上参数为整形，调用了整形版本的函数。</p>
<p>为了解决这个问题，C++
11引入了空指针字面量<code>nullptr</code>，其类型为<code>std::nullptr_t</code>，可以隐式类型转换为任意类型指针或类成员指针。在一些C++
11之后的实现中，<code>NULL</code>定义为<code>nullptr</code>。</p>
<h4 id="延伸类成员指针不是指针">延伸：类成员指针不是指针</h4>
<p>类成员指针实际上是偏置量offset，而不是指向某一内存地址的指针。参考：<a
href="https://isocpp.org/wiki/faq/pointers-to-members">Pointers to
Member Functions</a>.</p>
<h3
id="如何在执行main函数前做一些自定义行为">如何在执行<code>main</code>函数前做一些自定义行为？</h3>
<p>一个trick：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Foo</span>() &#123;</span><br><span class="line">        <span class="comment">// do something...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Foo foo;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>全局变量在<code>main</code>之前初始化，因此只要在自定义类型的构造函数里安排自定义行为，然后定义一个全局变量对象即可。</p>
<blockquote>
<p>一个想法：或许这里用<code>static Foo foo;</code>更好。</p>
</blockquote>
<h3
id="模板函数能否在.cpp里实现编译后成.o后再链接">模板函数能否在<code>.cpp</code>里实现，编译后成<code>.o</code>后再链接？</h3>
<p>不行。本科写图形学大作业时踩过的坑，当时乔总就告诉我应该直接写在<code>.hpp</code>头文件里。</p>
<p>原理是<code>template</code>并没有定义任何东西，只有特化后确定了类型信息，编译器才能分配空间进而编译成<code>.o</code>，否则无法编译。</p>
<h4 id="延伸避免模板重复">延伸：避免模板重复</h4>
<p>据说可以用<code>extern</code>，没有尝试过。</p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>面试</tag>
        <tag>空指针</tag>
      </tags>
  </entry>
  <entry>
    <title>面试中的C++问题（2）</title>
    <url>/2021/09/05/%E9%9D%A2%E8%AF%95%E4%B8%AD%E7%9A%84C-%E9%97%AE%E9%A2%98%EF%BC%882%EF%BC%89/</url>
    <content><![CDATA[<p>继续这个系列。本篇的问题可能比上一篇稍复杂一些。</p>
<span id="more"></span>
<h3 id="三种智能指针">三种智能指针</h3>
<p>C++
11之后建议使用三种智能指针。需要包含<code>&lt;memory&gt;</code>头文件。请区分对象的“生命周期拥有权”和“观测权”。</p>
<blockquote>
<p><code>auto_ptr</code>已经被淘汰，不建议使用。</p>
</blockquote>
<h4 id="unique_ptr"><code>unique_ptr</code></h4>
<p>独占对象的生命周期拥有权，当然也包括观测权。它指向的对象不能复制、值传递，不能用于基于值传递的STL库。只能移动，之后原始的<code>unique_ptr</code>变成空指针。</p>
<p><strong>注意</strong>：如果<code>unique_ptr</code>是临时右值，则允许拷贝。</p>
<p>可以用<code>reset()</code>、<code>release()</code>，也可以直接重新赋值。</p>
<p><code>unique_ptr</code>生命周期结束时，自动析构其指向的资源。</p>
<h4 id="shared_ptr"><code>shared_ptr</code></h4>
<p>可以共享对象的生命周期拥有权（包括观测权）。底层原理是引用计数，因此除了对象本身，还需要分配一块内存用于记录引用计数，所有<code>shared_ptr</code>共享该计数区域，每多一个<code>shared_ptr</code>，引用+1.
每个<code>shared_ptr</code>结束生命周期时，引用-1.
当引用归零时，自动析构其指向的资源。</p>
<p><strong>注意</strong>：在涉及循环引用时，可能出现问题，如（例子来自<a
href="https://www.cnblogs.com/KillerAery/p/9096558.html">KillerAery -
C++11智能指针的深度理解</a>）：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Monster</span> &#123;</span><br><span class="line">　　std::shared_ptr&lt;Monster&gt; m_father;</span><br><span class="line">　　std::shared_ptr&lt;Monster&gt; m_son;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">　　<span class="function"><span class="type">void</span> <span class="title">setFather</span><span class="params">(std::shared_ptr&lt;Monster&gt;&amp; father)</span></span>;<span class="comment">//实现细节懒得写了</span></span><br><span class="line">　　<span class="function"><span class="type">void</span> <span class="title">setSon</span><span class="params">(std::shared_ptr&lt;Monster&gt;&amp; son)</span></span>;　　　 <span class="comment">//懒</span></span><br><span class="line">　　~<span class="built_in">Monster</span>() &#123;std::cout &lt;&lt; <span class="string">&quot;A monster die!&quot;</span>;&#125;　　　　<span class="comment">//析构时发出死亡的悲鸣</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">runGame</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::shared_ptr&lt;Monster&gt; father = <span class="keyword">new</span> <span class="built_in">Monster</span>();</span><br><span class="line">    std::shared_ptr&lt;Monster&gt; son = <span class="keyword">new</span> <span class="built_in">Monster</span>();</span><br><span class="line">    father-&gt;<span class="built_in">setSon</span>(son);</span><br><span class="line">    son-&gt;<span class="built_in">setFather</span>(father);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么在<code>runGame()</code>结束时，父子指针都无法正常析构。为了解决这一问题，需要使用<code>weak_ptr</code>。</p>
<h4 id="weak_ptr"><code>weak_ptr</code></h4>
<p><code>shared_ptr</code>代表强引用，即生命周期拥有权；而<code>weak_ptr</code>代表弱引用，即只拥有观测权。<code>weak_ptr</code>不应该单独使用，应该仅作为<code>shared_ptr</code>的辅助。</p>
<p>引入<code>weak_ptr</code>后，计数区域需要区分两种引用计数：强引用计数和弱引用计数。当强引用计数归零时，析构指向的对象；当弱引用计数和强引用计数都归零时，才能释放该计数区域。</p>
<p>在定义拥有对象生命周期控制权的指针时，使用<strong>一次</strong><code>shared_ptr</code>以拥有该对象（i.e.
当该指针的生命周期结束时，该对象予以析构，其他任何地方都不应该再使用该对象）。<strong>其他任何</strong>要引用该对象的地方，都应该使用<code>weak_ptr</code>。</p>
<p><strong>注意</strong>：</p>
<ol type="1">
<li>如果在<code>weak_ptr</code>未感知的地方<code>shared_ptr</code>生命周期结束，可能导致<code>weak_ptr</code>指针空悬问题。为了解决这一问题，<code>weak_ptr</code>引入<code>expired()</code>成员，可以判断对象是否已释放。</li>
<li>同样原因，<code>weak_ptr</code>没有重载<code>*</code>和<code>-&gt;</code>，所以称为“观测权”要比“使用权”更好。因此要使用被弱引用的对象，必须先用<code>weak_ptr</code>的<code>lock()</code>获得一个
<strong><code>shared_ptr</code></strong>，用该<code>shared_ptr</code>使用对象，在使用完成后即使析构该指针（善用作用域）。</li>
</ol>
<h3 id="四种显式类型转换">四种显式类型转换</h3>
<h4 id="static_cast"><code>static_cast</code></h4>
<p>总体而言用于相关类型间的转换，编译器将尽可能检查类型转换的正确性，并在需要时修改底层二进制表示（如<code>int</code>转成<code>float</code>）。在可能丢失精度时，编译器<strong>不会</strong>提示——如果程序员显示使用了<code>static_cast</code>，则认为你已经预料到了这样的风险。几种常见用法：</p>
<ol type="1">
<li>用于内置类型间的转换；</li>
<li>用于<code>void *</code>和包含类型的指针之间的互相转换；</li>
<li>有<strong>继承关系</strong>的类型<strong>指针或引用</strong>之间的转换：从子类到父类安全，但从父类到子类不一定安全！如果可能，最好使用<code>dynamic_cast</code>；</li>
<li>自定义了转换关系的类型<strong>对象</strong>之间的转换。</li>
</ol>
<blockquote>
<p>自定义转换关系： 1）在源类型中定义目标类型的operator；
2）在目标类型中定义以源类型为唯一参数的构造函数。</p>
</blockquote>
<h4 id="reinterpret_cast"><code>reinterpret_cast</code></h4>
<p>保证底层二进制不变，只是编译器层面上改变了对该二进制的解释类型。</p>
<p>一般用于<strong>无关类型</strong>的指针间互相转换。也可以用于整数和指针直接的转化，如:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">Device *p = <span class="built_in">reinterpret_cast</span>&lt;Device *&gt;(<span class="number">0xff00</span>);</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：如果转换可能导致精度丢失，则编译器报错。</p>
<p><code>static_cast</code>和<code>reinterpret_cast</code>的几个例子：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> *p = <span class="keyword">new</span> <span class="type">float</span>;</span><br><span class="line">*p = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> *ip = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">int</span> *&gt;(p);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;0x%x\n&quot;</span>, *ip);</span><br><span class="line">cout &lt;&lt; ip &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// float *fp = static_cast&lt;float *&gt;(ip);    // forbidden: invalid type</span></span><br><span class="line"><span class="type">void</span> *vp = <span class="built_in">static_cast</span>&lt;<span class="type">void</span> *&gt;(p);</span><br><span class="line"><span class="type">float</span> *fp = <span class="built_in">static_cast</span>&lt;<span class="type">float</span> *&gt;(vp);</span><br><span class="line">cout &lt;&lt; *fp &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> i = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(*p);</span><br><span class="line">cout &lt;&lt; i &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// int what = reinterpret_cast&lt;int&gt;(p);     // on x64 forbidden: loses precision</span></span><br><span class="line"><span class="type">long</span> <span class="type">long</span> what = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">long</span> <span class="type">long</span>&gt;(p);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;0x%llx\n&quot;</span>, what);</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> lose = <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="number">1.1f</span>);</span><br><span class="line">cout &lt;&lt; lose &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line"><span class="type">char</span> losec = <span class="built_in">static_cast</span>&lt;<span class="type">char</span>&gt;(<span class="number">1</span> &lt;&lt; <span class="number">20</span>);</span><br><span class="line">cout &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(losec) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">delete</span> p;</span><br></pre></td></tr></table></figure>
<p>其输出为</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">0x40000000</span><br><span class="line">0x562df031eeb0</span><br><span class="line">2</span><br><span class="line">2</span><br><span class="line">0x562df031eeb0</span><br><span class="line">1</span><br><span class="line">0</span><br></pre></td></tr></table></figure>
<h4 id="dynamic_cast"><code>dynamic_cast</code></h4>
<p>主要用于有（直接或间接）继承关系的类的指针和引用的转换。<strong>注意</strong>：基类必须定义虚函数！</p>
<p>几个例子。先定义如下类型：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="type">int</span> _a;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">A</span><span class="params">(<span class="type">int</span> a)</span> : _a(a) &#123;</span>&#125;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_a</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> _a; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">B</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">func</span><span class="params">()</span> </span>&#123; <span class="built_in">puts</span>(<span class="string">&quot;I&#x27;m B!&quot;</span>); &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">D</span>: <span class="keyword">public</span> B &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="built_in">puts</span>(<span class="string">&quot;I&#x27;m D!&quot;</span>); &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dadd</span>: <span class="keyword">public</span> B &#123;</span><br><span class="line">    <span class="type">int</span> _d;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">Dadd</span><span class="params">(<span class="type">int</span> d)</span> : _d(d) &#123;</span> &#125;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">get_d</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> _d; &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="built_in">printf</span>(<span class="string">&quot;I&#x27;m D(%d)!\n&quot;</span>, _d); &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">myfunc</span><span class="params">()</span> </span>&#123; <span class="built_in">printf</span>(<span class="string">&quot;I&#x27;m special with %d!\n&quot;</span>, _d); &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DA</span>: <span class="keyword">public</span> Dadd, <span class="keyword">public</span> A &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">DA</span>(<span class="type">int</span> d, <span class="type">int</span> a) : <span class="built_in">Dadd</span>(d), <span class="built_in">A</span>(a) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="built_in">printf</span>(<span class="string">&quot;I&#x27;m DA(%d, %d)!\n&quot;</span>, <span class="built_in">get_d</span>(), <span class="built_in">get_a</span>()); &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>继承关系：</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">A     B</span><br><span class="line">^     ^</span><br><span class="line">|     |------</span><br><span class="line">|     |     |</span><br><span class="line">|     Dadd  D</span><br><span class="line">|     |</span><br><span class="line">-------</span><br><span class="line">   |</span><br><span class="line">   DA</span><br></pre></td></tr></table></figure>
<h5 id="例1">例1</h5>
<p>首先是指针间互相转换。同一条继承线上的类型指针可以用<code>static_cast</code>或<code>dynamic_cast</code>随意转换，最终运行时都会根据VTABLE选择<strong>对象</strong>对应的函数。原理是对象就在内存中，且具有确定的类型和确定的VTABLE，指针可以随意类型。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">D *d = <span class="keyword">new</span> D;</span><br><span class="line">B *sb = <span class="built_in">static_cast</span>&lt;B *&gt;(d);</span><br><span class="line">sb-&gt;<span class="built_in">func</span>();</span><br><span class="line"></span><br><span class="line">B *db = <span class="built_in">dynamic_cast</span>&lt;B *&gt;(d);</span><br><span class="line">db-&gt;<span class="built_in">func</span>();</span><br><span class="line">D *dd = <span class="built_in">dynamic_cast</span>&lt;D *&gt;(db);</span><br><span class="line">dd-&gt;<span class="built_in">func</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Dadd *sdadd = static_cast&lt;Dadd *&gt;(d);    // forbidden</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// This is WRONG!</span></span><br><span class="line"><span class="comment">// `sdadd-&gt;myfunc()` may run with output 0 on some platforms,</span></span><br><span class="line"><span class="comment">// and with random output on others.</span></span><br><span class="line">Dadd *sdadd = <span class="built_in">static_cast</span>&lt;Dadd *&gt;(db);</span><br><span class="line">sdadd-&gt;<span class="built_in">func</span>();</span><br><span class="line">sdadd-&gt;<span class="built_in">myfunc</span>();</span><br><span class="line"></span><br><span class="line">DA *sDA = <span class="built_in">static_cast</span>&lt;DA *&gt;(db);</span><br><span class="line">sDA-&gt;<span class="built_in">func</span>();</span><br><span class="line"></span><br><span class="line">Dadd *ddadd = <span class="built_in">dynamic_cast</span>&lt;Dadd *&gt;(db);</span><br><span class="line"><span class="keyword">if</span> (ddadd) &#123;</span><br><span class="line">    ddadd-&gt;<span class="built_in">myfunc</span>();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;failed to convert: B* -&gt; Dadd*&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">delete</span> d;</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">I&#x27;m D!</span><br><span class="line">I&#x27;m D!</span><br><span class="line">I&#x27;m D!</span><br><span class="line">I&#x27;m D!</span><br><span class="line">I&#x27;m special with 2123768864!</span><br><span class="line">I&#x27;m D!</span><br><span class="line">failed to convert: B* -&gt; Dadd*</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：<code>Dadd *sdadd</code>
导致的越界访存错误在本文初版中没有提示，详见评论区。</p>
<p>也可以试试将 <code>_d</code>
改为一个堆上指针，这种情况下，直接运行可能并不会报错而是输出随机值，但用
gdb launch 就会 SEGV，有趣的一点是，某些 gdb 实现会给 <code>_d</code>
这种未初始化的堆指针赋默认值如 <code>0xabababab</code>，因此
<code>sdadd-&gt;myfunc()</code> 会触发段错误。但本文中放在栈上，即使用
gdb 也不会段错误。</p>
</blockquote>
<h5 id="例2">例2</h5>
<p>不能直接转化的类型指针之间，也可以调用<code>dynamic_cast</code>，但结果为空指针。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">Dadd *da = <span class="keyword">new</span> <span class="built_in">Dadd</span>(<span class="number">2</span>);</span><br><span class="line">D *dad = <span class="built_in">dynamic_cast</span>&lt;D *&gt;(da);</span><br><span class="line"><span class="keyword">if</span> (dad) &#123;</span><br><span class="line">    dad-&gt;<span class="built_in">func</span>();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;failed to convert: Dadd* -&gt; D*&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">delete</span> da;</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">failed to convert: Dadd* -&gt; D*</span><br></pre></td></tr></table></figure>
<h5 id="例3">例3</h5>
<p><code>dynamic_cast</code>还可以用于引用的转换（注意是引用，<strong>不是</strong>对象！），成功与否同样取决于被引用的对象实际的类型。类似的，<code>static_cast</code>也有同样效果。</p>
<p><strong>注意</strong>：不同于指针转换失败会返回空指针，引用转换失败会抛出<code>std::bad_cast</code>异常。</p>
<p>另外，<code>static_cast</code>还是可以用于<strong>对象本身</strong>的直接转换——会尝试构造<strong>新对象</strong>！</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">    <span class="function">Dadd <span class="title">dar</span><span class="params">(<span class="number">3</span>)</span></span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// D &amp;dadr = static_cast&lt;D &amp;&gt;(dar);     // forbidden</span></span><br><span class="line">        D &amp;dadr = <span class="built_in">dynamic_cast</span>&lt;D &amp;&gt;(dar);</span><br><span class="line">        dadr.<span class="built_in">func</span>();</span><br><span class="line">    &#125; <span class="built_in">catch</span>(<span class="type">const</span> bad_cast&amp; e) &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;failed to convert: Dadd&amp; -&gt; D&amp;&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// B &amp;dabr = static_cast&lt;B &amp;&gt;(dar);         // this is also OK!</span></span><br><span class="line">    B &amp;dabr = <span class="built_in">dynamic_cast</span>&lt;B &amp;&gt;(dar);</span><br><span class="line">    dabr.<span class="built_in">func</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        D &amp;bdr = <span class="built_in">dynamic_cast</span>&lt;D &amp;&gt;(dabr);</span><br><span class="line">        bdr.<span class="built_in">func</span>();</span><br><span class="line">    &#125; <span class="built_in">catch</span>(<span class="type">const</span> bad_cast&amp; e) &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;failed to convert: B&amp; -&gt; D&amp;&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Dadd &amp;bdadr = <span class="built_in">dynamic_cast</span>&lt;Dadd &amp;&gt;(dabr);</span><br><span class="line">    bdadr.<span class="built_in">func</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// DA what1 = static_cast&lt;DA&gt;(dar);     // no matching function for call to ‘DA::DA(Dadd&amp;)’</span></span><br><span class="line">    B what2 = <span class="built_in">static_cast</span>&lt;B&gt;(dar);</span><br><span class="line">    what2.<span class="built_in">func</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">failed to convert: Dadd&amp; -&gt; D&amp;</span><br><span class="line">I&#x27;m D(3)!</span><br><span class="line">failed to convert: B&amp; -&gt; D&amp;</span><br><span class="line">I&#x27;m D(3)!</span><br><span class="line">I&#x27;m B!</span><br></pre></td></tr></table></figure>
<h5 id="例4">例4</h5>
<p><code>dynamic_cast</code>甚至可以实现有共同子类（多根继承）的基类间的转换——这是通过运行时检查VTABLE做到的，也是<code>static_cast</code>在编译时做不到的事！</p>
<blockquote>
<p>To be mentioned,
<code>dynamic_cast</code>的目标类型不一定是多态的，如例子中的<code>class A</code>。</p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">    DA *carrier = <span class="keyword">new</span> <span class="built_in">DA</span>(<span class="number">5</span>, <span class="number">6</span>);</span><br><span class="line"></span><br><span class="line">    B *cb = <span class="built_in">static_cast</span>&lt;B *&gt;(carrier);</span><br><span class="line">    <span class="comment">// A *cas = static_cast&lt;A *&gt;(cb);       // forbidden</span></span><br><span class="line">    A *cad = <span class="built_in">dynamic_cast</span>&lt;A *&gt;(cb);</span><br><span class="line">    cout &lt;&lt; cad-&gt;<span class="built_in">get_a</span>() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">delete</span> carrier;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">6</span><br></pre></td></tr></table></figure>
<h4 id="const_cast"><code>const_cast</code></h4>
<p>用于去除<code>const</code>限定符。</p>
<blockquote>
<p>如果要修改<code>const</code>变量的某个部分，强制转换不一定是最好的方案。可以考虑使用<code>mutable</code>将可变的部分定义为“一定不是常量”。</p>
</blockquote>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>面试</tag>
        <tag>智能指针</tag>
        <tag>显式类型转换</tag>
      </tags>
  </entry>
</search>
